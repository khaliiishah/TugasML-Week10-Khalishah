{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries"
      ],
      "metadata": {
        "id": "pSe3dbi-bk-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4C0u1i6HbKOk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset"
      ],
      "metadata": {
        "id": "Xy2Lc2SXcABg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/heart_failure_clinical_records_dataset.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "LAqiv3upcEDx",
        "outputId": "ca3af63f-7e56-4ae8-8a39-473058bdb660"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
              "0  75.0        0                       582         0                 20   \n",
              "1  55.0        0                      7861         0                 38   \n",
              "2  65.0        0                       146         0                 20   \n",
              "3  50.0        1                       111         0                 20   \n",
              "4  65.0        1                       160         1                 20   \n",
              "\n",
              "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
              "0                    1  265000.00               1.9           130    1   \n",
              "1                    0  263358.03               1.1           136    1   \n",
              "2                    0  162000.00               1.3           129    1   \n",
              "3                    0  210000.00               1.9           137    1   \n",
              "4                    0  327000.00               2.7           116    0   \n",
              "\n",
              "   smoking  time  DEATH_EVENT  \n",
              "0        0     4            1  \n",
              "1        0     6            1  \n",
              "2        1     7            1  \n",
              "3        0     7            1  \n",
              "4        0     8            1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df33922b-662f-4b61-bb33-9d296c55e253\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>582</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>265000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>130</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55.0</td>\n",
              "      <td>0</td>\n",
              "      <td>7861</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>263358.03</td>\n",
              "      <td>1.1</td>\n",
              "      <td>136</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65.0</td>\n",
              "      <td>0</td>\n",
              "      <td>146</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>162000.00</td>\n",
              "      <td>1.3</td>\n",
              "      <td>129</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50.0</td>\n",
              "      <td>1</td>\n",
              "      <td>111</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>210000.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>137</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65.0</td>\n",
              "      <td>1</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>327000.00</td>\n",
              "      <td>2.7</td>\n",
              "      <td>116</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df33922b-662f-4b61-bb33-9d296c55e253')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df33922b-662f-4b61-bb33-9d296c55e253 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df33922b-662f-4b61-bb33-9d296c55e253');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7dce14c6-24c5-4724-8536-bd9bd70cd524\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7dce14c6-24c5-4724-8536-bd9bd70cd524')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7dce14c6-24c5-4724-8536-bd9bd70cd524 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 299,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11.894809074044478,\n        \"min\": 40.0,\n        \"max\": 95.0,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          79.0,\n          40.0,\n          67.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anaemia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"creatinine_phosphokinase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 970,\n        \"min\": 23,\n        \"max\": 7861,\n        \"num_unique_values\": 208,\n        \"samples\": [\n          86,\n          379\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ejection_fraction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 14,\n        \"max\": 80,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          20,\n          38\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high_blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"platelets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 97804.23686859828,\n        \"min\": 25100.0,\n        \"max\": 850000.0,\n        \"num_unique_values\": 176,\n        \"samples\": [\n          297000.0,\n          255000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"serum_creatinine\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.034510064089853,\n        \"min\": 0.5,\n        \"max\": 9.4,\n        \"num_unique_values\": 40,\n        \"samples\": [\n          4.4,\n          3.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"serum_sodium\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 113,\n        \"max\": 148,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          133,\n          134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77,\n        \"min\": 4,\n        \"max\": 285,\n        \"num_unique_values\": 148,\n        \"samples\": [\n          215,\n          79\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DEATH_EVENT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHjlT1wrcMq6",
        "outputId": "749de3bd-3d1d-4b6b-c8fe-5c69f8653617"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 299 entries, 0 to 298\n",
            "Data columns (total 13 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   age                       299 non-null    float64\n",
            " 1   anaemia                   299 non-null    int64  \n",
            " 2   creatinine_phosphokinase  299 non-null    int64  \n",
            " 3   diabetes                  299 non-null    int64  \n",
            " 4   ejection_fraction         299 non-null    int64  \n",
            " 5   high_blood_pressure       299 non-null    int64  \n",
            " 6   platelets                 299 non-null    float64\n",
            " 7   serum_creatinine          299 non-null    float64\n",
            " 8   serum_sodium              299 non-null    int64  \n",
            " 9   sex                       299 non-null    int64  \n",
            " 10  smoking                   299 non-null    int64  \n",
            " 11  time                      299 non-null    int64  \n",
            " 12  DEATH_EVENT               299 non-null    int64  \n",
            "dtypes: float64(3), int64(10)\n",
            "memory usage: 30.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "sqhhDY8ZcSY5",
        "outputId": "6307a7d7-b023-4977-a405-0c43a604b2c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              age     anaemia  creatinine_phosphokinase    diabetes  \\\n",
              "count  299.000000  299.000000                299.000000  299.000000   \n",
              "mean    60.833893    0.431438                581.839465    0.418060   \n",
              "std     11.894809    0.496107                970.287881    0.494067   \n",
              "min     40.000000    0.000000                 23.000000    0.000000   \n",
              "25%     51.000000    0.000000                116.500000    0.000000   \n",
              "50%     60.000000    0.000000                250.000000    0.000000   \n",
              "75%     70.000000    1.000000                582.000000    1.000000   \n",
              "max     95.000000    1.000000               7861.000000    1.000000   \n",
              "\n",
              "       ejection_fraction  high_blood_pressure      platelets  \\\n",
              "count         299.000000           299.000000     299.000000   \n",
              "mean           38.083612             0.351171  263358.029264   \n",
              "std            11.834841             0.478136   97804.236869   \n",
              "min            14.000000             0.000000   25100.000000   \n",
              "25%            30.000000             0.000000  212500.000000   \n",
              "50%            38.000000             0.000000  262000.000000   \n",
              "75%            45.000000             1.000000  303500.000000   \n",
              "max            80.000000             1.000000  850000.000000   \n",
              "\n",
              "       serum_creatinine  serum_sodium         sex    smoking        time  \\\n",
              "count         299.00000    299.000000  299.000000  299.00000  299.000000   \n",
              "mean            1.39388    136.625418    0.648829    0.32107  130.260870   \n",
              "std             1.03451      4.412477    0.478136    0.46767   77.614208   \n",
              "min             0.50000    113.000000    0.000000    0.00000    4.000000   \n",
              "25%             0.90000    134.000000    0.000000    0.00000   73.000000   \n",
              "50%             1.10000    137.000000    1.000000    0.00000  115.000000   \n",
              "75%             1.40000    140.000000    1.000000    1.00000  203.000000   \n",
              "max             9.40000    148.000000    1.000000    1.00000  285.000000   \n",
              "\n",
              "       DEATH_EVENT  \n",
              "count    299.00000  \n",
              "mean       0.32107  \n",
              "std        0.46767  \n",
              "min        0.00000  \n",
              "25%        0.00000  \n",
              "50%        0.00000  \n",
              "75%        1.00000  \n",
              "max        1.00000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-91a3c120-dce4-4f3a-a89a-2218fadb13d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>anaemia</th>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <th>diabetes</th>\n",
              "      <th>ejection_fraction</th>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <th>platelets</th>\n",
              "      <th>serum_creatinine</th>\n",
              "      <th>serum_sodium</th>\n",
              "      <th>sex</th>\n",
              "      <th>smoking</th>\n",
              "      <th>time</th>\n",
              "      <th>DEATH_EVENT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.00000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.00000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>299.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>60.833893</td>\n",
              "      <td>0.431438</td>\n",
              "      <td>581.839465</td>\n",
              "      <td>0.418060</td>\n",
              "      <td>38.083612</td>\n",
              "      <td>0.351171</td>\n",
              "      <td>263358.029264</td>\n",
              "      <td>1.39388</td>\n",
              "      <td>136.625418</td>\n",
              "      <td>0.648829</td>\n",
              "      <td>0.32107</td>\n",
              "      <td>130.260870</td>\n",
              "      <td>0.32107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.894809</td>\n",
              "      <td>0.496107</td>\n",
              "      <td>970.287881</td>\n",
              "      <td>0.494067</td>\n",
              "      <td>11.834841</td>\n",
              "      <td>0.478136</td>\n",
              "      <td>97804.236869</td>\n",
              "      <td>1.03451</td>\n",
              "      <td>4.412477</td>\n",
              "      <td>0.478136</td>\n",
              "      <td>0.46767</td>\n",
              "      <td>77.614208</td>\n",
              "      <td>0.46767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25100.000000</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>51.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>116.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>212500.000000</td>\n",
              "      <td>0.90000</td>\n",
              "      <td>134.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>73.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>250.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>262000.000000</td>\n",
              "      <td>1.10000</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>115.000000</td>\n",
              "      <td>0.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>70.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>582.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>303500.000000</td>\n",
              "      <td>1.40000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>203.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>95.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7861.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>850000.000000</td>\n",
              "      <td>9.40000</td>\n",
              "      <td>148.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>285.000000</td>\n",
              "      <td>1.00000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91a3c120-dce4-4f3a-a89a-2218fadb13d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91a3c120-dce4-4f3a-a89a-2218fadb13d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91a3c120-dce4-4f3a-a89a-2218fadb13d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-769c57b5-69a2-459f-8d40-af83b47a2825\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-769c57b5-69a2-459f-8d40-af83b47a2825')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-769c57b5-69a2-459f-8d40-af83b47a2825 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 89.3211725536912,\n        \"min\": 11.894809074044478,\n        \"max\": 299.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          60.83389297658862,\n          60.0,\n          299.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anaemia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.56541771928569,\n        \"min\": 0.0,\n        \"max\": 299.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.431438127090301,\n          1.0,\n          0.49610726813307915\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"creatinine_phosphokinase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2654.17612524943,\n        \"min\": 23.0,\n        \"max\": 7861.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          581.8394648829432,\n          250.0,\n          299.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"diabetes\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.56619609300547,\n        \"min\": 0.0,\n        \"max\": 299.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.4180602006688963,\n          1.0,\n          0.49406706510360887\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ejection_fraction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 95.11328523214719,\n        \"min\": 11.834840741039173,\n        \"max\": 299.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          38.08361204013378,\n          38.0,\n          299.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high_blood_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.57037978700328,\n        \"min\": 0.0,\n        \"max\": 299.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3511705685618729,\n          1.0,\n          0.4781363790627452\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"platelets\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 267437.1976619797,\n        \"min\": 299.0,\n        \"max\": 850000.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          263358.02926421404,\n          262000.0,\n          299.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"serum_creatinine\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 104.95907923971718,\n        \"min\": 0.5,\n        \"max\": 299.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.3938795986622072,\n          1.1,\n          299.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"serum_sodium\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 79.73746182740307,\n        \"min\": 4.412477283909233,\n        \"max\": 299.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          136.62541806020067,\n          137.0,\n          299.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.50484411278607,\n        \"min\": 0.0,\n        \"max\": 299.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.6488294314381271,\n          1.0,\n          0.47813637906274487\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoking\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.57243031811801,\n        \"min\": 0.0,\n        \"max\": 299.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3210702341137124,\n          1.0,\n          0.4676704280567721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.09370187205508,\n        \"min\": 4.0,\n        \"max\": 299.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          130.2608695652174,\n          115.0,\n          299.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DEATH_EVENT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.57243031811801,\n        \"min\": 0.0,\n        \"max\": 299.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3210702341137124,\n          1.0,\n          0.4676704280567721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "_3zrbJQmcWAV",
        "outputId": "dd2ac8d5-646e-46da-cde8-cda080d2cfb6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                         0\n",
              "anaemia                     0\n",
              "creatinine_phosphokinase    0\n",
              "diabetes                    0\n",
              "ejection_fraction           0\n",
              "high_blood_pressure         0\n",
              "platelets                   0\n",
              "serum_creatinine            0\n",
              "serum_sodium                0\n",
              "sex                         0\n",
              "smoking                     0\n",
              "time                        0\n",
              "DEATH_EVENT                 0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anaemia</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>creatinine_phosphokinase</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>diabetes</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ejection_fraction</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high_blood_pressure</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>platelets</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>serum_creatinine</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>serum_sodium</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sex</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoking</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DEATH_EVENT</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ViF7AUBcYu0",
        "outputId": "9de409b4-4f08-40a8-ccac-e7f33571d0a4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['age', 'anaemia', 'creatinine_phosphokinase', 'diabetes',\n",
              "       'ejection_fraction', 'high_blood_pressure', 'platelets',\n",
              "       'serum_creatinine', 'serum_sodium', 'sex', 'smoking', 'time',\n",
              "       'DEATH_EVENT'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding categorical columns using LabelEncoder"
      ],
      "metadata": {
        "id": "uG9kfc1hcgHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_cols = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking', 'DEATH_EVENT']\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "for col in label_cols:\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        ""
      ],
      "metadata": {
        "id": "Gpbdz_lAcftW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine features (X) and targets (y)"
      ],
      "metadata": {
        "id": "gBYU6kRbc9kW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(['DEATH_EVENT'], axis=1)\n",
        "y = df['DEATH_EVENT']"
      ],
      "metadata": {
        "id": "OG1EnPuBdJxN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cb1P8-HmdhQK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standardization of numeric features"
      ],
      "metadata": {
        "id": "-mKK6mDUdp_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "8JNwdFh8du_7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert data to tensor"
      ],
      "metadata": {
        "id": "U7HgXKPseA-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
      ],
      "metadata": {
        "id": "BDP0U7uyeEJH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constructing an MLP model for regression"
      ],
      "metadata": {
        "id": "sYmd8IdAeHoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPRegression(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layers, neurons, activation):\n",
        "        super(MLPRegression, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.neurons = neurons\n",
        "        self.activation = activation\n",
        "\n",
        "        # Create input to hidden layer\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(self.input_size, self.neurons))\n",
        "\n",
        "        # Add hidden layers\n",
        "        for _ in range(self.hidden_layers - 1):\n",
        "            layers.append(self.activation())\n",
        "            layers.append(nn.Linear(self.neurons, self.neurons))\n",
        "\n",
        "        layers.append(nn.Linear(self.neurons, 1))  # Output layer\n",
        "\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x).squeeze()\n"
      ],
      "metadata": {
        "id": "THk0Jx5neMGe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup device (GPU if available)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters to be tested\n",
        "hidden_layers = [1, 2, 3]\n",
        "neurons = [4, 8, 16, 32, 64]\n",
        "activations = [nn.Sigmoid, nn.ReLU, nn.Softmax, nn.Tanh]  # Corrected nn.RelU to nn.ReLU\n",
        "epochs_list = [1, 10, 25, 50, 100, 250]\n",
        "learning_rates = [10, 1, 0.1, 0.01, 0.001, 0.0001]\n",
        "batch_sizes = [16, 32, 64, 128, 256, 512]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Experimenting with hyperparameter combinations\n",
        "for layers in hidden_layers:\n",
        "    for neuron in neurons:\n",
        "        for activation in activations:\n",
        "            for epochs in epochs_list:\n",
        "                for lr in learning_rates:\n",
        "                    for batch_size in batch_sizes:\n",
        "                        # Create and move model to device (GPU or CPU)\n",
        "                        model = MLPRegression(input_size=X_train_tensor.shape[1],\n",
        "                                              hidden_layers=layers,\n",
        "                                              neurons=neuron,\n",
        "                                              activation=activation).to(device)\n",
        "\n",
        "                        # Define loss function and optimizer\n",
        "                        criterion = nn.MSELoss()\n",
        "                        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                        # Training loop\n",
        "                        for epoch in range(epochs):\n",
        "                            model.train()\n",
        "                            optimizer.zero_grad()\n",
        "                            outputs = model(X_train_tensor.to(device))\n",
        "                            loss = criterion(outputs, y_train_tensor.to(device))\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                        # Evaluate model after training\n",
        "                        model.eval()\n",
        "                        with torch.no_grad():\n",
        "                            y_pred = model(X_test_tensor.to(device)).cpu().numpy()\n",
        "                            mae = mean_absolute_error(y_test, y_pred)\n",
        "                            mse = mean_squared_error(y_test, y_pred)\n",
        "                            r2 = r2_score(y_test, y_pred)\n",
        "                            accuracy = (1 - mae / max(y_test)) * 100  # Accuracy estimation\n",
        "\n",
        "                        # Store results\n",
        "                        results.append({\n",
        "                            'layers': layers,\n",
        "                            'neurons': neuron,\n",
        "                            'activation': activation.__name__,\n",
        "                            'epochs': epochs,\n",
        "                            'lr': lr,\n",
        "                            'batch_size': batch_size,\n",
        "                            'mae': mae,\n",
        "                            'mse': mse,\n",
        "                            'r2': r2,\n",
        "                            'accuracy': accuracy\n",
        "                        })\n",
        "                        print(f\"Layers: {layers}, Neurons: {neuron}, Activation: {activation.__name__}, Epochs: {epochs}, LR: {lr}, Batch Size: {batch_size}, Accuracy:{accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlWqid78eccF",
        "outputId": "92b36126-5edf-4de5-c01d-99b0ef24fa25"
      },
      "execution_count": 16,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-52533.182075818375\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-124020.19070943198\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-58549.255882898964\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-56550.92655022939\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-119413.73678843181\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-68454.98852094014\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-896.025365491708\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-636.5178641676903\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-146.13908559083936\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-707.3535920182865\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-197.6951965689659\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-269.5691728591919\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:59.69966048995654\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:56.662546868125595\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:51.784247706333794\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:55.57460541526476\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:54.01521804432075\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:62.8718121846517\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:37.772789138058826\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:37.61260040104389\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:1.818725541234012\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.492667992909745\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:28.21259225408236\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:17.845943619807557\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:35.50693275717397\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.09584754953782\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:41.17854515711466\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.33453525106112\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:45.25680020451546\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:48.5813419893384\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:7.97139495611191\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:25.20063986380895\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:51.67971844474475\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:10.43845529357592\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.960148848593235\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:40.20771543184917\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-9752.618781725567\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-16607.042922973633\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-34717.279580434166\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-17017.377103169758\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-16699.398091634113\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-14361.146227518717\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-183.58386079470316\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-222.74417797724405\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-289.2744544148445\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-146.2027910351753\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-117.39266395568846\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-50.109240611394256\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.938065285484\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:62.42011534050107\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:63.08969095349312\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:59.4042482227087\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:63.80221857378881\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:65.21484057108562\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:61.785925179719925\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:61.65862618324658\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:58.67874413728714\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:47.24717881530523\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.62748097876707\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:55.30503729979197\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:46.19206534077723\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:49.471101934711136\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:44.75705566505591\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:59.56559151411056\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:38.555172085762024\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:17.53158231576284\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:39.29329112172126\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.570003276069954\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:29.064695338408153\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.40920383731524\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:46.35105798641841\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:37.94755893448989\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-3837.81312306722\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-2894.1572411855063\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-7083.628425598144\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-4267.625549634297\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-14710.276589393616\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1883.0883153279622\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-46.69637635350228\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-47.18586047490439\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:9.164295444885894\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:18.631730278333023\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-21.25497351090113\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-81.98284193873407\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.55473460257053\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.60476331412792\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.92785694698493\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:65.47639379898706\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.52271225551765\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.74522806704044\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.57175127168496\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.47544178863367\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:50.05821311225493\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.62097302079201\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.38539744913578\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.74266902233164\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:12.85219505429268\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:41.74374057600896\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.00623195370038\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:51.661255806684494\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.362843895951904\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:39.4582063704729\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:36.504324873288475\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:39.106136709451675\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:49.163921251893036\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:24.863375648856167\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:42.488518587003156\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.60887810091177\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-242.91412800550464\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1619.9400277932486\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-3704.2964458465576\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-8894.999874432882\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-5862.120469411215\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-2653.745331764221\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:56.48526350657146\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:44.90180474550773\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:55.8243029564619\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:51.07213174303374\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:50.263410856326416\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:52.76383002599081\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.0668383638064\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.70723780492942\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.84798872222504\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.86794489125411\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.99694640437762\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.02117517093818\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.80375864698242\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:62.46752284467221\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.014470393459\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.22483372750382\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.79100561390321\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.22384092522164\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:39.67195288588603\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:28.602308382590614\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:34.082607527573906\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.74852210034926\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:40.80860902865727\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:57.46560404698053\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:43.79043980812033\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:32.182097447415195\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:44.667760686328016\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:28.4569326043129\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:44.91146421680848\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:16.262647261222206\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-104.91992314656575\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-142.3087239265442\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-104.14115448792774\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:0.5250644683837846\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-56.30444844563802\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:32.2653329372406\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:64.98636563618977\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:64.37015046676\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:65.15569845835367\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:64.80118930339813\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.79123791058858\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:65.65135523676872\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.02929947028558\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.02936959266663\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.12354026238123\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.0438442826271\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.0141685207685\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.02426164845625\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.0371138130625\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.028878202041\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.0206896290183\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.00187069177628\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.04879606266816\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.00419224301974\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:53.3398654560248\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:51.43600088854631\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:57.06709104279677\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.17861969769001\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:52.66270340109864\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:63.66259963562091\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:28.816056201855346\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.92477208375931\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:12.33140880862872\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.023873418569565\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:32.4570303161939\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:57.525837173064545\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:65.0130573908488\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.98419443766277\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.02157688140869\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.01326243082683\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:65.00671704610188\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.00948588053386\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01357764005661\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01218318939209\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.01352046926816\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.0280519326528\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01352349917093\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01354632278283\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.03006279468536\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.0136123970151\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01360185444355\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.06218361357847\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.00685455898444\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.00623591244221\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360427588224\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360014081001\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360012839238\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360289131601\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01361019909382\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01358804603417\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.8853574693203\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.02474069595337\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.49190533564737\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:61.967605178554855\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.22615398963292\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.17320185899734\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:61.373388655483716\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:2.722144251068437\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.4340071429809\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.25747329493364\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:58.45508086184661\n",
            "Layers: 1, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:49.80455491691828\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-52918.89685948689\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-124534.40329233806\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-3899.283431371053\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-124364.85563278197\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-53465.88188648224\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-52104.3462785085\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-805.6593932708104\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-82.1639147400856\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-291.315987855196\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-96.82304099202157\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-989.681082169215\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-727.9352236787478\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:55.91188882788023\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:52.52974912524223\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:60.83613522350788\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:31.226379051804543\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:56.42559183140597\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:63.641881396373115\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.51999548574289\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.54639719426632\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:20.051520789663\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:37.372985243176416\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:28.284679626425103\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:44.385130386799574\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:6.857448170582458\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:32.5598077227672\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:45.9949572943151\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:45.74870988726616\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:10.910885433355965\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:42.71299008280038\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:4.335630225638553\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.65317551791669\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:20.436531230807308\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:38.31585258245468\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:40.464787296950824\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:9.99403044581413\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-19233.32514444987\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-35096.08954747518\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-28671.9268544515\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-31247.852212587994\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-40811.575787862144\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-11650.098770459494\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-129.88440076510113\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-113.56977264086407\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-121.2728283305963\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-105.56376457214354\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-72.55443612734476\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-212.38345275322595\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.14897720019023\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:64.23294397691886\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:59.527995213866234\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:63.04139108707507\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:65.03787656625111\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:64.93358346323173\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:58.66469316184521\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:32.97158127029737\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:63.44933385650317\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:42.7892942726612\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:55.85376199334859\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:61.13172327478726\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.693953917672246\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:24.020500952998802\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:46.66419168313344\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:23.270683065056797\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.61447449028492\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.49660995105903\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:9.175770084063217\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:57.45927167435487\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:49.407495434085526\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:28.34001737336318\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:41.70361153781415\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:45.96839300046365\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1877.7801704406738\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-7895.514326095581\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-4296.27495765686\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-8274.767692883808\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-2331.3430500030518\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-18927.621962229412\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-111.5539730588595\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-37.85990645488104\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-56.70071144898732\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-103.89345288276672\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-42.28292783101399\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-45.01194874445598\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.61864193280537\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.40216767291228\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.2675302202503\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:65.24482441445191\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.92391316841046\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.96722069879372\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:63.82233219842116\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:51.04840658605099\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:57.147814383109406\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.01777027050655\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:63.96854107578596\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.09260269502799\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:50.80377376948794\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:27.824985533952717\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:57.24301560471455\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:38.95759094506502\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:34.11959918836752\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:55.85782897348206\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:43.6782036225001\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:49.009998229642704\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:39.20059705773989\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:14.440476174155869\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:28.835485602418586\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:3.7201831241448713\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1932.057419617971\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-863.8600095113118\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-312.45042483011883\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-10248.997694651285\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-4648.712938626607\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-993.1949281692505\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:58.31130128353834\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:47.099126180013016\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:48.15620914101601\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:63.966714665293686\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:58.3969110250473\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:36.24212433894475\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.82517340530951\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.10777674615383\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.70659931500752\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.04060752689838\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.0086228797833\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.66193594038486\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.99644650767247\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.99083523948987\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.041074603796\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.79694520433743\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.20463218291601\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.24959949155648\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:34.27536562085152\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:51.452496126294136\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:46.04455181087057\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:33.90449099242687\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.20239798476299\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:46.62602222835024\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:18.60440460344156\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:21.595411859452728\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:37.769239259262875\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:44.08017611751954\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.603135906159885\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:-4.882219086090722\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-921.8095366160074\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-928.7834898630779\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-7.590408325195308\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-82.39761630694072\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-80.11143684387207\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-216.2410926818848\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:64.81174568335216\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:64.93879040082295\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:63.968952894210815\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:65.22318085034688\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.54703311125438\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:26.20031793912252\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.99118556578954\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.00771110256514\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.01838992039363\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.01752622425556\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.01511772473654\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.06851007541022\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:64.99053105711937\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:64.98371275762717\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:64.99193189044794\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:64.9975847452879\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.02985309654225\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.03857602675755\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:60.833815758426994\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:52.97008206446965\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:36.559286465247474\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:57.01335057616234\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:63.002744379142925\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:62.54694886505604\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:44.77163013070822\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:58.62886910637219\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.69378320376078\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:44.32444122930368\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:14.25236898163954\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:42.78808167825142\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-50.29064814249675\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.01213019092877\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-14.05002752939859\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.01767158508301\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:65.08827845255534\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.01363364358743\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:64.2791493733724\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01355608304343\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.0137476126353\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.0136335939169\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.0136415163676\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01336256663004\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.05613816281159\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01227766275406\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.11098039646943\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.04087929924329\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01359348495801\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.18324601153533\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360210279623\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01359419276316\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360992280145\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360188548763\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01361958682537\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360442489386\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.44696349402268\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.57043403138717\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.96340396503608\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:63.6741575350364\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.02886656671762\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:62.89109235008558\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:46.290880938371025\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:53.69810417294503\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:15.376322145263355\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:58.31539745132128\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:41.770263413588204\n",
            "Layers: 1, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:59.25090931355953\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-62651.53178532918\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-2775.8847649892173\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-65056.79017702738\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-49484.857778549194\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-55887.1257909139\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-3132.213616371155\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-246.90712372461957\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-300.3589699169\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-189.11697437365848\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-76.93295816580455\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-511.05870574712753\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-371.90377314885455\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:47.5298677260677\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:55.12967063734928\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:50.094857290387154\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:59.0532393132647\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:57.00464564065138\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.310786729057625\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:28.632996206482254\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:25.953053881724674\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.56306272496781\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:13.266718561450642\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:43.199895123640694\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:38.261772667368255\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:14.666724254687624\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.41911844412486\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.22758047034344\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:4.556474760174756\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:56.012005036075905\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:41.826366533835724\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:17.964196602503456\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.882188990712166\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:36.78435715536277\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:42.370935579140976\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:1.0982986787954951\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:51.39189466834069\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-18171.752592722576\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-35591.15783691406\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-15631.12590154012\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-37677.59276469549\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-31175.754249890644\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-31862.46652444204\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-139.32381192843118\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-64.61571733156839\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-295.40492365757626\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-52.65818635622661\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-59.51873501141867\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-114.70651254057884\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.85611528158188\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:63.67180035760005\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:63.4822123621901\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:64.0858702113231\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:63.74378837645054\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:63.082965314388275\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:55.43831340968609\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:60.98885652298729\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.151502097646386\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.11197665333748\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:65.22298799206814\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:60.589068035284676\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:50.67517810811599\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:44.58875268697739\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:4.4168595721324255\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:22.52254284918308\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.66984230776628\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:25.652335608998932\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:42.48507511802018\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:24.74722988903523\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:59.26402064661185\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.921563317378364\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:44.84518426936119\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:47.07358422378699\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-6216.023797988892\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-29211.779588063557\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-8740.338263511658\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-7173.501027425131\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-11407.706823348999\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-11794.547812143963\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-109.82261359691621\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-21.07247451941172\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:18.81784061590831\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:22.071057558059692\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-61.14290674527487\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-57.76517470677693\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.27404870589575\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.81257560352485\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.84399871279795\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.86120412747066\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:65.08179229994614\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.43771865467231\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.37442943453789\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.1279036750396\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.02419752379258\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.30821884423494\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.30345520625511\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.26247496406236\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:51.12351657201846\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:45.26010107171411\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:48.48571973542373\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:46.54007442295551\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:42.020868733525276\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:34.44032279153665\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:39.083509457608066\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:8.922376334667204\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:17.187090143561367\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:2.836724470059082\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:34.464522674679756\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:30.33541515469551\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2329.067053794861\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-719.5971560478209\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5466.764039993286\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1444.4936815897624\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3643.1302142143254\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-9591.343859036764\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:60.64171334107718\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:44.92435852686564\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:7.778588185707724\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:55.22497713565826\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:62.290990849335984\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:55.35621166229247\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.04990629851818\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.03664448857307\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.95935427645843\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.81990749637285\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.87948911885421\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.98779870569706\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.83617131908734\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.06536155318221\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.44244445612033\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.95549286405246\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.09552462647359\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.72816612261036\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.80433801313241\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:59.20380861187975\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:59.13014214485883\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:51.63254624387869\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:43.55981423209111\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:60.13290266195933\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:1.4804379642009757\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:39.53320040057103\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:47.11139974494775\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:57.06901106983423\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:21.97873783608277\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.10084357857704\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-151.14382108052573\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-161.66093508402506\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-183.05480559666952\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1539.5548470815022\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-287.8296073277791\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1.423966089884443\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:64.883713722229\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:65.20773231983185\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:64.21954912443955\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:64.95677312215169\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.94738159080346\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:64.64778502782185\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.72052916884422\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.00167759756248\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:64.92959313094616\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:64.99494719008605\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.01470605532329\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.00768414388101\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01858359823625\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.00941334913175\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.00648438930511\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.07647645504524\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:64.99890267848969\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.04946472744146\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:61.68363071978092\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.72507078945637\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.32843249539535\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:38.850263456503555\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:66.67225367079179\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:55.340874791145325\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:57.45390492180984\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:21.170566951235138\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.00180190304915\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:41.284335404634476\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:23.393771325548485\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:29.466341038544975\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:65.01404126485188\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.01250584920247\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.01162588596344\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:64.95767434438069\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:64.81414357821147\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.01179059346516\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01033107439677\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01319944858551\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.0136978427569\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01348435878754\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:59.0552814801534\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:3.6986919244130445\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.01331488291422\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.0135915974776\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01655612140894\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.66088290015857\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.04933310051759\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01014247536659\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.0135703633229\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360097279152\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01359763244787\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360227664313\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01359652727842\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01359216868877\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.96394713719687\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.08355367928743\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.70463196436565\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:64.61082094659407\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.7033665701747\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:64.70037582019965\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:34.89125160189966\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:59.17641215026379\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:44.43194352090358\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:50.08174365075926\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:60.526226833462715\n",
            "Layers: 1, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:51.11763382951418\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-60960.70676962534\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-57525.10201772054\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-132121.07579549155\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-52301.974964141846\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-107461.40123685202\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-69256.73468589783\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-113.30033709605533\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1431.0713802774749\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-72.94910450776418\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-559.352842370669\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-870.0034523010254\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-352.3822567860285\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:57.709832762678474\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.09492046882709\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:58.875182826692864\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:55.98471706112226\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:55.88951664666335\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:50.0746471931537\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:6.310930997133257\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:51.846518740057945\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:38.84179491549731\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:28.892270823319755\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:42.187108527868986\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:58.73954338332017\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:10.601787616809212\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:21.8594529479742\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:44.154014413555466\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:50.18293542166551\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:47.05477734406789\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:-8.770611832539243\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:19.58926893770695\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.53698323418696\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.696631483733654\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:33.75659356514613\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:31.859448170289394\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:56.41462611655395\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-16295.775928497314\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-18089.806156158447\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-37110.35442173481\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-12348.853770891827\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-15222.818749745687\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-39172.82406270504\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-34.29745088020961\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-103.45483243465425\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-86.79893056551616\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-195.88669121265409\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-94.51272974411647\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-41.764449278513595\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:60.28220331917207\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:65.37102884302537\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:66.23004761834939\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:63.30077854295572\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:63.599711482723556\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:63.94004511336486\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:59.76944523553054\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:56.78109834591547\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:44.65358297030131\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:59.26482381299139\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:56.91879943013192\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:65.05388146887223\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.349940230449036\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:7.858894690871243\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:52.62975284208854\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:28.374850830684107\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:51.109800810615226\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:16.828381866216656\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:16.87616993983586\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:45.33030070364475\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:25.23438982665539\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:47.31504528472821\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:29.389779244860016\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.75455871721108\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-16904.538911183674\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-33535.81503868103\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-5022.308794657389\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-30576.10696792602\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-2747.7340189615884\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6187.165565490723\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-44.12016242742538\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-130.78501562277478\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-57.134739657243095\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:14.73819474379222\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:14.840522408485413\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-50.85615674654642\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.57354394098122\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.80541030565898\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.01213796188433\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.70459014177322\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.39794838428497\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.87595190604527\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.54610920200746\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.4198140129447\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.14839162429173\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:63.98550388713677\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.16237073888381\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.08763816207647\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:44.750261008739464\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:44.80607341974974\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:10.707544858256979\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:57.8972622503837\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:47.973517440259464\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:57.75977436453103\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:6.672061185042066\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:16.712900102138516\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:8.920960401495293\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:34.73309429983298\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:12.215217128396038\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:55.808162242174156\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2416.4976437886553\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2965.43114622434\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-3258.103084564209\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2064.4989585876465\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3586.4764412244162\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1929.5289019743602\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:56.91407144069671\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:58.69521220525106\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:56.39239801093936\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:48.2917491098245\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:58.68929187456766\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:57.16132735212645\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.00477025906245\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.79423871884744\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.03662183880806\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.13276254137357\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.91434921820958\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.82980405290921\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.15898210306963\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.29320769011974\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.86659151346733\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.71224072078864\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.13193506747484\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.1371864726146\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:55.412190556526184\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:57.66307860612869\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:47.056541020671524\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:29.89678318301837\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.75694231688977\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:40.354611004392304\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.91602685550849\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:42.350576358536884\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:40.91636726011833\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:45.089448820799596\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:47.863028421998024\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:30.960951447486874\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-137.99797693888345\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-677.2048886617025\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:9.49641476074855\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-631.7735497156779\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-108.24368238449095\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-240.4806065559387\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:65.34499183297157\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:64.37569697697958\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:64.57573811213176\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:65.1141386386007\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:63.9015652736028\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:65.30084888140361\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.02371641496818\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.00476136803627\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.05037928620973\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.16056530177593\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.02569881578286\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.03447530170281\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01203387975693\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.0086413944761\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.11054303497076\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.04996803899606\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.0369297961394\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.02360509087642\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:63.6011786510547\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:25.008123368024826\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:60.043369090805456\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:60.30652843415737\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:56.65171106656393\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:60.4351065059503\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:48.45795282473166\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:44.12397334973017\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:44.808126750091716\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:29.38437566161156\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:60.09135939180851\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:45.820649949212864\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:65.6304391225179\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.02520561218262\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.01294136047363\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.01079817612965\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:65.0181261698405\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:64.91184075673422\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01347824931145\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.17811119556427\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.0136266152064\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01377423604329\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.08533120155334\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01355451842149\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.013615253071\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01354287068048\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.02683088183403\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.96983254949251\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.04391153653462\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01359678804874\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360155642033\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360861584544\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360294719537\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01359399408102\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01359415551026\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.0135944535335\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.90110032260418\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:60.14869786798954\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:55.35346291959286\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:64.8651075984041\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.6181611220042\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:63.14676173031331\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:59.080405297378704\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.2343722085158\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:50.6818366671602\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.405879124999046\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:29.424961209297184\n",
            "Layers: 1, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:5.98376053074996\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-93073.63749345145\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-71787.11500167847\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-60038.860289255776\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-56064.0967241923\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-93962.70908673604\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-61349.21170552572\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-880.0481888155142\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1424.2544189095497\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-520.8286136388779\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-37.330311636130006\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-575.244916031758\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-997.8380238016447\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:57.13930072883765\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:42.80165359377861\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:45.8179249924918\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:59.429333309332534\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:50.901444541911275\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:57.976038480798394\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:49.40199866890907\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:37.32001299659411\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:40.95737876991431\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:40.85269230107467\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:33.58516277745366\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:51.032223949829735\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:44.90977402155598\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:36.07819472750028\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:25.046886528531708\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.97182952860991\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:38.140183215339974\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:49.10277531171838\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:32.72646987189849\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:33.68716726700465\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:29.22228338817755\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:54.69297846158345\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:31.69636823236942\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:14.989175026615465\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-23644.533917109173\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-133738.7734222412\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-82031.108862559\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-73376.55393918355\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-75783.7280869484\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-70772.34136581421\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-614.6374640862147\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-245.7826167345047\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-437.34672586123145\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-726.8218340476354\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-921.9815744956334\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-333.48202745119727\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.86997025708358\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:65.8081236233314\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:64.66621811191241\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:64.98621299862862\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:64.48447975019613\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:63.106538032492\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.74309074381988\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:48.15180433293184\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:58.312114427487046\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:60.2987569073836\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:61.111489459872246\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:53.73019782205423\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:56.492220163345344\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:57.728629410266876\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:43.5173787145565\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:28.66084670027097\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:56.61397351572911\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.90986197193464\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:39.741510643313326\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:11.641389777263\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.19128029048443\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:39.20172613114119\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:31.6725404560566\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:42.822807425012186\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-31319.666878382366\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-67280.39521455765\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-41915.231030782066\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-35025.98161061605\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-9371.061553955078\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-27854.896313349407\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-192.3476243019104\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-339.03816024462384\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-318.2001443703969\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-292.77112503846485\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-300.3022762139638\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-104.42758798599243\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.26743084192276\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.45315100252628\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.35092618068059\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.63889434933662\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.49064411222935\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.70918528735638\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.00302535792191\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.3798683732748\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.36017863452435\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.73848788936934\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.38092384735744\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.8276312276721\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:52.664178175230816\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:46.14054856201013\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.460920161257185\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:48.942053566376366\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:52.167072308560215\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:49.93812059362729\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.010015154878296\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:25.34181830783685\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:45.59870097786188\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:15.665238623817757\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:39.22875255346299\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:43.801294788718224\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-21593.539140224457\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-21824.90452369054\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-3327.042764027913\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3333.3977429072065\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-7187.434129714966\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-21646.740991274517\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:5.114736954371136\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:30.83577791849772\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:8.928735653559372\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:24.217252930005394\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:33.44533999760946\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:54.77717399597169\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.18089090784392\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.85679348309834\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.79919776320457\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.95096740623315\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.77077600856622\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.10173728068669\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.82479256267348\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.93946614364783\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.95684511959553\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.17189527551332\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.038167356203\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.10899423311155\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:60.36790169775485\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:56.164650060236454\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.35364437103272\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:39.43145640194417\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:39.57010559737682\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:46.27197460620665\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.32567168275515\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:27.970019554098446\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:47.331393671532474\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:22.550915802518524\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.25589963297049\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:45.42219818880161\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-274.5523325602214\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-162.35209941864014\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-232.96951929728192\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-589.598134358724\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1182.373496691386\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-16.24158859252929\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:66.07650438944499\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:62.40478515625\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:65.08259243021408\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:64.08743778864543\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.69564755757649\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:64.40623919169109\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.99803103506565\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.27097324530284\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.00124720235665\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.1639864097039\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.01802059511344\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:64.8379152516524\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01413864394029\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.01283125331004\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.06002829720576\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.02966706951459\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.025738440454\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:64.99533424774806\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:57.19333418955406\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.30392228066921\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:57.81782786051433\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:59.01741323371728\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:59.48859785683454\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:63.63228090107441\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:23.190898771087333\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:39.14774768054485\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:12.142071053385738\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:47.57609342535337\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:25.128674979011222\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:47.46318514148394\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:65.01434485117595\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.75696007410686\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.03038128217061\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.0073273976644\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:64.99790032704671\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:64.9874750773112\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01386165618896\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01321911811829\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.014089345932\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01364323000114\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01374423503876\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01353581746419\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.00175351897876\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01360607643922\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:64.995822062095\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.0122342010339\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01492450634639\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.00885042051475\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360015012324\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01361109316349\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360267400742\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360436280568\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01361387471358\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360088586807\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.99441834787527\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.056395791471\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.96477130800486\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:64.31013936797778\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.97949153184891\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.02297850946586\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.71552042663097\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:49.72369047502677\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:39.88617369905114\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.68278182360034\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:41.99471961706877\n",
            "Layers: 1, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:36.441194365421936\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-201389.05925750732\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-193417.1727339427\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-59556.726191838585\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-66777.51484711966\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-145373.023668925\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-6196.499897638957\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-84.53179091215132\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-74.81849124034245\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-67.8779168923696\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-223.1524713834127\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1096.8861434857051\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1874.7859390576682\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:58.04081377883752\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.377089415987335\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:50.956316559265055\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:58.84793616831303\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:59.60183887432019\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:44.828006476163864\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:44.24557973941167\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.511555954813964\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:48.811701933542885\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:50.19967937221131\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:29.6023390442133\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:21.303279449542366\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:46.574016703913614\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:32.60080088550846\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:39.29377906024456\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:45.98594168821971\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:31.73671260476112\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:42.09621326376995\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:48.44597493608792\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:56.63009575257698\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:44.3245806141446\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:29.8902902007103\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:44.43404467155536\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.45194456974665\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-86318.74869664511\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-119423.434715271\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-24864.690074920654\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-78905.08242925008\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-76986.29878997803\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-56273.45682144165\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-200.01869599024454\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-649.7815736134847\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-586.8411563833555\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-342.1649280190468\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-442.2972798347473\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-685.2724230289459\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:60.29453558226427\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:66.17438313861688\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:64.63850477089484\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:62.76223396261533\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:64.5064677298069\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:65.31412817537785\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:55.38209321598212\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:54.93877183645963\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:58.947603505415216\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.52569072445233\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.61123008280993\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:62.822621123244375\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:49.37409974634648\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:37.9070270061493\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.4717126985391\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:23.55844048162301\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.90239603072404\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:54.13351309796175\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:45.548691116273396\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:47.10124560942253\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:34.40704457461834\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:38.826150835181274\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:44.6202174325784\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:45.22341221570969\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-9980.656855901083\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-5062.686087290446\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-34598.04757436116\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-27132.114000320435\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-7705.463609695434\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-4957.2612651189165\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-118.82922371228534\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-106.12788299719492\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-33.93849710623422\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-655.967606107394\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-339.52895959218347\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-83.63663733005524\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.16559723764658\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.89417808751266\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.07447293400764\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:66.13809291273355\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:65.98772058884303\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.78392538925011\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.86011603474617\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.51591627299786\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.86186390121777\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:63.47829471031825\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:64.78161925449967\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.29031246900558\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:49.08289775252342\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.35156909003853\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:47.021656806270286\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.88670103748639\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.79540477196376\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.64801785598199\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:62.32410973558824\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:33.748248939712845\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:40.047276504337795\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:47.11742437134186\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:48.674994061390564\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:44.29045899771153\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-6737.754936218262\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-3086.29119237264\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6684.173234303792\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-16023.177261352537\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-7385.970589319865\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4420.496724446614\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:51.18024716774623\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:60.15057682991027\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:43.775824308395386\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:5.841714143753052\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:15.423921023805931\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:43.69960270822049\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.01927132407825\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.5498372366031\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.3593688706557\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.28368736306827\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.2286297827959\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.6541811277469\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.06517601509888\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.82014899452527\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.88250737388928\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.95689590771994\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.95986841619015\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.02483763421576\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.520039478937775\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:46.004141072432205\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.41511582831542\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:56.726601595679924\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:52.57193760946392\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:59.02535843507697\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:9.792170276244484\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:41.547300492723785\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.01772351935505\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.672105913981795\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:47.71273016929627\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.05695813645919\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-339.6685791015625\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-279.88081455230713\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-458.59820763270056\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-242.43569294611612\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-329.9958165486654\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-70.87442398071289\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:64.30373748143514\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:65.08844996492068\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:63.711887200673424\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:65.03734429677328\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.79689995447795\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:64.75008805592854\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.99601190288861\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.02878310779731\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.05188052852948\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.02102116743724\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.11411182582378\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.03123785058658\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:64.97403983026743\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.0014254823327\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.06513926821451\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.01867902775605\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.00759301086268\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.02784848213196\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.49455795188746\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:56.729031981279455\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:60.378731091817215\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:47.58870040376981\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.77607811490695\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.31008675694466\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.75306456287702\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.7994770805041\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.706010000159345\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.69114046295485\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:43.50752325107654\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:51.478310814127326\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:64.9510637919108\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.01617431640625\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:64.98830159505209\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.02729892730713\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:65.01016934712727\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.0357468922933\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01353532075882\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01347263654074\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.01386195421219\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01368641853333\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01461344460647\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01309603452682\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.02268639703593\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01360485951106\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.08233070373535\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01379338403544\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:64.9978090574344\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.0137769182523\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01358812053999\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360589638352\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01358973483245\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01361039777596\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01360924914479\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360108455022\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.92679934948683\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.50294678409894\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.89193519887824\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01882156978051\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01336596906185\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:64.97875194996595\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.53225989763935\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:47.40030836313963\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.297424880166844\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:49.032985381782055\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:49.99014588383337\n",
            "Layers: 1, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:40.838904678821564\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-5265.050400098165\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-110650.44301986696\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-6092.052330970764\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-132529.91243998212\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-102278.0673789978\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-63287.852919896446\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-94.46827317277591\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-79.8543287316958\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-22.680531342824306\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-90.62015910943349\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-373.1504283348719\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1736.9032392899196\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:41.62346807618936\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:57.668674510593206\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:52.69002772867679\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:41.37260439495246\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:50.90066205089291\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:55.45341143384576\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:40.62352476020654\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:37.183878446618714\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:30.533738862723116\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:30.844101508458454\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:40.02095167835553\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.88027122616767\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:41.50584450612465\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:37.25479684459666\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:24.747698567807674\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:35.658597250779465\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:27.28317039708297\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:34.41566282262405\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:44.77780676757296\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:27.55407022933165\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:21.379247941076752\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:34.25794823095203\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:12.839313820004461\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:43.16463872790337\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-88667.733669281\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-66988.62467447917\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-71218.73714447021\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-77266.3690630595\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-19368.635851542156\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-81604.01948293051\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-302.20804532368976\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-428.52657457192737\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-430.5387364327908\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-694.4456201791763\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-309.09845034281415\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-579.8009972771009\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.13620981077352\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:61.85590515534083\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:64.16479274630547\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:64.8556792239348\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:63.19488748908043\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:65.14256874720256\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.39253163586061\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:61.4359587803483\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.83434555431207\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.88650094966093\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.65247134491801\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:40.025849441687264\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.57593520979087\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.42055770258109\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:35.65639425069094\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.57385501265526\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:26.256477658947308\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:32.06016502032677\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:27.703509554266926\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:49.831877648830414\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:36.48090509387354\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:46.38498495022456\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:48.60435843467712\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:17.035849938790005\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-36863.53963851929\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-7794.931678771973\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-23674.230422973633\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-71775.04314104716\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-5018.288145065308\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-13957.307078043621\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-260.3562662998835\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-171.68860753377277\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-41.891434192657464\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-213.35093915462494\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-58.50357075532278\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-173.68634839852652\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.37826581299305\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.00796363999446\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.14919678370158\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.33623636762302\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.61649052798748\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.7670720765988\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:63.826903104782104\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.32975068688393\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:63.182077358166374\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.88859420021376\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:63.59663826723894\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.73038546989362\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:45.307940753797695\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.05406904220581\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:30.943188865979508\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:51.270667451123394\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:59.83975987881423\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:46.951452742020294\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:62.87018410861492\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:29.47757732123136\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:27.6764840260148\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:46.0371091713508\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:37.572186210503176\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:19.994087728361286\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-9526.000000635782\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5686.2788645426435\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4661.806818644206\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-736.9848410288492\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-5450.840975443522\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-5035.144583384195\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:31.44723256429036\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-1.8415749073028564\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:36.930342515309654\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:49.64177827040355\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:29.164169232050575\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:45.5266265074412\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.14770237108071\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.45659179488818\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.92418060700098\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.23687782386939\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.9480433265368\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.20199663937092\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.06411732484897\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.87384289503098\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.02071895947059\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.77097743501265\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.9625958998998\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.27543110152085\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:59.880615075429276\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:49.94821272790432\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:22.266579444209732\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.07419719795385\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.79332122641305\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.99562368790309\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:48.24726488441229\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:24.76248661677043\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:46.744876081744835\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:32.80497185885907\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:38.73836035529773\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:45.92590115343531\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-414.46545124053955\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-450.2568848927816\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1186.8975480397544\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-226.81569417317706\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-461.0981671015422\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-5.864127477010084\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-250.6649438540141\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:65.45334180196126\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:64.40499305725098\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:64.82922156651814\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:63.99908661842346\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:64.47511514027913\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.8552767187357\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.01914908488591\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.00491999089718\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.00575972100098\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:64.81115333735943\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.00043796996276\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.03471636523803\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.00190778325002\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.03777438541874\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.03601063042879\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.02230159938335\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.02282066891591\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.56218822300434\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.52741163720688\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:62.527547404170036\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:59.111134546498455\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:63.676376678049564\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:63.745666593313224\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:46.298847434421376\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:32.48191431164742\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:51.7954042305549\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:25.620115200678505\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:18.984422336022057\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:33.206296836336456\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-356.55397574106854\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.9910831451416\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.0111198425293\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-32.39342371622722\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:65.04142761230469\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.04451115926106\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01422782739003\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01347571611404\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.01408656438193\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.0140647093455\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:56.31141781806945\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.013480981191\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.0610926002264\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.00885871549447\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.0176910807689\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.0135978559653\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.00838004052639\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01387350261211\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360293477774\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360730268061\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01359796772401\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360796391964\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01359359671672\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360535621643\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:64.56072036021699\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.08361272513866\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01305170357227\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:64.38139832268159\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.66560527682304\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:64.44169085472822\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.86414467295011\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:42.44585462535421\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:35.258088860039905\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:30.911650533477463\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:58.044625545541436\n",
            "Layers: 1, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:24.14436536530654\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-61697.43978500367\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-194776.1611366272\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-210037.48633702594\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-130627.61634667715\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-109797.25167592366\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-48392.914447784424\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-102.3543816804886\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-965.5728948116301\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-144.8722199598948\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1037.7490931749344\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1094.1847353180249\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1391.9595843553543\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:52.37123786161344\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.446153131624065\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.75079463919004\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:60.29906754692396\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:43.96942085276048\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.656124045451485\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:56.0183408856392\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:48.4876399487257\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:34.90328796207904\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:47.783375680446625\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:48.83694312224785\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.69003261625767\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:47.53223188842336\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:47.14469561353326\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:40.47715026885271\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.794307212034866\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:30.1822941750288\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.9267071634531\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.733911342918866\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.12741380433242\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:37.58908800159892\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:51.08358626564345\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.62910411258539\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:51.64156501491865\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-109664.88326549529\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-94489.56235249838\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-107369.84479268391\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-105605.05300521849\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-73683.6865822474\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-86822.12958494823\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-42.642951210339874\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-574.4794998566309\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-239.29134597380957\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-757.7697463830311\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-327.47710675001144\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-226.1937279502551\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.99738280971845\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:64.13453981280327\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:64.86897439385454\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:60.471531823277466\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:63.671958943208054\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:63.58511226872603\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:60.20171485841275\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:61.29313573241234\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:62.77508397897085\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:57.36972289780775\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:66.23461360111833\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:60.40767862771948\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:32.30913167198499\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:50.076410292337336\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:41.390754828850426\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:41.78764467438062\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:57.0950074121356\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:40.48555086056391\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.09524675210318\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:41.154411385456726\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:38.78696003307899\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:43.89305076251427\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:37.59045450637738\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:41.18501488119364\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-21586.596571604412\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-21586.518710454304\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-29324.013376235962\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-21160.57143529256\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3133.169150352478\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-8574.887288411459\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-485.01480996608734\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-131.19141181310016\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-100.30245651801425\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-204.508638381958\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-340.1257446408271\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-204.36638196309408\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.17256409923236\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.76892380913098\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.397463341554\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:65.21938366194566\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:65.19649490714073\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.1045843710502\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:61.67848409463962\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.26026135931413\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.33675552345812\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.69057534138362\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:63.945097240308925\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.56370112175742\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:46.49862065911293\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:60.746813093622535\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:61.356937140226364\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:44.767027770479515\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.55725028614202\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:33.65010244150957\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.8448164810737\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:19.403251782059673\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.634115181552865\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:48.11480360726515\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:48.76158793146411\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:40.00070220480363\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-4908.050944010417\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-16907.06166108449\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6365.465656916301\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-6243.267475763957\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1375.141577720642\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-22632.84506559372\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:3.1676324208577467\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:36.5956400334835\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:33.84127676486969\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:21.583905617396038\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-11.505982875823983\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:26.030069589614868\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.44223960240683\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.10020323097706\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.04345250626405\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.1400585224231\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.19456932942073\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.92206536233425\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.92287863666813\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.02923655013244\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.38651439050834\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.12286636978388\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.81235546370347\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.82028729903202\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.82134580115476\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:55.70925365512569\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:60.47165503104528\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.53672319961092\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.901952532430485\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:60.492074949045985\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:40.446962652107075\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:55.838568856318794\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:40.31928318242232\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:39.8104394475619\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:36.55948154628277\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:45.64415539304415\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-418.94597371419275\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-361.4173698425293\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-384.7251566251119\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-236.16331736246744\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-382.01741536458337\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-233.2429218292236\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:65.18934637308121\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:65.27586857477824\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:25.64472238222758\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:64.68848705291748\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.6888558069865\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:65.86116711298624\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.13686008751392\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.0224456936121\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.2139812707901\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:64.89561262230079\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.2008119225502\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.21831460297108\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.02856142818928\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.00612323482831\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.01461632549763\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.02353754515448\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.03105870137612\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.02024985849857\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:62.65139068166414\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.4518857349952\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.47283087919156\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.57200830181439\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:63.19950689872106\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.84687861055136\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.48842195173105\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:47.47930563054978\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:49.82559918115537\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:38.81891569743554\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:30.933940584460895\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:42.42998012651999\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-16.784702936808273\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.02471923828125\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:27.966521581013993\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.020911693573\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:65.01689275105794\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-16.058727900187165\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01339628050724\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.23051659266154\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.01376847426097\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.11768341064453\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01359184583029\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.0149651368459\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.04627111057441\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01491119464238\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.00172170499961\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.00996520121892\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.00946642210086\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01360324521859\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360336939494\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01361007491748\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01358897735675\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360662203903\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01360330730677\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360097279152\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.04977968831858\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.02233321468036\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.83304192622504\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01428780456384\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.9674953520298\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:64.71285163114469\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.396851271390915\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.889151329795524\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:42.51714882751306\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.32615969578425\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:33.19907672082384\n",
            "Layers: 1, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:52.02724256863196\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-256602.68280029294\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-104996.46382808685\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-186752.65427271524\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-46068.49269390106\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-97642.65754381816\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-245815.73041915894\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-480.83808501561487\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1324.845469991366\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2364.108073115349\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-953.886127571265\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-360.6255644559861\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-116.65944258371988\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:37.98503444840511\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:52.76758152991533\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:48.32819394767285\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:46.29097502678633\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:16.674841158092025\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.92848396797975\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.97753687699635\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:33.358303786565855\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:44.50792689497273\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:43.08394677937031\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:61.26975756138563\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:36.8427932014068\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:42.51010718444983\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:26.21406119316816\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:32.87967531631391\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:41.40536624317368\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:43.26544431348641\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:46.413433154424034\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:31.76292588313421\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.62246803877254\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:39.51169803738595\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.310166507959366\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:43.69947041074435\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:63.215718915065125\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-149037.30653762817\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-224377.14373906452\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-219896.08074188232\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-12808.742949167887\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-281990.8647759755\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-9899.7509654363\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2007.3279160261154\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1102.112403512001\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1106.5601618091266\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-974.9209585785867\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1317.6034140586853\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-582.9802646239599\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:60.220731745163604\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:63.147685006260865\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:61.36261527736981\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:63.74148783584436\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:61.4025021592776\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:63.10194763044517\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.17863841230671\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:64.64176272352536\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.93501881835982\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:61.82800332084298\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.92114278177421\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:63.1598292166988\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:37.892576232552535\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.218194896976144\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.28354266410073\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.40608304490647\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:35.04782130320867\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.72221640497446\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:60.8159621929129\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:42.320898597439125\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:46.32560962617087\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.30726761122544\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:42.921773443619415\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:41.78981751203536\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-67754.75862503052\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-33223.04129282633\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-70452.27177937826\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-127941.90129796664\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-124219.95471954347\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-7989.87938563029\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-720.0659545262655\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-186.72624568144482\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-228.79651387532553\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-676.6582481066386\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-35.903219381968185\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-448.80866348743444\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.0732647255063\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.21945512294769\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.25561053057511\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.69031694034734\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:65.61518609523773\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.30583118398985\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.63681742548943\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.9914410461982\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.10053347547849\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:63.53954955935478\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:64.15172467629115\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.08449378733833\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.386917178829506\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:50.96244752407074\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:57.09826859335105\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:58.86348758048068\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:59.35897742708525\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.43962555130323\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.09617475171884\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:42.43754753222068\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:41.70411392425497\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.51108809063831\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:42.96347085386515\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:35.0792758911848\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-37812.33658154806\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-37935.787580808006\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-28530.73249816895\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-33009.19724941254\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-12116.830078760784\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-10540.087877909342\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-22.850215435028076\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-55.67210932572684\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-103.12309265136719\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-4.128490885098768\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-18.4068500995636\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:10.176909665266676\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.55438082416852\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.04511137803395\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.113565325737\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.95794266462326\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.06798113385837\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.8139518747727\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.92740478366613\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.14020343621571\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.76092480123043\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.69204084482044\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.00368859618902\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.97671846300364\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:59.59424211168274\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:56.08107830553005\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:60.092927341659866\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:61.3987352574865\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:62.072813808918006\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:61.340682332714394\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:24.506000926097236\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:46.32145016143719\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:22.88907467077176\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:47.290891520679004\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:43.57559723158677\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:41.37272961437702\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-501.4577356974284\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-792.565975189209\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-195.1544698079427\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-545.180360476176\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-528.4848626454672\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-332.61772155761713\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:65.02480109532674\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:61.364448865254715\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:57.15016047159831\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:60.20364088316759\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:38.83754869302114\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:60.64130837718646\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.01181311905384\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:64.99436085422833\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.02514508863291\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.01662542422612\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.50854712724686\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.60242799421152\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01656568298738\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.03115216890971\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.01357314487298\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.0099768737952\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.01276170214017\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.00675556560358\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.86897864689429\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:63.90628659476836\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.13391685734193\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:60.29488213981191\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.810258615762\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:58.53740862260261\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.574570216238506\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:62.178812225659684\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:50.142885819077485\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.101773579915374\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.31568529953559\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:52.72026572376489\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:64.99473571777344\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.64994112650552\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.04661560058594\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.03777503967285\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:64.86006100972493\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.2920373280843\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01322905222575\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01336415608723\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.0136415163676\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.0132554769516\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01378059387207\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:61.54638156294823\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:64.96517731497686\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:64.8221185306708\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01874414583047\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01359686255455\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.04268544415632\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01356817781925\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01359981795152\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360489676395\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.0136083488663\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360920568307\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.0135990480582\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360638688007\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01364295681317\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01334745436907\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01360920568307\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01348692923784\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.0136024132371\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01361522823572\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.6002860168616\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.189212578038365\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.88448246692618\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.21701133499543\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:52.871114828934274\n",
            "Layers: 1, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:50.20200093587239\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-203919.70701058707\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-297650.2956199646\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-8388.717002868652\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-324081.0603650411\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-57244.61862564088\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-197227.89823532104\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2036.573895116647\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1254.1572552919388\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-550.7723924517632\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2455.9792963663735\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-865.7384959856669\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2535.1826314131417\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:24.361801991860077\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:58.82342512408892\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:42.831244698415205\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:61.778483179708324\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:32.424619868397706\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:52.23478977878888\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:58.103906220446035\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:51.263259686529636\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:30.659509276350338\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:16.275065243244168\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:48.7109583367904\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.762010097503655\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:45.7824778681\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:44.032620626191296\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:41.53053847452005\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:15.48567640284697\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:45.52083754291137\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:52.089121093352645\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:36.35486400375763\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:34.89478142311175\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.43938101579746\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:23.379526523252323\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:58.78312899420659\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:44.181666622559234\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-66827.11243947347\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-12161.375478108725\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-210853.09150695804\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-152545.04247029623\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-201789.4425201416\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-223914.7353553772\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-861.1539056897163\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1716.9875262180963\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1332.2598713636398\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1461.6368693113327\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1841.2985610961914\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2689.662943283717\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:63.13756693154573\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:65.09028051048517\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:64.75781078139941\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:57.38060221076011\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:61.925349657734245\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:62.6991368830204\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.38554894427459\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.512325212359436\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:66.02873931328456\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.96809241672356\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.17795643210411\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:62.72192694246769\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.31349191566308\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:41.147980367143944\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:47.9622853298982\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:43.10503505170345\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:45.48065785008172\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:40.57727353026469\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:37.037260429933674\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:34.83664439370234\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.476802967488766\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:56.822346995274216\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:38.63054217149814\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:48.85023045043151\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-95347.53360271454\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-35720.46295483907\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-24363.621848424275\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1995.9218597412112\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-30078.061478932697\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-45034.84544118246\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-95.16753236452737\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-603.2070823510488\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-359.6090948581695\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-503.2481340567271\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-262.713893254598\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-307.518310546875\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.97903468708198\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.72743820647399\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.31599531571071\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.03959934910138\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:65.72336145987113\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.21208528180917\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.39873650670052\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.85932602236669\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.03972051975629\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.18710413699348\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.354408317556\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.565507384638\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:60.30962647249301\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:59.43886399269104\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.375833312670395\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:46.36155504733323\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:47.8104688351353\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.7711561669906\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.04400846982995\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:46.68962517132361\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:50.045677547653526\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:39.392565873761974\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:18.47134534269571\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:29.73180584609508\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-36938.32699139913\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-11155.30650138855\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-11675.53947130839\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-28916.464131673176\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-37351.07813835144\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-9607.368783950806\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-27.759300470352176\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-27.70196785529455\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-152.45792031288147\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-153.9574058850606\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:22.341941595077518\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-26.136307319005336\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.61666618784268\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.1677401860555\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.84587130447228\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.79359318812688\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.87476622064908\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.98648934066296\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.02409877876441\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.23392703384161\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.7752108797431\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.95743439222376\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.07175137599309\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.23981822033723\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:59.73940330247085\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:63.30351376906037\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:62.85969498256843\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:47.36111633479595\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:62.12987148513396\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:58.31594476476312\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:32.09368955343962\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.32349647581578\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:55.12356414149204\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:26.458106612165764\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:33.951698876917355\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.343982112904385\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-376.56141281127924\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-530.7253583272299\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-234.0768559773763\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-993.2605489095051\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-8114.805661837259\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-190.88093121846518\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:60.35821199417114\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:64.70802913109462\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:61.403916478157036\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:56.062743154664844\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:63.64678919315339\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:64.95690027872722\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.03235056996346\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.33841247359912\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.01079012950261\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.035846332709\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.01792137821516\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.04826456308365\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.03771319364509\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.04221577197313\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.02337999021013\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.01567251980305\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.00083514178793\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:64.99740798026323\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.00311449170113\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.08159876863162\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:61.31703337033589\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.00828449924786\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.93614892164867\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:59.79239656900366\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:44.20991147557894\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.92662476996581\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.91048551350833\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.823424377168216\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.34114187583327\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.622732151299715\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:64.96805191040039\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.94804382324219\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.04811604817708\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.05285263061523\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:28.396542867024742\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.0277328491211\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.0138008594513\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01348813374837\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.0133206943671\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01383622487387\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01309275627136\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.0139953692754\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.01877834399541\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01447188357513\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01361067096391\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01346463958421\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01531844337781\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.2290765196085\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01359949819744\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01359672596057\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01359810431798\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01359499370058\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01360406478246\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01359728475411\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01366867373387\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01368227104346\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01365723709264\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01551342507203\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01393835991621\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01359184583029\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:43.01896497607232\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.76284842193127\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.45863161732754\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:62.027791067957885\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:50.89024008562168\n",
            "Layers: 1, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:62.79254153991739\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-244949.25799687704\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-249785.90672810873\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-329335.0468468666\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-397436.8377176921\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-127020.5415725708\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-132520.93841552734\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-338.63419731458026\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1554.294015467167\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-212.03627149264017\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1176.1029543479283\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1049.1944042841594\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-524.812064965566\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:42.21516937017441\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:60.12476851542791\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:49.24803880353769\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:52.91213163485129\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:41.9219412902991\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:55.940460301935666\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:32.586516477167606\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:43.028373469909035\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:46.28863881031672\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:42.864807316412524\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:49.496762392421566\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:60.52770058314005\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:35.62127127001683\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:29.537114923199013\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:39.06475656976303\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.19783992071947\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:45.775875349839524\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:36.225830093026154\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:37.02965810894966\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:42.538779744257525\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:40.330978110432625\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:44.66462578624487\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:33.22212112446626\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:47.320895151545606\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-139605.90895970663\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-60751.697519620255\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-152772.6605097453\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-59944.5115407308\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-176296.06940905252\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-56226.748781204216\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1364.7766879200935\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1312.9464944203696\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-593.5505682229996\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-639.9694821238518\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-598.9631520708402\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-956.1361043155193\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:63.7983554850022\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:63.527319828669235\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:62.430257722735405\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:62.683225522438676\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:61.76108936468761\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.489911153912544\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.45497170339027\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.82488768547774\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.50186096131802\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:63.43433293203513\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.63077234725158\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.9649778008461\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:39.63027416417996\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:38.613667488098145\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:47.21978813409805\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:29.225618044535317\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:30.91840645919244\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.5884967794021\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.669510294993714\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:34.84451975673437\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:54.7833547120293\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:43.78304226013522\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:25.404031897584602\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.372866819302246\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-94183.39831352234\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-6750.2916622161865\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-4837.647457122803\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-44846.96160634359\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-30300.08326530457\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-11399.969387054443\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-579.6498235066732\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-415.8365448315938\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-825.335863530636\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-535.8797021706899\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-371.837746500969\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-517.6491355895996\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.00745626787345\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.55378389855227\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.49487886329493\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.1932393486301\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.4017340739568\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.57474779585996\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.16370458900928\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.69316451748213\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.44707655906677\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.39618601401646\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.1717335358262\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.89508197953305\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:59.93817398945491\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:58.67814189443985\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:50.08470818400384\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:51.41575155779719\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:61.115630430479854\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:51.11780288318792\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:45.254599153995514\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:57.74250239133835\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.65878421937427\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:48.612235287825264\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:41.051703581276044\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:36.56529570619266\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-25222.972167332966\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-6060.707200368245\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-17267.765159606934\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-8703.177286783854\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2668.4493923187256\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-9079.992287953695\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-17.74752000967661\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:8.222650885581972\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:17.475292285283405\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-169.7857501109441\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:28.554318149884537\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:19.197432597478226\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.17007338503997\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.09239388008912\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.14627618094285\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.96715209384759\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.27999691665173\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.8052453994751\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.12803388138613\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.99076887965202\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.40506829507649\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.89957954734564\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.87243257462978\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.01742164293924\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:63.81335102021695\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:63.512487659851715\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:64.56635133673747\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.55232113599777\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:62.3866417631507\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.04792715112369\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:46.67839717119933\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:26.16312337728838\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:39.26574806372325\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:48.82638263205688\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:24.628928837676845\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:43.29436541845401\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-8704.557439486185\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3506.8233776092525\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-616.4985148111979\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-449.74176963170373\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-65786.11615498862\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-3800.840708414714\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:65.31027634938557\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:63.10393810272217\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:63.971981604894005\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:64.54246819019318\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:65.78951676686604\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:64.92123246192932\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.00072511533897\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.05906792978446\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:64.97273455063501\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.29156275093555\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.03032351533572\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:64.80130886038144\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01427340010801\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.01156736165285\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.02293119827907\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.03772682199876\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.06990065177281\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.01314426461855\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.0468369325002\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:63.592307257155575\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.26745084983607\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.635413743555546\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.50378496199846\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.9763059973096\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:38.56181552012762\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:58.78542559842268\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:50.85529732207456\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:47.320438704142965\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:47.82727692897121\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.19501946369807\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:64.89509582519531\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.9859078725179\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.00021616617839\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-1006.3901964823405\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:64.99047597249348\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:44.552507400512695\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01354535420735\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01358389854431\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:64.40582036972046\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01416365305583\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01041650772095\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01415530840555\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.01365306476752\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01360756655534\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01151112218697\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01361610988776\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01360108455022\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01352379719417\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01359511166811\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360408961773\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.0135967011253\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360549281041\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.0136096868664\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360140740871\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01361073305209\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01368835568428\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01360302170119\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01364313066006\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01358562459548\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01336768269539\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.290505024294056\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:39.985260503987476\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:47.59497595795741\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:45.77804206560055\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.511811217914016\n",
            "Layers: 1, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:40.080275697012745\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-268706.25995635986\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-118470.72057723999\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-211852.47585296628\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-128432.18891779582\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-202602.57479349774\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-243849.85572814938\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-189.68773106733957\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1322.9574592908223\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1068.9108726382256\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-395.6851803263029\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-399.4951816399892\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-904.2652710278828\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:15.85629004985094\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:51.651865119735405\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:49.19035909076531\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:44.09714029481013\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:47.04958046476047\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:58.63966638843219\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:43.996468521654606\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:25.085055145124592\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:50.256243751694754\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:42.316390772660576\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:49.85831974695126\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:40.46377825240294\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:55.41605222970247\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:38.90507354090611\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:42.40084044014414\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:34.15763672441244\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:32.14629597961902\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:44.87322708591819\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:52.5585176392148\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:22.541654904683426\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.27380344520012\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:54.28901148339113\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:48.55951651930809\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.567079869409405\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-58088.41294606526\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-163208.51758321124\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-209115.12277603152\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-55546.54241482417\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-208958.05943806967\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-151035.59731801352\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-687.6837237675985\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1262.5745891531308\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2189.4915630420046\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-491.51703268289566\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-554.5239086945852\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1342.3726018269856\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:63.52433942258357\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:62.38391903539499\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:63.55016435186068\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:61.689071605602905\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:66.30818288773298\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.21744538346927\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.863697536289685\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.22918450459838\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.31418177982171\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:59.117750289539494\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.87250506567459\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:65.25801301002502\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.5203443467617\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:50.951710616548866\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:61.485344655811794\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:45.23064572364092\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:46.32136967033148\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:49.30701161424319\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:38.61616395413876\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.91702869286139\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:43.06316820283731\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.11305875579516\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:34.585374941428505\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:33.3443085476756\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-27189.47683334351\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-106804.76000150044\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-13711.002248128256\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-17745.96546967824\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-33028.874435424805\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-35572.627058029175\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1032.5373508036137\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-252.60896225770315\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-377.6891672611237\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-484.9737074971199\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-311.6584360599518\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-304.17031606038415\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.57179447015126\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.59024771054585\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.94883007307848\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:65.44600260754426\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.1664631664753\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.10752153893311\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:63.76529638965924\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:63.9930255835255\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.26711461196344\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.31137647728124\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:63.85271275105575\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.16201642962794\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:51.985476737221084\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:49.18165070315202\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:42.22401916359861\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:60.59080405781667\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:62.04667219271263\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.13412047425905\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:34.86895648141702\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:49.73199709008137\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:50.51617139329513\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:32.57968629399935\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:47.12096620816737\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:49.62246341009935\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-4608.912946383159\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-46489.8367635409\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-8736.496130625408\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-13412.820974985758\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-24683.793544769287\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-35910.345718860626\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-74.07827496528625\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:4.495595097541805\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:18.770916461944577\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-101.23219807942706\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-26.656553347905486\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-68.68820046385129\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.63728912423055\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.8895546545585\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.23765238622825\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.86885227262974\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.34278843303521\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.83769454061985\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.93344770123561\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.92810973276694\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.65972736555462\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.09646902481715\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.95741942276557\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.07385243972142\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:56.39184847474098\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:63.776037519176796\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:61.48036463186145\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:47.03373142828544\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.98109194387993\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:59.79501743490497\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.84826053430637\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:48.27506666382154\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:37.85377023120721\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:38.91405170162518\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:56.252926476299756\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:48.10026186207931\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-379.83612696329754\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3074.4427831967673\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-740.0785446166992\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-668.5576756795247\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-720.5204264322917\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-82.90883382161458\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:64.91664330164592\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:66.14240348339081\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:63.84733994801839\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:64.84219551086426\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-132.34575907389322\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:65.48270021875699\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.99974608421326\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.0156376014153\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:64.99685523410639\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.01765857140222\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.03189166386922\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.00646398713191\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.00977497547865\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.01444317400455\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.0193474938472\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.02669704457125\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.00406432896852\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.03296288351218\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:63.28611299395561\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:63.70783692846695\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.24933791160583\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.3594538172086\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:58.60864628106356\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.79447190960248\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.00617953638236\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:33.73827820022901\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:60.0969419380029\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:34.340181574225426\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:41.74039719005426\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.70992940167586\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:65.04464467366536\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.99006907145181\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-462.20712343851727\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:64.99348322550456\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:65.1581319173177\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-525.739351908366\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01423279444376\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.083867435654\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.01452133059502\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01395066579182\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01377741495769\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01340627670288\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.01325517892838\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:64.96703709165254\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.0136037915945\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01360513269901\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01334319512048\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01354264716308\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360007251303\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360645207266\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.0136064986388\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01359583809972\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01360714435577\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01361446455121\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01952190262577\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01361276954412\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01400156567495\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01362120111783\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.0136278453283\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.0138442715009\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:41.34607555965582\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.37741806358098\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:38.21863384296497\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:58.278805911540985\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:47.02475072816015\n",
            "Layers: 1, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:60.127629786729806\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-264054.8005898794\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-317358.26725006104\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-11979.187173843384\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-72561.04468663533\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-297258.32290649414\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-270139.9122238159\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-978.1549363334973\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-517.572255730629\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2606.654962102572\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2709.9984961748123\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-251.5836188197136\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-4524.255448977153\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:30.029499431451157\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:48.08565478771924\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:8.301517162472006\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:21.69173041979472\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:18.58649668594201\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-10.484060887247315\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:48.353685569018126\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:48.35179733733336\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.11735260734955\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:50.534619080523655\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:40.19820246845484\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.3971759279569\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:47.18459997947018\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:40.3604231774807\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:50.743773877620704\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:47.787869814783335\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:43.100593400498234\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:31.323541998863224\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.04744055122137\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:47.65390619635582\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:45.72115957736968\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:41.85582872480153\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.90306843817234\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:31.480445166428883\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-97847.69401550293\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-59135.42071024577\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-41975.09790579478\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-222736.29430294037\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-450436.44486745197\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-251232.41505940756\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-585.3474123279253\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2938.092363278071\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1754.0135303139684\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-3120.4656722148256\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1369.0093030532203\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1527.946974436442\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:47.21492346376181\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:56.795249469578266\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:52.10623636841773\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:51.8424728512764\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:54.47276324033737\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:54.477372926970325\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:62.50071304539839\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:64.15844182173412\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:63.32379485170046\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.45690289636453\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.61851449062426\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:63.38823905835549\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:50.932061212758214\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:44.16416617731254\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.56221688911319\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:55.69517415016889\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:59.60746727883816\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:46.58227793872356\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:50.48417007550597\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:47.10033728430668\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.344648883522794\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.19924925764401\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:41.28850990285476\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:32.93299715965986\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-59940.757675170906\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-97206.51750564575\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-36431.74518903097\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-143757.3000272115\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-273387.0135688782\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-12735.078980127972\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1440.4505972067516\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1854.0685464441776\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1265.238127509753\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-873.1579518318176\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-687.5013546148936\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-633.3791415890058\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:63.59292094906171\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:67.00334104398887\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.93085174759229\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:65.26636415471634\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:63.336921359101936\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.01329022149245\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.91916324943304\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.72227853039901\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:63.86225846285621\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.99537202219167\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.06103022334476\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.67430237680674\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:60.4805742080013\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:59.99154444783926\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:59.87587098032237\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:62.802843997875854\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:62.17213541269302\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.58255893985431\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:45.010636492321886\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:44.536937506248556\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.79140166441599\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:40.820072405040264\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:54.1054385031263\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:23.0052683626612\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-6156.050758361816\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-26335.26580810547\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-24021.982186635334\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-27913.889325459797\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-83939.4534142812\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-36987.030560175575\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-163.78758629163107\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-93.03787767887115\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-151.8230458100637\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-278.72440973917645\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-455.75493295987445\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-263.0583081642787\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.62801866233349\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.16234241425991\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.58614078660806\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.09207670887311\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.50978521505992\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.00707815090816\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.72378448738407\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.04484531780084\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.19585814016561\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.9153373700877\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.9433576874435\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.1936211809516\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:63.91819306959709\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.78400195638339\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:63.6596783498923\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.59797841807206\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:65.64939236889282\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:64.49263374010722\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.06434720009565\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:40.64852688461542\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.29627009977897\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:51.490317496160664\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:45.709366649389274\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:49.37718562781811\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-710.5724302927653\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1965.7773590087893\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-23319.081948598225\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-722.6024055480957\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-19.867045084635414\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-75954.99175389609\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:62.366906901200615\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:67.38241314888\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:56.88257575035095\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-64.4279408454895\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:37.631046970685325\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:55.52543759346008\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.98696061472099\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.04426678021748\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.0422065705061\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.00483512878418\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:64.95343322555225\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:64.97863332430522\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.02130766709647\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.00550561274092\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.01976703604062\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.02179846167564\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.01093990479907\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.01414182285468\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.00974616656701\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.00290087113778\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.97043163826068\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.00825239966312\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.97477047145367\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.96515753368537\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:47.84813198571404\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:46.07810750681286\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:35.571102586885296\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:41.66542695214351\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.05346483240525\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:50.857869616399206\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1299.080546696981\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.85355377197266\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:64.7724978129069\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:64.24719492594402\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-652.4164342880249\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.27222951253255\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:64.85292832056682\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.17637451489766\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:64.99093110362688\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-238.54429403940838\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.02336877087752\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01201073328654\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.07750200728574\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01359323660533\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01360923051834\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01360595226288\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01355638106664\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01227892935276\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360706364115\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360065303743\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360680907965\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01359584430854\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.0136053437988\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360361774762\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01364375154178\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01359797082841\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01361663142839\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01360944161813\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01359602436423\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01360168059666\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:62.165558102230236\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.90498250722885\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:59.46303453296423\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.874309885005154\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.05159878979127\n",
            "Layers: 1, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:62.17752179751794\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-259787.64045238495\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-173320.85006713867\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-210844.12508805594\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-53177.81255245209\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-97442.21016565958\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-260225.9565957387\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1050.721318523089\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1501.3196951150896\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-624.4720671574274\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2944.931232134501\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-857.6183864474297\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-3644.2937086025872\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:31.17583067466815\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-16.277249604463574\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:43.002863228321075\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:45.8282205214103\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-9.829799737781286\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:32.26181740562121\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:57.84913282841444\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.73032150790096\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:50.9348306680719\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:56.31601439168056\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:40.69826857497295\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.33363431195418\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:44.085179617007576\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:58.19608915597201\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:32.54926779617866\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.727846408883735\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:46.39578541119893\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:44.523613806813955\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:32.05911438912153\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:37.27927153930069\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:42.41500995432337\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:26.306091733276848\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.51601999253035\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:38.71776412862042\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-239073.21623802185\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-100005.6685256958\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-447392.97414143884\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-191491.71951929727\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-114036.16472880046\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-65258.44404061635\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2130.292608340581\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1031.4568732182186\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2164.112266699473\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-820.3636630376179\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-3660.4972716172533\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3297.353337903817\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:58.07893878469865\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:52.37393575410047\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:50.983548338214554\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:54.55832871297995\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:55.220140144228935\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:58.910704205433525\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.92441228652994\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:66.1691197194159\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:62.36728798598051\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:63.79034620399276\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:65.1678952947259\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:67.58406102657318\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:58.870474472641945\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:59.63343578080335\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:40.582111328840256\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.60031862991552\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:57.93069729271034\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.87795992195606\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:45.62375726799171\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:36.24011989682913\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:38.99476869031787\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:35.36114202812314\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:43.4584313010176\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:42.20926021613801\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-60064.39627329508\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-49107.42571512858\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-191352.52604961395\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-25313.60638300578\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-43500.46683629354\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6049.462718963623\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-650.4059282938639\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1024.1947865486145\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-162.3290761311849\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2042.9624211788177\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1898.223655919234\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1355.098520418008\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:62.961159224311515\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:60.84153418739638\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.04434700806935\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.18239235877991\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.56296560664971\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:67.07477625459433\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.56916896005471\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.36034935216108\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.27017061971128\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.13980045666297\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:63.79717066884041\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:63.78540103634198\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:59.803638520340115\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.46496272459627\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.43815939376751\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:64.77569490671158\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:63.844602325310305\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.63992351541916\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:44.17931443080306\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:48.12033174249033\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:48.9561733789742\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:46.4712106063962\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:39.472972502311066\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:45.84600411355495\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-13076.037565867106\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-21665.56519826253\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-53326.891020933785\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-6380.482921600341\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-73167.79645284018\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3297.7887821197514\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-37.83184190591176\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-24.21403010686238\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-163.05085102717084\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-193.01777919133505\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-115.70238868395487\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-294.1327065229416\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.11167071759701\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.1790852099657\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.95685798426469\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.89914613465469\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.79182389875253\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.59743599096934\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.17445306293666\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.98085516194503\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.98981177496414\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.9768356854717\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.95763138557473\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.94482358607154\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.53238006386285\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.8332904651761\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:60.080426844457776\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.55651404956977\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:64.00172475725412\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:64.09281740585963\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:57.77255587279797\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:49.96833972632885\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:37.79024685422579\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:50.04034423579773\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:35.671838472286865\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:49.117719692488514\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-8501.019821166992\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-545.3495724995931\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-56.350905100504555\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-17409.847208658855\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-3174.0366744995113\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2384.5627721150718\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:60.81772049268086\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-40.64712206522623\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:55.77832221984863\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:58.46017519632976\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:52.49520937601726\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:62.5006602704525\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.08762647708257\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.0181171298027\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.00275306403637\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:64.98149201273918\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.00338799009721\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.00846120218435\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01871751621366\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.01606735090415\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.01382974907756\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.03350333931546\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.03209124008815\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.03112005690734\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.01307987918456\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.67269422486424\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.03015351792176\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.04436107973257\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.03351197733234\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.06142581502597\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:44.42695744956533\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:51.23881113405029\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:59.78947747498751\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:47.71444500734409\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:60.9264362975955\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:49.85004249339302\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1.3224347432454486\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-446.37063821156823\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-232.62683232625326\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.021071434021\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:64.8031997680664\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-53.15673351287842\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01553138097127\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01358032226562\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.00423570473988\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:57.30189641316732\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.0426013271014\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.0122622648875\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.01360836128394\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01362023254235\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01404881477356\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.0087982416153\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01358481744926\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.0136361643672\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360685875018\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360634341836\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360722507039\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360218971968\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.0135936991622\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01359769453605\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01361430933078\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01362390505771\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01354157924652\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01359726612766\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01359732200702\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01358448217313\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:61.4303526468575\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:48.52169112612804\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.12607586430386\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:59.45473045110703\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:48.20936261986692\n",
            "Layers: 1, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:57.374362225333854\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-245028.8455200195\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-112360.8658472697\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-183823.63774617514\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-492386.9323730469\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-155987.71653811136\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-188647.9221089681\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-214.75580086310705\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1153.54039311409\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1225.018780330817\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1842.6463342706363\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1236.5039386351903\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-334.6087110042572\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:4.734514939288303\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:23.234327932198838\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:30.830105158189937\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:17.031280174851414\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-4.281415343284611\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:36.69049772123496\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:59.72786072641612\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.619364144901425\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:58.96520565574368\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:50.34518195626636\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:47.61253143350284\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:40.65545455863079\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:37.93582541247209\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:39.0123185267051\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:48.750372727712\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:48.15757664541403\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:43.113006177203104\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:49.52284473925829\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:47.57839266210795\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:34.06588699668646\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.8603810214748\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:48.33494195714593\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:39.09849055111408\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:42.37377636134625\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-77817.08378632863\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-238933.1978607178\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-398270.8632659912\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-120945.69007873535\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-78966.20126724243\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-310281.4736398061\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2568.2912091414137\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1946.5840073426566\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2842.506187359492\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-4096.951012412707\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-4092.8001626332602\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1997.2068508466084\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:54.404474621017776\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:58.562073707580566\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:42.84228039284547\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:51.61015808582305\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:58.008090704679496\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:55.11424666891496\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.73809266928583\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:62.19900901118914\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.99844541152318\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:63.99717114865779\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:61.87043346464633\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:66.62916783243418\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:47.43714557339748\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:45.02751952037215\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:49.59551327008133\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:58.193954899907105\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.99432064096132\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.87854683523376\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.65982314695914\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:30.735852060218647\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:46.43671070535977\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:42.86097213005026\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:45.21827232092619\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:37.31806812187036\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-191957.54506429037\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-131007.642771403\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-10479.125378926596\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-262019.5736948649\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-43235.58363278707\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-254231.13189697266\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-502.11890260378516\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2086.174111366272\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2301.8728359540305\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2131.2660678227744\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1430.7878762980301\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-307.3734058936437\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.69561185936132\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:62.56716546912988\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.35115964710712\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:64.92514468729496\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:65.23908263693254\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:63.31344779580832\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.33016591022411\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:63.01966837296884\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.36056669801474\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.8399893566966\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:63.7350844219327\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:63.196423556655645\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:65.79595881203811\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:58.44481134787202\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.69395184144378\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.82671398917833\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:62.31993634253741\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:60.071766724189125\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:35.1265822785596\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:29.531487276156742\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:48.89463086922964\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:36.769513400892414\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:45.018713853011526\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:45.6321009248495\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-28050.044485727944\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-59012.05190022787\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-59714.84551906585\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-63450.57126363119\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-31034.79922612508\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-78191.51246388753\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-323.86721134185785\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-2.53988941510519\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-201.82050307591757\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-409.61804747581476\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-332.6887591679891\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-294.47831233342487\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.92382487903039\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.69743409752846\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.13230216999848\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.00576016803583\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:63.92645264665286\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.81496065855026\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.74042573943734\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.88512744506201\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.95642157892387\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.99225730076432\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.75735940039158\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.60462958862384\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.02062782955666\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:63.91452675064404\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:64.97455693781376\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.94225481525064\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:62.94499459366003\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:63.56911594669023\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:41.299535458286606\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:39.245953634381294\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:42.987120834489666\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:58.090139577786125\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:43.14810737967492\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.09470263309777\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1299.8380104700723\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-8261.325422922771\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-626.945374806722\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-944.2868645985922\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-53.61746470133464\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-3271.48733774821\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-199.9295008182526\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-13.18995972474417\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:43.08574875195821\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:47.54114637772242\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:63.520844777425125\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:44.298168917496994\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.04111212988694\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.02071152130763\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.01206340889136\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:64.9138409892718\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.00497790674369\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.00106662511826\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.00625112404425\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.01493978003661\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.01250352710485\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.00969598302618\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.00973112260301\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:64.98964814003557\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.47937922552228\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.23625974232952\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.0768057256937\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.99178284158309\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.96882122009993\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.03397012750307\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.26069914922118\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.81259573251009\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:34.44066803902388\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:52.796116278817266\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.5417216916879\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:33.8359326745073\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:64.9022928873698\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.07958730061848\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:64.58665211995442\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.03534317016602\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:64.68259175618489\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-678.9822832743326\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.0152571996053\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01306811968486\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:64.93400891621907\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.02105765044689\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01614354550838\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:65.01855611801147\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.01362683872382\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:64.9610994507869\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.06686093906562\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.02743321160476\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01361946264903\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01359733442466\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360461736718\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.0136016557614\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.013596083348\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360283543667\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01360595226288\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01359760761261\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01356447736421\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01363657414913\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01357610026996\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01357176030676\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01360443498318\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.0136029223601\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.25187802066405\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.15224973857403\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:61.14867530142267\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:59.830626149972275\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:61.910270328323044\n",
            "Layers: 1, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:59.295729820926994\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-418595.10876973474\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-305351.07720692956\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-74221.60433451335\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-188268.00593058267\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-128428.54793548584\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-271222.9215113322\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1400.6301560004551\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-545.2370989322662\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1341.2707245349884\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2393.7160072724023\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-498.2547684510549\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-241.46432618300122\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:41.79844421645006\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:29.687318205833435\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:41.18188983450334\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:37.51764547079801\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:0.005893881122276401\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:13.492410443723202\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:57.04514101768534\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.41835984339316\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:57.80960043271383\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:34.12450308601061\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:42.25548166781664\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.9435705592235\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:43.8139681580166\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:34.467803090810776\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:37.51752393941084\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:26.435119435191158\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:47.55449422945579\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:40.804941381017365\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:43.877934627234936\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:37.88481613000234\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.99923290684819\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:39.65913108550012\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:23.48921336233616\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.56203069910407\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-193066.83363119763\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-382993.0264727275\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-404794.3164189657\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-60948.13901861509\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-103001.18333180746\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-308752.7706336975\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1522.6975838343303\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1605.0349754095078\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-508.52651456991833\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-4012.6651664574943\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-4736.788718700409\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2760.3603062033653\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:56.18512210746607\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:51.214751030007996\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:59.576645642519\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:59.663213553527996\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:56.48973282426596\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:63.18073682487011\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.99592720468839\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.5663817046831\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.81042247265577\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.83398648848136\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:63.4470742320021\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:66.41371622681618\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:43.645000718533986\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:49.38653726751606\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:61.814139162500695\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:49.1121270864581\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:49.371474745372936\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:49.58587709814311\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:38.039285205304616\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:45.86588940272729\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:41.53829153627158\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:42.6186294729511\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:46.24730097750823\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.07201961427928\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-264047.6484044393\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-107871.86769485475\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-213212.4248631795\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-20684.462998708088\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-33578.01120440165\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-224649.69162623087\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1455.1434290409088\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1508.1859791278837\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1687.159515619278\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1736.007094681263\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1847.29859093825\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-428.1868060429891\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.05656116704147\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:63.047121266523995\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.82710683345795\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:61.22687881191571\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.5662897080183\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:63.573054497440666\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.9904748921593\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.81747499356668\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.45043234154582\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.53023038059473\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.10572111854951\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:63.09571679060657\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:65.11753283441067\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:60.6365023367107\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:61.499995552003384\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:61.32979708413283\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:61.76035977279146\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:64.80695430189371\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:48.02789044876893\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:29.33532122522593\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:41.38066335270803\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:39.56316461165746\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:46.882511569807924\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.81589267402887\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-35401.36873881022\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-13612.168553670248\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-33611.97252909342\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-62980.98055203756\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-42816.69372240702\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-41752.29958534241\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-106.77456855773926\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-141.7109513282776\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-268.6547563473384\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-187.99157291650772\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-221.47276242574057\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-203.929682970047\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.46787013610205\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.18120718499026\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.1096751789252\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.2479845782121\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.25875429312389\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.7463808208704\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.12437000870705\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.88533327976862\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.992364977176\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.00038582831621\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.96882411340871\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.93861368546882\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.04522023101647\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:63.69348517308633\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:63.77682951589425\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.7259034588933\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:64.93228829155366\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.24029074857633\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:43.72863827894131\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:47.56450116634369\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:40.88361779227853\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:47.50088403622309\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.35157161951065\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:60.770934758086995\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-8038.655845324199\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2810.392322540283\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-3168.386688232422\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1919.3603897094724\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2763.0133724212646\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2489.462242126465\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:40.50087710221608\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:51.978696187337235\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:55.175512631734215\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:55.1869918902715\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:12.81133681535721\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:54.84822958707809\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.02524582048257\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:64.98190720876057\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:64.98624376952648\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.06641122202079\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.00684129695098\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.09410227338472\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.00932068874438\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.0105872862817\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.01573322961728\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.03340077276032\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.00483311712742\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:64.96569798638423\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.00015592823426\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.91646725684404\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.25783057014148\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.00614147012432\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.99631561338902\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.04139204742387\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:41.68195107330879\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:50.53318967421849\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:43.98224055146177\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:46.54339174429576\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:44.07681906595826\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:52.12585403273503\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:65.07824579874675\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.80847040812175\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:64.91255124409993\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.09167035420735\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-33.3449935913086\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:65.18893241882324\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:63.27315310637156\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01266598701477\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.01283327738444\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01524209976196\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-1374.6304361025493\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-230.57433615128198\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.01360669732094\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:63.20583569506803\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01350204149882\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.0135946770509\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01358258227508\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:63.37953425943852\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01361181338628\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360168680549\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360322077137\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360194136699\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01361202759047\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360107213259\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01359475155671\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01363235215346\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01360199103753\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01360014081001\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01359059164922\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01354215977094\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:62.796799099693686\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:45.34306488931179\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.54825708766778\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:58.20324749375383\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:49.02272146195173\n",
            "Layers: 1, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.763770524412394\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-107975.79647699992\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-17792.36385981242\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-450508.68604024255\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-633659.3296813965\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-562800.6325022379\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-554883.8827641805\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1229.1789944966633\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-2042.1658225854237\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-713.7197900811831\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2544.3600579102836\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-4654.223920702934\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-5092.200074195862\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-44.90058317780494\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-10.802011340856543\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-54.141379495461784\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-31.7266118278106\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-5.905172427495331\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-47.09728047251702\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:59.82300413151582\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.778514364113406\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:63.536524275938675\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.18235667608678\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.87827248312533\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:44.88613457108538\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.94854704601069\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:33.62869886060555\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:40.40749874586861\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:37.42453730354707\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.82105907859902\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:49.72299465288719\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:39.045943630238376\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.045408224066094\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:43.234072724978134\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.699900751933455\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.72090206543605\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:46.65416095405816\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-290670.3129577637\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-978595.9480857849\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-303529.62614774704\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-237107.16840108234\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-52782.82100518544\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-457366.3738759359\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-6670.83103299141\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-3230.192032456398\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2318.5235230624676\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-5806.084481676419\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-2688.2397945721946\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3354.2952724297843\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:31.33330353846152\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:49.873292384048305\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:46.604823072751365\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:49.53131474554539\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:57.55231687178215\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:48.89065866669019\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.60549288988113\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.67093861103058\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:61.51569767544667\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.0182436555624\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.26875180378556\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.90914973119894\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:61.93275290851792\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:59.440678507089615\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.636467752357326\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:42.26965679476658\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:56.00900920418401\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:59.079410769045346\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:46.923967500527695\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.900916357835136\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.76971989714851\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:59.72817017386357\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.733211954434715\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.73852108605206\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-142410.65872828165\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-58803.6647160848\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-544809.9944559733\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-336402.71781921387\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-229795.63698450723\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-17466.780284245808\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2334.1421937942505\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2144.615494410197\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1004.2096563180287\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-5238.729864756267\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2054.0571987628937\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-2356.5312671661377\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:57.68015628059705\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.1414725780487\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:58.61639256278674\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:58.94983443121116\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:57.65924190481504\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:56.220219557484\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.49776684415217\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.06377649183075\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.60016483068466\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:63.222690795858696\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.67461555202803\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.62688506270449\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:64.55418424680829\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:63.904485957076155\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:64.86116537203391\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:65.0181357562542\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:63.74302325770259\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:64.0272350112597\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.064064256846905\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:47.63242920239767\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:38.174928588171795\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.34172039727369\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:44.80376981819669\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:48.53627136598031\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-193841.4778629939\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-34021.40253702799\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-83353.78511428833\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-152694.09801483154\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-41415.44316768646\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-88190.59236526489\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-1056.5462457140286\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-283.85239243507385\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-986.7478736241658\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-323.8965702056885\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-852.2782238324484\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-468.5183209180832\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.98276161650817\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.45806540548801\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.92561889191468\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.00057467321555\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.35109599431355\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.4128071765105\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.16125060617924\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.84295796602964\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.32892768581708\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.98866997872635\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.96886406714717\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.02728664626677\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.65364605669552\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.58829355736573\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:64.90397100026408\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.1624142890796\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:64.84611882517734\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.29685504734516\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:46.22588132197658\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:45.45000409086545\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.55999581019084\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.28717176864544\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:50.7469954714179\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.18090461815397\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-4553.035659790039\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-245630.301361084\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-5334.93350982666\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1267.2938283284504\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-37514.18215751648\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-9602.241684595743\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:29.609589576721195\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:1.1935440699259448\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:19.17243957519531\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-978.4167305628459\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.53542391459148\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:47.01488812764486\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.98718965798616\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:64.99030490716298\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.04791562755902\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.09685901304086\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:64.95237263540427\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.21458784739175\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:64.99328433225553\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:64.99513981863856\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.0009740019838\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.0137454085052\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.02318739891052\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.0119427467386\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.99786055025956\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.01000851392746\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.04349515773356\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.0157975529631\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.95017721007268\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.02287402749062\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.7441429728642\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:45.81554792821407\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:45.30266576757034\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:60.872671914597355\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:57.853571946422264\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:63.45241488267979\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:64.95804150899251\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.00480651855469\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:64.99536514282227\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-274.4493595759074\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1963.8205750783286\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:64.96629079182942\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01036326090495\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.62629781042536\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.44803828001022\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:47.09826509157816\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-63.079952498277024\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:64.98497530817986\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.35585823158424\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01363029082616\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.0136152903239\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01361310482025\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01354207595189\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01355583469073\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360127702355\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360754792888\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01359883695841\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360435659687\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01360454286139\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.0136099383235\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01360899458328\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.0136231382688\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01360401511192\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.0136055983603\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01359723236722\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01359744618335\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.9936387129128\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:63.30960286781192\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:59.36113155136506\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:63.68431125457088\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:62.14524218191704\n",
            "Layers: 1, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:60.667811644574\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-512787.6688385009\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-487440.12978235877\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-167057.66537348428\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-208160.74540456134\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-488077.1479288737\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-82209.1736984253\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-522.0720513661703\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-667.4586711327235\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1930.3398666779199\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1992.1927656730015\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1260.243946115176\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1940.8029691378274\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-0.7081841677427203\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:3.0789828797181396\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-42.84984377523264\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:10.157658631602928\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:1.9767617310086916\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-47.709691276152924\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:60.53076357891163\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:49.874500685061015\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:47.07316728929679\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.55154018228252\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.073785384496055\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:60.50489882628123\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:46.06160502880812\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:40.48495003332694\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:41.05869239817063\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:35.92886178443829\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:49.378498171766594\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:43.55150108536085\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:46.582439156870045\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:46.556862791379295\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:52.4931802538534\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:30.19333969801664\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:59.91037655000886\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:43.05068193934858\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-294532.58209228516\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-179854.58724975586\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-377375.8380635579\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-130341.89926783244\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-51119.45870558421\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-515084.03620402014\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-4441.66660497586\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-4393.5707817474995\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-5943.5020887851715\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2340.92866619428\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-5949.96821641922\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-5833.073774973551\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:40.908027167121574\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:39.871855999032654\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:57.04460670550664\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:50.03736982742946\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:55.98426192998887\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:48.21536799271902\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.74270458395282\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.05491876477996\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:61.95456599195799\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:63.82688823932161\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.47112719962995\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.26510472471516\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:50.46022366732359\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.5952821324269\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:63.356583161900446\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.268532451242216\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:45.42526646206776\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:51.185634316255644\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:38.18632532532017\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:48.02594339475036\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:39.4874628012379\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:39.881553680946425\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:46.196389980614185\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:37.46789845327536\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-94691.61534627278\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-272655.1771736145\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-250212.44771877924\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-434208.0387401581\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-420651.7392985026\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-3265.5281956990557\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-3203.759275277456\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2594.837567011515\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2185.779449939728\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1813.6826491355898\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-3182.265181938807\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-2154.0789357821145\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:58.01372413833936\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:62.14969957868258\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:53.77009463806948\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:58.07888676722845\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:60.6823556125164\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:59.662708044052124\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.25742764646809\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.88673275957505\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:63.81372497727473\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.38417889177799\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.2549612832566\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.9695295157532\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:63.53267130131523\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:60.29896173005302\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:63.191835905114814\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:62.54712039604783\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:64.48287962625425\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:60.083849343160786\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:43.8192407724758\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:41.3077972146372\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:47.95153840134542\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:47.71276052420338\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:44.51159431599081\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:44.95513087759415\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-34940.66439946493\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-74634.78660583496\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-23592.4551709493\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-94466.15158716837\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-103332.11085001628\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-149248.4541463852\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-854.9245393276215\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-847.7970747152964\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-248.79444738229117\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-608.1062986453375\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-238.73674432436624\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-599.9606863657633\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.11296878258388\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.98597440620264\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.73834035297234\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:63.1038473546505\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.17341993749142\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.5011426905791\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.99456947048505\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.90874735638499\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.20262032747269\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.89721255376935\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.0016163662076\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.96156459674239\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.05032163113356\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.80580639249335\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:64.7865956579335\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.95796154563625\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:65.10984722524881\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.77512522538503\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:39.81957973291477\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:58.78347990413506\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.38890417913595\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.47703992878087\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:56.284972379604966\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:45.84975580995282\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-12076.492188771566\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3679.5086002349854\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-3385.7307211558023\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-4276.618127822876\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-25990.787467956547\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-18051.198461850483\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-761.9248000780741\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:28.779471913973488\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:48.544448018074036\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-391.0982658465703\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-1463.1409879525502\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:33.478264013926186\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.0280482073625\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:64.98402391870816\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.04863212505975\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.04219214121501\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.02063279350598\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.06798398991425\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01185107976198\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:64.99806134651105\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.00877724339564\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.01192866514127\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.02013198410471\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:64.99471170206866\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.040004812181\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.01787924518187\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.0488786244144\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.97868563979864\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.01749459654093\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.98975457934041\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.07887539640069\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.84782201548417\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:59.39301942785581\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.532506682910025\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:48.69173149267832\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:48.48488899568717\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:64.95737393697102\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.09792645772299\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:64.51702117919922\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.21470387776694\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:64.855162302653\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-344.44020589192706\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.01586318016052\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01718918482462\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-98.44799667596817\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-486.44116823871934\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:64.82797940572102\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-273.72693439324695\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.01362949609756\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01359847684701\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01359372089306\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01360669732094\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01361303031445\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.0136594971021\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360614473622\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01361113429691\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360087965926\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01360555489858\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01359915438418\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01361137256026\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.0136025242197\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01359269022942\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01360054438312\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01360570080578\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.01360739270847\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01360382884741\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:60.87429797897737\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:60.05130738019944\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:61.105748191475875\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:64.37672023350993\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:61.86596551444381\n",
            "Layers: 1, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:63.32339441403747\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-512181.1707878112\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-501689.8987325033\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-22872.12887922923\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-227919.94659423825\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-393826.1374282837\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-335390.88609695435\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-3805.9122784932456\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-4019.6289829413095\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1615.601377884547\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-656.7210787534714\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1989.7557274500527\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2657.2697182496386\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-1.1289631326993232\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:1.1640977611144354\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-30.967579235633224\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:6.654273731013138\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-30.27044708530109\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-7.645192792018252\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.17600477486849\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:45.57743612987299\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:46.35647216190895\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.12091861665249\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:61.02654224882523\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:59.025335796177394\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:41.34747649232546\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:48.85802977097531\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:48.09107416619857\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:41.1042431058983\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:33.667138759046786\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:48.946713296075664\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:31.911134564628206\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:35.92457755158345\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:47.001972111562885\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:31.166851011415318\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:44.072177093476064\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:38.16052313273152\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-213607.81494935355\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-466999.2828496297\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-450629.41610336304\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-225578.4669685364\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1021348.6220296223\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-165467.13788350424\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-4091.3650155067444\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-607.551318804423\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-406.6202561060588\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1831.3354674975078\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-3359.5004936059318\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-6009.11043047905\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:38.95202552278837\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:49.92730990052223\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:34.71229871114095\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:37.347903909782566\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:46.56625422338645\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:32.19807321826617\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:62.36440458645423\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.72025458763043\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.30879415323336\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.11890015006065\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:63.10111703972021\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:62.52393795798222\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:57.27556790535648\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.09884543965259\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.50026748950283\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:62.610303654025\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:58.04582076147199\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:32.85879049450159\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:35.52803309013446\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:33.550012434522316\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:37.068343212207154\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:44.381706987818085\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.61880903442701\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:42.71996580064297\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-423077.3947143554\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-377214.8871866862\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-177078.0804570516\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-228281.85212453204\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-232611.76828702292\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-39018.70941797892\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-4514.60061053435\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-3500.0328856209912\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2524.0833266576133\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2817.1932713190713\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2503.0738337834678\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1554.6001768112185\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:60.48969139655431\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:51.289927611748375\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:54.05884432295957\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:56.925610154867165\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:49.62777358790239\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:62.57601228853067\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.10942187781134\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.01841213554144\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.92958555618922\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.91961100449164\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.76922945678234\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.951296672225\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:63.26360359787942\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:61.146549079567194\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:63.03312613939245\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:64.1060256275038\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:62.42112192014852\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:65.14976418887575\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.479960790524885\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:36.43979380528132\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.69989701732994\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:32.09985257436831\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:42.02755630016327\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:46.710932739079006\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-54234.272079467766\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-3267.9232120513916\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-139677.4552345276\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-74734.90669329962\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-109272.6368967692\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-24813.97276878357\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-637.2348183393478\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-73.0568144718806\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1143.5322054227192\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-689.9717176457247\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-770.9681701660155\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-825.1882340510687\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:66.19778220852216\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.79626051088174\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.62442464133103\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.35618035495281\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.59994333485763\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.41853327304125\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.04710007458925\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.04079180459182\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.04588800792892\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.94783711309235\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.08590376625459\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.00310120483239\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:64.76249424740672\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:65.41941500889759\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:64.98989939689636\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.11327739804983\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:65.01142803579569\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:64.49631080031395\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.05865840613841\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:43.77150541792313\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:57.43169469914089\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:49.231203639258936\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.59318511436383\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.55768874908486\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-8980.469779968262\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-40337.5288772583\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-7462.737321853638\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1701.0838556289673\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-3491.1763509114585\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-4728.8768672943115\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:9.412132898966474\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-6037.319663365682\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:58.76531958580017\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-165.10483781496683\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:47.75080839792888\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:62.32884327570598\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.0241972754399\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:64.97482041517894\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:64.91467915475368\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:64.99408143262069\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.02738299469154\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:64.9640333155791\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01769465704758\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.01769590812425\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.01242253308494\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.01644495874643\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:64.98515109221141\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.0052704786261\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.00437342872223\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.02723301295191\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.03994292269151\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.00185526907444\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.99750657317539\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.02633463591337\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:62.10590032860637\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:46.919607569773994\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:60.021871974070876\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.03858983765046\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.02312421550353\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:51.96560966627051\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:64.12846247355144\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.7235933939616\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:65.16170501708984\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:65.31986872355144\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1326.6731103261313\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-2294.4598865509033\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.00710248947144\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01347502072652\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.01606583595276\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:65.01382827758789\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:64.85636274019878\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:37.7083303531011\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.0136266152064\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01360304964085\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.0135862827301\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01362015803656\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01357172926268\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01356224219003\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01360667248566\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360175510247\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.0136035362569\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01359560837348\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01360140119989\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.013604691873\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01362085342407\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01359881212313\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.0136189100643\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01360134532055\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.0135940189163\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01359656453133\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:63.26738995810351\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:64.65958377967279\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:58.818325574199356\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:63.15645902107158\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:62.9867397621274\n",
            "Layers: 1, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:59.293051849429816\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-212106.88544591266\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-225605.66733837128\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-238602.99872080487\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-498849.8963069916\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1037439.318043391\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-360873.4713872274\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-650.9719323118528\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-617.8028309345245\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-4713.889744679133\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1590.6255888938904\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-4829.377916653951\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-4599.137438734372\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-32.57365183283885\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-17.478974635402356\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-47.284030901889\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-31.831660146514572\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-18.098952323198315\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-65.26019139836232\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:56.38459318627913\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:58.445911050463714\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.468389101326466\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:43.250494158516325\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.80327218522628\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.91138369372735\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:48.99182445990543\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:26.612034787734352\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:43.300095126032836\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:42.25017994021376\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:49.434217189749084\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:46.804173874358334\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:42.80083768069745\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.419835240890585\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.285044316202395\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:38.13652095695337\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.622764440874256\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:47.62455977499484\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-546188.57421875\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-872815.6056022644\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-538339.6479797363\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-59708.82116317749\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-158880.2335357666\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-909080.1879119874\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-7594.676971832911\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1125.8147243658702\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-6731.172780195872\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-3539.357318878174\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-8212.43914604187\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-603.4401162465414\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:40.68930321683486\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:31.46536526580651\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:50.74745049079259\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:32.12057481209437\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:31.043813973665234\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:43.92416633665561\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.67854097733895\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:61.43429161359866\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.2278346295158\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.80738723029692\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.058108150959015\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:62.490649049480766\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:60.07156108816465\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.244039115806416\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.47854998956123\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:51.5972425788641\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:57.70306922184925\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:48.64060267806053\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:50.38403244068226\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:51.8234711761276\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:48.273872236410774\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:33.960667264958225\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:27.554477912684284\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:40.14060481141011\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-102000.35409927368\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-66559.3515586853\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-392234.87932840985\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-194592.6779683431\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-463104.2860921224\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-150631.96935653687\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1331.6616968313854\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2547.704270283381\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-953.5138348738352\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-3776.9520648320517\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-4358.147587776184\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-3825.363336404165\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:55.77188722789288\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:59.14892376710972\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:62.095749452710145\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:59.6198420226574\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:63.830313012003906\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:57.837622935573265\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:63.23793103219941\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.95762160917123\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.97045159339905\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.2052876042823\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:64.88755564826229\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.9494946282357\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:65.1372942328453\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:63.114236419399575\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:62.58485656852524\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:64.44096139011283\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:63.83315993783374\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:62.43988063186408\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.613136388361454\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.66747181365887\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:43.49249276642998\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.965567750235394\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:45.764469976226486\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:46.00849863762657\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-25071.464246114094\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-18316.569112141926\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-117044.40749804178\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-83668.04768880208\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-40594.21044667562\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-26479.050833384197\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-620.0156990687052\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-304.76125478744507\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1406.4142306645713\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-436.4641602834066\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-760.2766050895054\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-691.2713905175526\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.38174853722253\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:66.54056529204051\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.8372562477986\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.89746541405718\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.61441266040006\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.6726130346457\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.7648487240076\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.85891620938978\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.43714775703847\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.94376217325528\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.10128668198982\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.17454405004779\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.10449287792046\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.88751090752582\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:65.03278338660796\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.35227057834466\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:65.05491030712922\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.15183278669913\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.71323820700248\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.60196024924517\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:41.066288171956934\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:44.15795683550338\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.86191569392879\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:59.9122120688359\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-615.4371198018392\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-72632.00889587402\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-5653.113624254863\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-62874.31126912435\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1182.2911389668782\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-3220.766264597575\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-297.5164463122686\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-1834.340134461721\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:41.79189464077353\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:63.18964521090189\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-46.15201622247695\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-647.6792136828105\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.00253940622012\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.11959947645664\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:62.107471923033394\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.1297405610482\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.03325656056404\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.0180556376775\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.01525459190209\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.01656311253707\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.05936965346336\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:65.02914230028789\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.01603735610843\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.01355675359567\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.00370853270094\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.01443336407344\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.99027067174514\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.06540215263765\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.02229964360595\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.06069470817843\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:46.09874253471692\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:61.23126963774364\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:61.10000258932511\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:59.64257081349691\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.719278688232095\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:43.587709379692875\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-322.0878903071085\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-295.3567886352539\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-1165.350817044576\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-366.49235010147095\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-163399.04900868735\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:64.96255874633789\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:64.57513550917308\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:65.01693447430928\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:51.97006821632385\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-584.4148528575897\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:65.01690089702606\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:40.823280811309814\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.08496624728043\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.01360769073167\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01359971861045\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:65.01359661420186\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.01362822949886\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.01361188789208\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.01359309380253\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.01360859411459\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.01360176752011\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.01361183822155\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.01361485570669\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:65.01360083619754\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.01359129945436\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.01360351763044\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.01360862205425\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.01360672215621\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.0135921066006\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.01359310001135\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:64.05524667352438\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:61.31741926694909\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:61.33078480760257\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:64.38467860221863\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:63.584676906466484\n",
            "Layers: 1, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:64.38027128577232\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-65820.8783976237\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-6531.051324208577\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-6638.851483662923\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-32845.046450297035\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-55878.4250386556\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-4722.809321085612\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:56.255904734134674\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-967.8533744812011\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-303.1224596500397\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:6.072544753551479\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-984.6604609489441\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-316.96865598360694\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:52.6547106107076\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.65199907620748\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:54.32866851488749\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:48.43594948450725\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:52.07841351628304\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:49.24135436614354\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.79338857531548\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:40.945715829730034\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:50.733694632848106\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.456249887744576\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.61263845115901\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.35164730747542\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:43.43603094418843\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:-19.77851370970407\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:58.04447755217552\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.00545499722162\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:57.823072820901864\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:57.22384547193845\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:45.80363723138968\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:-3.8549485802650496\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:-7.506851851940155\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:51.20114867885908\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:57.262014544879406\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:55.52655013899008\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-7617.757906913758\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-5726.811739603679\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-2074.635209639867\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-12316.1891746521\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-8404.258766174316\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-5340.947984059651\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-5.60138344764709\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-293.3290859063467\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:43.2201103369395\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-169.97710088888803\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-239.11677877108258\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-115.24328271547955\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:68.01566348721583\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:61.46639625231425\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:63.20892781019211\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:65.60780716439088\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:66.39470765988031\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:67.58504816641411\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:57.599276552597686\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:56.78057928880056\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:54.333958725134536\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:55.136570980151504\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:56.31549425423146\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:54.637575348218284\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:58.18660908689102\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.155234461029366\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:16.00379109382629\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:36.8513132383426\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:-5.869062642256417\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:27.87231790522734\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:56.04804749290149\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.79504042863846\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:19.832739084959027\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:33.932742128769554\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:4.627865453561142\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.72438543041547\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-10433.588155110676\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-4960.259908040364\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-22822.07895596822\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-5415.582987467448\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1749.8746395111084\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6522.698814074198\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:52.84175435702005\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:30.886754592259724\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-84.5889719327291\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:3.6672155062357548\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-16.430635054906205\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:27.305389444033302\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:67.08297610282898\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:67.89316691458225\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.84287299464147\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:67.11110649009547\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:69.62011930843195\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:63.813785562912614\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.23606425523758\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:62.04358082264662\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:60.67909270524978\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:57.8830270593365\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:56.46088898181916\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.21716034660736\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:32.14151732623577\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.621063977479935\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.65633875876666\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:40.4368094354868\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:41.46019486089547\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:51.707153568665184\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:23.79289656877518\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:34.99903544783592\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:57.15764041990041\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.15032342324655\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:39.742763414978974\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:24.249783903360367\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1895.7686233520508\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-7976.867141723634\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2123.4421157836914\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2017.2831980387368\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2503.7225691477456\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3285.8186848958335\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:50.13417164484659\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:53.230127493540444\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:48.34126343329748\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:54.25482630729675\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:59.06135121981303\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:55.2786386013031\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:68.78855153918266\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:68.78524222721656\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:69.18671109403174\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:69.1042921692133\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:68.4980255117019\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:69.32504324863355\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.30739466349284\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.6106107433637\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.34623081112902\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.66086059063673\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:59.18858634928863\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:66.14921788374583\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.63562696675459\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:52.081844409306846\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:33.15361628929774\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:55.279074013233185\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:42.48661994934082\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.75872299075126\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:57.184630408883095\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:34.58965500195821\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.09965927402178\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.219969900324934\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.206673150261246\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.38976313670476\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-30.18689473470053\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:24.67259724934896\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-37.60069529215495\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-91.56495412190755\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-0.10809580485025005\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-523.9338684082031\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:60.01010924577713\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:62.399617334206894\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:62.20919807751974\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:59.551273187001556\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:60.498988231023155\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:67.17105547587077\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:67.3650012537837\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:64.74801765133937\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:70.22222782174747\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.99879828592141\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:68.8284487153093\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:66.98650838186344\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:66.37470375746489\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:67.76879479487737\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:67.65912981082995\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:66.95088915526867\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:68.2942130168279\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:66.32771151761214\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:56.46870757142703\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:54.738512958089515\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:57.01909148444733\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:54.58076293269794\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:54.631044616301864\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:57.7498322725296\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.74933576583862\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:45.36935339371363\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:45.375485817591354\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.447264730930335\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:2.1695901950200436\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.869062577684716\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:56.744130452473954\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-335.271053314209\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:56.06349309285481\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-799.7651799519856\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:54.18725331624349\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-2644.99392191569\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:60.20247717698415\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:70.50529956817627\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:69.70081170399985\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:68.11135048667589\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:63.1694221496582\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:68.88064483801524\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:69.64602184792359\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:69.87005985652407\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:69.86525475978851\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:69.24496050924063\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:66.44535793612401\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:63.670721873641014\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:68.67901156966884\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:66.05918924013774\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.57410246382157\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:67.61758767068386\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:67.54745483398438\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:68.42020144065222\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:56.66995443403721\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:63.60018576184909\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:62.022054493427284\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:59.27072023351987\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:57.29855711261431\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:61.12152248620987\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.42523535589376\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:51.804457952578865\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:38.527896925807006\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.77034411331018\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:51.475637654463455\n",
            "Layers: 2, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:48.89975347245733\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1577658.8079516094\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-108382.75797526042\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-64900.67272186279\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1611748.4816996257\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-87047.53852844238\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-405009.54793294275\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-60.09883920351664\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-406.13258361816406\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-359.6534048517545\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1181.4595532417297\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-632.9600691795349\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-628.4548769394557\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:57.72706866264343\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:55.16418258969982\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:59.48229640722275\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:51.17322996258735\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:58.51130649447441\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:60.16007706522941\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:7.895393520593641\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:40.63059671471516\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.55281709134578\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:-23.016231258710217\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:14.723006511727965\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:45.95269533495109\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:33.206626549363136\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:30.54057809213797\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.05160924792289\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.60975177461902\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:25.953466370701793\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.08557014167309\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:38.88403636713823\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.760178898771606\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:37.34618771821261\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:58.79422041277091\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.7346327950557\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:54.67308754722278\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-183377.74434407553\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-156801.2129275004\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-57240.824381510414\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-160819.4246419271\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-5426.076253255209\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-140380.8756510417\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-204.1314438978831\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-15.628384848435717\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-181.26310110092163\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-45.418459971745804\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-88.4467135866483\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:20.370480815569557\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:67.70240602393945\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:61.322281807661064\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:66.01981593295932\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:63.075129999779165\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:62.28799658517043\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:62.933002188801765\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:55.589230482776955\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:59.07087637732427\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:55.84067429105441\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:56.776157170534134\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.67461707194646\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:52.0301379263401\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:57.74144714077314\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.32341100772222\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:52.644968554377556\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:58.03932412217061\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.254710545142494\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:15.169593542814253\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.71807736158372\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:35.22095236927271\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.1642393519481\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.24123887966077\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:15.674427772561705\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:54.64090555906296\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-40170.97540537516\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-119493.50158691406\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-29590.81319173177\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-77431.30126953125\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-29665.52670796712\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-64403.629557291664\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-99.7541638215383\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-210.03713170687357\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-92.93938736120859\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-70.33573130766551\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-186.61628564198813\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-99.47843392690024\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:66.78686378213267\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.9911950925986\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.35095339951415\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:66.12313196063042\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:66.83604426681995\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.41498837123314\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:61.86766440669695\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.67674709359805\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:58.88633146882057\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:63.45313931504886\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:60.448129127422966\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:56.777096316218376\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:40.11000802119573\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:51.97502682606378\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:24.612149596214294\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.71690861384073\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.48256121079127\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.39957801749309\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:33.959416026870414\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:42.90466582092146\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:10.08490145206451\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:46.50459975004196\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:55.199500151599445\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:39.49024229620893\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-17974.37249501546\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-14926.842244466146\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-16914.388529459633\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-22793.876902262367\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-21512.81753540039\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-12307.628593444824\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:51.08611524105072\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:39.109238386154175\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:50.99407384792964\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-2.5994185606638576\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:1.3152035077412916\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:51.04933500289916\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.87237510830164\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.30148759235938\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.8096662349999\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:68.95561983187993\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:67.78714410960674\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.80031517893076\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:67.90060912258923\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.49511155486107\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:62.8292978554964\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.80876292288303\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.35491792485118\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:66.99668444693089\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:30.16961810489496\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.40690117577711\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:37.19026818871498\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.64455777903398\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.01998661458492\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:56.60772984226546\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:6.538710941871006\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:21.06779421369235\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:56.270229406654835\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.35952413082123\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:54.130709394812584\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:45.41532690326373\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-5809.085063934326\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-49274.383754730225\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-64763.32310994466\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-226372.09734280905\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1003.7764167785645\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-65374.18507258097\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:55.30548095703125\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:53.47945690155029\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:22.618668178717293\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:50.555654168128974\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:53.64172259966533\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:53.919834544261306\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:61.43474272141853\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.70659626275301\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:62.58308013280233\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.32863800724347\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:62.32822373509407\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:62.84001729761562\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:67.36914459615946\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:67.03380711376667\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:64.21328370769818\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:66.75024479627609\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:64.7653940320015\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:66.05724606662989\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.1114600499471\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.53292753050725\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:59.66916769742966\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:58.153006484111145\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:59.193371795117855\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:54.33632135391235\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.90527515858412\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:6.134720395008719\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.31293621162574\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.20765247568489\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.38788012663523\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:31.422107617060348\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-49.51849619547526\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:53.24241638183593\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:53.62223307291667\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:52.809168497721345\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-651.574379603068\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:54.83633677164714\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:59.672479927539825\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:10.330246686935428\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:54.68510985374451\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:20.536154111226402\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:57.05894495050112\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:54.04879887898764\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:61.42129860818386\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:64.88913983106613\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:60.56812717268865\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.30051036179066\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.72875260064998\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:67.09060286482176\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.72987249780758\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:67.17098126808803\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.78940858443578\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:64.33311626315117\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:62.4617374688387\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:62.3939549488326\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.21775126457214\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.24865256994963\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:61.142077135543026\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:67.36932704846063\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.53608723978202\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:67.76255633682013\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.73315605521202\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.10964361329873\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.76015265037616\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:53.61853197216988\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:14.877311338980991\n",
            "Layers: 2, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:48.999524475075305\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-2810.966625213623\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-43682.56459554037\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-43563.21375528971\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-3255.9324645996094\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-35891.08891805013\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-62842.7431233724\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-58.66474986076356\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-394.80698982874554\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-59.78120843569437\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-684.8262000083923\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-430.7301039497058\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-162.1240278085073\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:57.82168686389924\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:56.52006633579732\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:56.477382431427635\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:56.760662893454224\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:56.41340586046377\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:48.14186463753383\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:50.4717479646206\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.1671219865481\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:43.99612466494243\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.19539089997609\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:27.711640397707626\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:0.9076119462649079\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:50.835764010747276\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:46.2989999850591\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:56.22292930881183\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:55.54750101019938\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.847979664802544\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:44.11909519384305\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.69161021212736\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.36954188346863\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:49.225911262134716\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:51.44832145422698\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:52.708041866620384\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.07388812303543\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-28743.81134033203\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-4508.025023142497\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-28653.587023417156\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-8086.176249186198\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-28728.02596728007\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-30674.30348714193\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-29.71410552660625\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-76.80781399210295\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:55.17791310946147\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:30.29730290174484\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:31.343059341112777\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-135.20166655381522\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.62425614396732\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:65.51194141308467\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:65.52623331546783\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:66.7132093757391\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:60.86045478781064\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.38476102302472\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:54.85963424046834\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:56.72277043263117\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:56.05814843128125\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:56.25854050119719\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:38.36899469296138\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.21939478317897\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.92606987555821\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:46.95818317433198\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.60135957101981\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:29.79978961249192\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:50.12099628647169\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.81815936168035\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:28.783976733684536\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.882888538142055\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:34.04822565615178\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.78481765588124\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:49.932934083044536\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.930840864777565\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-16738.078638712566\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-5312.031097412109\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-2031.2562561035159\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-12859.940183957417\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-6408.756993611653\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-5438.596591949463\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-22.064369519551597\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-20.111504743496567\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:19.469329516092937\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:39.668683310349785\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-115.24869849284491\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:4.311350186665852\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:71.46111581474543\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:69.29006579021613\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:69.3006768450141\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:71.4965799699227\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:72.3053223391374\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:66.94853226343791\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.68878112733364\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:61.119002526005104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:56.43726055820784\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:59.165378461281456\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:59.19498515625794\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:52.37580746412277\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.83823683361213\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:23.938713769117992\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:34.44218094150225\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:58.061857273181275\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:51.228927075862885\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:55.01602679491043\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:29.20869680742423\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.01495519280434\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:39.36336554586888\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:31.75273232161999\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:54.921049823363624\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:42.674569698671505\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-606.3381830851238\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2636.156679789225\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1297.943860689799\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1970.4914124806724\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1391.9248962402344\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-761.1531194051107\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:52.114860216776535\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:55.749588857094444\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:49.550042152404785\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:56.72658920288086\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:58.00131122271219\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:62.547332445780434\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:70.45515425503254\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:70.64723792175451\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:71.32523564000924\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:71.53031508127849\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:67.83981954678893\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:66.11582500239213\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:66.31093045075734\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.37165625890096\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:54.73205407460531\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.7434964676698\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:62.00398504734039\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:69.40146627525489\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:55.699224819739655\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:53.97125698626042\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.56751803805431\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:51.89833670854569\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:47.48698461800813\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.21707060436407\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.456977580984436\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.618420129021004\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.95984504620235\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:51.02122962474823\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:56.259899636109665\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:50.10645185907682\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:49.62118784586589\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-29510.706888834637\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2680.006993611654\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-12892.328592936197\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-10770.9987894694\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:35.96590677897136\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:64.13703208168347\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:55.372172594070435\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:58.87562890847524\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:61.361539363861084\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:60.55830836296081\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:62.95023361841838\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.27429363379875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:70.29018641759951\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:63.57623135050138\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.74929229915142\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:66.93698859463136\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:71.64183073677123\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:67.03329565624396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:68.84229476253192\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:68.82120318710804\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:69.67728834599257\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:70.18875089784463\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:68.22664042313893\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:57.50109694898129\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.00338115294774\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:57.52260901033879\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:57.83940653006236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:56.703094194332756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:55.6667119761308\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.10248360037804\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.61807193358739\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:48.9278727521499\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.47141267359257\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.3374451212585\n",
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.82154550527533\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.924458821614586\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:55.512193044026695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-80.42113860448201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:37.576615015665695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:54.25909360249837\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:29.528648058573403\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:59.52053698400657\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:63.50095748901368\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:65.36753669381142\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:63.02425066630046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:58.612603545188904\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:70.24093548456828\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:71.32640240093072\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:64.89041669294238\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:68.85029417773087\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:72.18816439310709\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:70.22020138800144\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:70.25935461123784\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:60.918268002569675\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.97263085345428\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:69.81802422553301\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:67.91976841787498\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:66.22496834645668\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:66.78395400444667\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:60.2785016099612\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:61.38966334362826\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:63.43298114836215\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:57.52221872409184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:61.41750253736973\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:60.28295366714398\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:48.0879225085179\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.43008105456829\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:51.08560293912887\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:24.017755637566253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:37.32192379732927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.27322314679623\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-48926.92311604817\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-30785.132395426434\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-3721.413593292236\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-25980.243797302246\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-31701.23560587565\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-3644.916501045227\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-509.7166608770689\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-197.61712605754536\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-325.0085834662119\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-137.79837518930432\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-263.3935417731603\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:44.77989703416825\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:37.45640158653259\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:57.775103573997825\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.50090808297197\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:55.213945657014854\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:58.6140155295531\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.63342212637266\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:29.058655028541878\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:59.44880705326796\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.54028511916597\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:28.907114031414196\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:23.54173655311267\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:24.49036291489999\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:47.035417376707\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:46.428429360191025\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:54.21069686611493\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:55.33508808662494\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:53.12958416218558\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:26.29303845266501\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:20.334820921222374\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:37.47441265111168\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:43.33552763486902\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:25.03195151686668\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.34581682085991\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:45.58471739292145\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-15114.201240539553\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-18968.499806722004\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-14615.578721364338\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-22567.35430399577\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-67218.34613800049\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-29762.702382405598\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-100.68594813346863\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-75.51211108764014\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-214.01592140396434\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-52.44219591220221\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-145.14356573422748\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-176.8330228328705\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:66.47932996352513\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:60.39414289096992\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:65.08237426479657\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:65.99530406296253\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:63.96382446090381\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:65.64498890191317\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:53.57380981246631\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:57.73638055970272\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.61477388441563\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:63.697164456049606\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:51.12693416575591\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:60.1293400178353\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.4060267060995\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:50.785598158836365\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:50.165889052053295\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:41.18070159107447\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.92706178377071\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.79903285950422\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:6.265000601609549\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:40.177728459239006\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.719969486196845\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:52.17930134385824\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:50.304862211147935\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.664289606114224\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-5889.535013834635\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-12437.21295674642\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-5311.604766845703\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-12062.251971562704\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-4816.78326924642\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-7165.0029373168945\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:32.427842020988464\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:50.226468394200005\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-69.87815578778584\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-10.405284563700356\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:24.972103635470077\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:12.728127688169478\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.02882270763317\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:66.44120037555695\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:68.67438639203706\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:67.92348809540272\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:67.19122596085072\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:67.24045264224212\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:66.18393907944362\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.43130433559418\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:66.28180707494418\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.53530998528004\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.57623761395614\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.13925111293793\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:52.53983947137992\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.4860989227891\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.524474918842316\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.79383782545726\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.02567876378694\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.94111531227828\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.309749871492386\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.34503550330798\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:51.82663848002751\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:50.45706745237112\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:52.83252909779549\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.41234743098418\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1316.993652979533\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2045.803672472636\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2223.385146458944\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1646.6184504826863\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2263.5230127970376\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-966.9082021713257\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:61.33302852511407\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:47.62455140550931\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:55.09888629118602\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:57.03596115112305\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:49.43020900090536\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:55.10826766490936\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:68.62222708761692\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:69.8091917981704\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.72860376040141\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:67.96084895730019\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:66.49707299346726\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.45992882053058\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.9908746307095\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.49288048967719\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.56832064191501\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.43004690607388\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.30622924367586\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:67.52090009550254\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:26.802602261304852\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:59.41250463326773\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:58.56868927677472\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:59.32816001276176\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:34.29802836229404\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:61.53830945491791\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:49.35030927260716\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.2658518999815\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:58.24897823234399\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.51134275396665\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:31.46022903422515\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:11.847232927878693\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-38.41810067494711\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-36.856209437052414\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1204.443194071452\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-25.091594060262047\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-21.634639104207352\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-192.36693064371747\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:66.20718874037266\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:62.51808921496074\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:53.088822017113365\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:69.06335418423018\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:64.22139843304953\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:54.55539428939422\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:63.22864618152379\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:66.2604969739914\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:68.48977888623872\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:68.75415898859501\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:64.96683252354462\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:64.4304983317852\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:68.39755697796743\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.44842846691608\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:67.94806614518166\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:67.29822352528572\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:66.82248537739117\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:67.52828692396481\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:60.308515081803\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:55.142041767636925\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:66.7593355725209\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:63.15100972851118\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:60.52148811519146\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:62.58280125757059\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.85108285086851\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:25.375259667634964\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.126057838400214\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:48.691178392618895\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.30050621678432\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:59.05140300591787\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:55.93344370524089\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:65.48782666524251\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:59.43286051352818\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:41.353802680969245\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:53.980897267659515\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:60.45375804106394\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.48028945922852\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:59.4478273888429\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:58.75815510749817\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:63.766882816950485\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:64.85604206720987\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:55.6469010313352\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:68.98256734013557\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:63.17406527698039\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:58.55471829573313\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.2994225770235\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:63.724130764603615\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:67.35429135461648\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:63.55794986089071\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:66.08591171602409\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:62.695040156443916\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:64.43251347790162\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:71.72777943313122\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:61.413420985142395\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:66.3805404305458\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.92841769009829\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.54668007791042\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:66.43017852058013\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.6127515907089\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:62.52724782253305\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.63706049323082\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.102113385995224\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:-4.404382904370618\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.47229472796123\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.479733501871436\n",
            "Layers: 2, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.31398322433233\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-11851.607411702475\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-89177.24853515625\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-12385.583038330078\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-200915.35380045572\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-174863.4612019857\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-138808.57360839844\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1592.7393690745034\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-976.3038531939189\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3124.0108712514243\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-664.6680299441019\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:41.20376269022624\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-36.13515396912892\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:20.595014293988545\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-4.799085905154543\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:49.96196712056796\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:46.57219171524047\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:19.948013226191208\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:31.188266972700752\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.36629418407877\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.7359398752451\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:58.10284876575073\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:39.02223788201808\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.319541891415916\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:59.192727530996\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:57.588725636402756\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:50.582831601301834\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:54.606381043170884\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:15.134872148434319\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.126265838742256\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.64406764507294\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:42.24383709331353\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:56.28943095604579\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.47991205798461\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:54.529600789149605\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:56.17271567384402\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:50.575735916694\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-32149.6231842041\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-155105.08977254233\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-44555.82722981771\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-127169.44346110027\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-98554.45831298828\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-40082.34062830607\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-659.7785087426504\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-667.8105743726095\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-545.0733455022176\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-467.0581883192062\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-737.9353447755177\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1729.8798290888467\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:56.95202751706043\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:61.684070552388825\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:58.6760630706946\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:51.04895091227566\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:65.55058054625988\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:64.86308932304382\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:55.58841427167256\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:56.247455527385085\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.14690918723741\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:53.292242834965386\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:54.289544820785515\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:57.81029569605987\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.631747518976525\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.18235135575136\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.733730033040054\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.22572628160319\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:57.45436159272989\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:58.162024412304156\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:37.853634282946594\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:57.68700608673195\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.31215776999792\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:33.66863590975603\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:57.735602247218296\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:2.63207579652468\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-16320.722007751465\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-11269.059693018595\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-27826.69532775879\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-42062.64712015788\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-75174.29677327473\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-37983.304595947266\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-292.69855697949725\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-108.72245311737059\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:31.775949398676552\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-116.08666022618613\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-203.5634422302246\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-351.35360956192017\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:67.30342099132638\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:70.50459156433742\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:70.0947136680285\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:67.84788958728313\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.06270352502663\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:63.92233582834403\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:66.10756299148004\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:56.493803585569054\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.80838977048795\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:63.775209337472916\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:59.939928924043976\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.17244486510754\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.06281803051631\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.02566700180371\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:56.7570519944032\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:54.91105005145073\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.18732556204001\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.08357606331507\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:49.50041156262159\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:29.795376832286514\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:57.32430733119448\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:44.94872104376555\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:55.12084014713764\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:55.36637805402279\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-6173.871790568034\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5932.916444142659\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-6698.94167582194\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-7559.332796732585\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-7577.482560475667\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-6593.889503479004\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:13.383426666259767\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:23.494845231374107\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-19.605418046315503\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:50.06058375040689\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:44.039705197016396\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:4.57984487215678\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:68.10550168156624\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:70.0694811095794\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:68.39376853158076\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:68.11132168707748\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:68.86039192477863\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:68.5620907942454\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.74186810292304\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.23372522493203\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.76176473249991\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.17852844297886\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:66.28397330641747\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.98842971026897\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:56.77364500860374\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.5657397309939\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:56.57896536091964\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.89396184682847\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:56.08262392381826\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:58.64303544163704\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:27.080934718251225\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:51.50424890220165\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:44.20333386088411\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:57.7114783724149\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.02602678537369\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:42.4563713868459\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-1523.9493624369302\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1423.5192012786865\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-644.9407450358073\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-726.9822311401366\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-604.0306282043457\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-734.8980712890626\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:58.59179496765137\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:56.90767447153727\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:58.30971916516622\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:59.7216522693634\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:59.52121138572692\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:60.154873728752136\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.85053185994427\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:68.0618077268203\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.1814294544359\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:64.69868635137877\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.26930284375946\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.02687187244494\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:67.28532272080581\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:66.9356004645427\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:67.09605800608793\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:66.31524922015765\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:66.47088790933292\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:66.93981595337391\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:61.680031369129814\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:61.135516737898186\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:63.08179465432961\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:54.506164516011864\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:57.54362786809604\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:56.00343329211076\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:37.45269951721032\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.0805434435606\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:36.02506284912427\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.69141578177611\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:57.52648781053722\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:48.990728706121445\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:61.614831288655594\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-173.70603402455646\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:62.46495564778646\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:62.001609802246094\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:64.78310902913411\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-148.63622824350995\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:46.7355473836263\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:59.64507579803466\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:64.1685124238332\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:55.898050864537566\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:59.86167709032695\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:62.05169121424356\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.23671393593152\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:62.93822278579076\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:56.70411402980486\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:51.066711184879146\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:59.44748235245545\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:55.82874730229378\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:67.30568083624044\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.19745426873367\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:58.182325164477035\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:66.76319903383651\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:62.49756580529113\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:59.14183852573236\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.84514867514372\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.8438383663694\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.14990948140621\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.46234796444574\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.59299330537517\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:66.10490091145039\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:56.360487043857574\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:57.29788521925608\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.249930550654724\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.86776774624984\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.929249857862786\n",
            "Layers: 2, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:57.08999736234546\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1906753.134358724\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-7370255.09765625\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-4504640.884602864\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-2131817.5428263345\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-132946.96858723956\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-2135108.9877065024\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-7034.965108235677\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-284.6871741612752\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3911.613071759542\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2353.909080028534\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-368.42285434405005\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-160.22564788659412\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:51.23134795576334\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:50.845452646414444\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:35.15613282720248\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:47.5158441066742\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:39.53057671586673\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:48.15164844195048\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:58.860695933302246\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.97939694890132\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.26042476048072\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:32.71811373531819\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:36.604476844271026\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:37.36939371873935\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.54235712687174\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.593096191684396\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.5030919512113\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.74443559596935\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:37.0400074372689\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:50.93579114725193\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.29199938227734\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:56.50304462760687\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:26.07643894851208\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.047840421398476\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.1316484666119\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:11.928452874223394\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2486289.5703125\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-481757.7340189616\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-125515.96069335938\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-648864.1453456879\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-332728.6104838053\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-662309.7087224324\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1077.2679688533146\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1131.3463147481282\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-510.8940366407236\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-690.0502276420593\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1240.8366139729817\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1361.34290655454\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.01003344605367\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:61.67067122956117\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:58.105603804190956\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:63.707543946802616\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:65.89905058344205\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.81618479390939\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:57.80296295881271\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:60.492951249082886\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:56.10637113451957\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:57.22429320216179\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:61.92138448357583\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:55.28666598101457\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:26.73179167012374\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.173677561183766\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.38407466808954\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.614477192362145\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.663044091314084\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.14774295439322\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:48.14916606992483\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:37.819628554085895\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:41.6858732017378\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.96901214122772\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:36.872256584465504\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.69759210199118\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-111219.03710683186\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-93047.86936442056\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-409166.241124471\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-140345.88302612305\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-182546.15451812744\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-462912.82302856445\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-101.06665054957071\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-304.72992599010473\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-788.9665508270264\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-350.83633740743005\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-53.112249374389656\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-980.3169059753419\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:67.26525235921144\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.12704703956842\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:67.08754676083724\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:66.1064833899339\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:67.48141984144847\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.78836057086785\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:63.43782198925814\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.3626758158207\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:67.49189526463549\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.14930629730225\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.02189553032318\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.79161603997152\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:58.357544913887985\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:50.38369707763195\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:59.51048751672109\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:37.3636090879639\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.43193135658899\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:60.46580088635285\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:32.69931520024936\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.93130350112915\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:23.803484787543617\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.12396934007605\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:46.41677413135768\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.61784242093564\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-39517.768351236984\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-4644.936828613281\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-351523.6185201009\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-9967.349891662598\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-414000.22120157874\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-842590.639038086\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-417.7694505453109\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:35.25087694327037\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-10.15544414520264\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:35.89630683263143\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-699.7059611479441\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-13.136777977148695\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:62.28592367221913\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:61.25728506905337\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:63.75439149638017\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.09582578266661\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:63.73463775962591\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:63.27829880019029\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.38873431583245\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.0258091961344\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.44117179016273\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.62594461192688\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.82714879264434\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.8903943002224\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:56.93215540299813\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.51077853639921\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.77103154857954\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:59.54370385035872\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.26255970199903\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.82063572232923\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:52.168378556768104\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:36.92486517131328\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:55.714657418429844\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.68198985606431\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.461538314819336\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:50.19468565781911\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-21382.432613372803\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2795.4501597086587\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-3727.0560073852535\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2837.91259765625\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-34387.06892172495\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2332.558148701986\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:54.25161520640056\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:53.48134756088256\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:54.7235631942749\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:42.36173401276271\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-20.05520900090536\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:59.048333962758385\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:63.99693941076596\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:57.09294923891623\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:59.7889885554711\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:63.09478007256985\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:57.63336315751075\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:52.910488111277424\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:62.201792784035206\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:61.38437367975712\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:59.30280722677708\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:61.938333536187805\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:62.9425482203563\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:60.97910150885581\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.46961770455042\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:60.84570785363515\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:57.173476380606495\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:60.756890128056206\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:63.973346042136356\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:63.02315587798755\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:52.43450991809369\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:43.31111988673607\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.370653589566544\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:58.825692621370166\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.76182250678539\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:25.294887373844787\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-6124.65758005778\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-376616.2401644389\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-86234.74704106648\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-14958.373139699299\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1531.4332167307537\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:48.224906921386726\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:54.90087270736694\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.369497060775764\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:40.654730796813965\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:57.15085188547771\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:39.266948997974396\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-195.00774686535198\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:56.92104229082664\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:58.52961628076932\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:53.1717853496472\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:56.898665092885494\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:56.12963818013667\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:56.539722879727684\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:53.8643560372293\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:58.37284985929727\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:59.03659374763568\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:54.242765791714184\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:59.33280897637208\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:53.94287031764786\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:62.790244370698936\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.18313959240913\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:66.21940642595291\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:64.22496282185118\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.24760030210018\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:64.9177315334479\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.4238892098268\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:57.54285747806232\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:43.13365345199903\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.47120142976443\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:59.31693566342196\n",
            "Layers: 2, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:58.61483073482911\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-45673.58861287435\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-45844.58180745443\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-5579.754638671875\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-44808.16782633463\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-73663.65661621094\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-35729.90958849589\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-758.3422899246216\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-64.86816008885701\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:32.045974334081016\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-678.0670603116353\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-313.2724094390869\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-424.66168880462646\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:50.283730924129486\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:54.463437311351306\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:54.83310366670291\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:55.59935281674066\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:35.37583269178868\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:49.41272586584091\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.278782725334175\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:45.34000076353551\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.165339820086956\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:55.21423563361167\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.54343156516553\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.43691039582093\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:51.48262649774551\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:58.1738330796361\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:43.11106324195861\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.105485782027245\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:47.57576212286949\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.15937883655231\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.95208288729191\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:53.34713260332744\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.54160946607589\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:21.3074533144633\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:26.695933789014813\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:57.33711779117584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-55005.10251363119\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-74191.8608601888\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-48336.84926350912\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-50421.0280863444\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-36886.379545529686\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-40064.45627848307\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-519.5265263319016\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-323.1786853075027\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-294.676570892334\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-204.52774027983347\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-294.25261696179706\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-78.04340084393819\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:67.02640342215697\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:67.36921854317188\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:64.91771792372067\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:68.78161547084649\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:64.64161696533361\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:67.85329580307007\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:53.48265384634337\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:57.12232911338408\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:52.68829474846521\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:53.952234387397766\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:56.3257992019256\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:53.919074684381485\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.24287198980649\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.76973074177901\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.22361028194427\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:43.962164198358856\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:57.16861401995024\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.86070235073566\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.52635499835014\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:30.139175256093342\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:49.49811305850744\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.97931079566478\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:13.596212466557823\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:43.441500551998615\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-5885.832993189493\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-15969.392534891764\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-9772.265402475994\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-16550.483779907227\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-15025.917326609295\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-4123.548545837402\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:35.405495067437485\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:1.4090915520985958\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-88.64277124404907\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-14.997069835662845\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-81.36014382044475\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-38.5662285486857\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:66.28584717710812\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:67.42815181612968\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:71.5574723854661\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:68.82994700223207\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:71.91815913344423\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:66.45033159603675\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.63348490496476\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:59.20047104358673\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:57.58179314434528\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:59.58567058046659\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:54.05483439564704\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:59.47301583985487\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:37.43806933363278\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.62501936654249\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.705697804689414\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:54.48541117211183\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.24570871392886\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.45463225245476\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:46.095288246870034\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.031770974397666\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:12.959946046272918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:30.781880120436355\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:54.686706960201256\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:4.280023425817491\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-4855.72021484375\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1030.6209866205852\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-10044.72000201543\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2914.9292310078936\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2377.9057947794595\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-4198.490587870279\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:44.76219097773234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:50.27528762817383\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:39.53288058439891\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:47.88910428682963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:32.906098365783684\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:46.49266481399537\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:63.14362758149703\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:68.87557827557127\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:67.98024500409763\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:70.45772964755695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:67.89814593891303\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:68.10836972047885\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:67.617380010585\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.67301870385806\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:68.03379215300083\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.64275062332551\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:63.93387246876955\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:67.26205602288246\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:54.49416756629943\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.74905846019587\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:56.00560103853544\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:49.20550330231587\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:57.85614157716433\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.92334092656772\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.480665624141686\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.78181002040704\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.16612694660823\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:57.04474223777651\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.81107224524021\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.9889064480861\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-345.7488886515299\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1323.3224892616272\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-1068.884755373001\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-3567.3131561279297\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-111.81852976481119\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-36.13637288411458\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:61.61034345626831\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:61.036380007863045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:57.88079182306925\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:55.11324326197307\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:61.309391260147095\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:66.32766087849934\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:68.8927795489629\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.52775194247565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:67.0141731450955\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:68.70384069780509\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:64.09453782563408\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:64.39972211917242\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:66.68482472499211\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:63.470740492145225\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:64.20488255719343\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:59.05651152133942\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:66.6286946584781\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:66.77000373601913\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:60.78957755118608\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:54.71510276198387\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:54.69471387565136\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:57.28794867793718\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:56.71585161238909\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:54.89363300303618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.498483146230384\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.79571121310194"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.70805839449167\n",
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:51.53458605209986\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:45.98427037398021\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:52.86985908945401\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:51.99481010437012\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:56.53479894002278\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:55.645929972330734\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:59.97416814168295\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:60.31080881754558\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:61.50391896565755\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:61.608169178167984\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:55.1502279440562\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-196.66547139485675\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:44.65720733006795\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:58.619518677393586\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:40.09355505307516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.00047575061521\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:66.14332938566804\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:67.07032566269238\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.05489765107632\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:67.98280127346516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:63.15466975172362\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.21273848911126\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:62.27423485989372\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:64.20944135636091\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:62.95822282632192\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:63.32022694249948\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:63.17802547166744\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:63.6484229316314\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.42705893268187\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:63.02423066149155\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:67.20572059353192\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:66.16798671583335\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:62.701906760533646\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.64149707307418\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:38.73103524247805\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.87237021327018\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.7813220086197\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:47.02166271706422\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.68970002606511\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-92876.99460983276\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-34405.512746175125\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-99445.35929361978\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-66740.48706054688\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-100738.63924662273\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-59107.001856168106\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-301.1845669150352\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-276.8817121783892\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-57.29226032892862\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-523.3429156740507\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-476.3992212216059\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-16.494352420171097\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:56.29250943660736\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:56.33886399368445\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:53.670989026625946\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:54.1969487691919\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:55.749746610720955\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:58.72745481630166\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:41.51146707435449\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:57.854183080295726\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:48.47956767926613\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:48.58669782678287\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:44.33086986963948\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:42.9155568095545\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.44435320856671\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:28.328429659207664\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.1869827878351\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.499815825372934\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:49.30768540749947\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:32.108209580183036\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:47.4310112123688\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.44250505293408\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.02148852745692\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:12.782215252518657\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:46.10844388604164\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:32.36900200446446\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-98037.76737213135\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-69718.31713358562\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-85077.15450286865\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-45065.25161743164\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-81022.36614227295\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-55684.29890950521\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-237.13758420199156\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-568.9455397923788\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-653.9360451698303\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-509.1598751147588\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-463.72118910153705\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-443.8305914402008\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:65.06551431491971\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:65.9781252592802\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:65.05302473902702\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:65.41504929463069\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:68.07290531694889\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:63.38270631308357\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:58.79110385974249\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.7566045920054\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:62.99253525833288\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:62.07388653730352\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:66.18620646496613\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:65.65389461194475\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:37.29732478658359\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:57.566148713231094\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:51.44657544170816\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:23.331506078441933\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:56.046195179224014\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.85204362745086\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:56.57538666079442\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:45.319718973090254\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.86627094695966\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.60950848956902\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:31.33503516515096\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.4234825881819\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-30924.21992301941\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-25915.928354660668\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-7848.261845906576\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-19417.325236002605\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-21210.97023646037\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-17273.798052469887\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-204.07879670461017\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-224.38222606976828\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-108.21140567461649\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-246.06540987888974\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-104.66965635617575\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-44.4400930404663\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:67.3923865829905\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:66.48457107444604\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.30305297424395\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:68.32355211178462\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:67.3784479747216\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:70.27970338861147\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.55027399833004\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:63.82066412518421\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.96103063225746\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.1420624886329\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.56912582678099\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.88229758044083\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:56.67568139731885\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.73679887751739\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:58.26019392659268\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:50.90565163021286\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.28078116724888\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:51.38985715806484\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:46.663109523554645\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.119341072936855\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:50.59092809756597\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:18.27733119328817\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:28.532533223430313\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:5.1279608905315355\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-5065.4533767700195\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-5451.222991943359\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5061.559276580811\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-6595.200894673665\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3659.297300974528\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-14901.351165771484\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:22.398687601089474\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:9.238731861114502\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:33.59307582179706\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:0.057811737060542434\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:22.324933360020317\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:59.69032513598601\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.43338256577651\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:68.94176367670298\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.88450820247333\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:67.0785881082217\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.94019851088524\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:68.14593934764464\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:66.09573751688004\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.55258584519228\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.04287341237068\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.37265652418137\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.71471825242043\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.91263569891453\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:63.761779448638364\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:41.598410196602345\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:61.87825625141461\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.3911434461673\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:47.288223740955196\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:62.7173548253874\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:39.37638976300756\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:55.402242789665856\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.78955023984114\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:27.973618408044175\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:25.403997600078586\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:49.74558740854263\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-355.8908335367838\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-12714.103247324627\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-476.44194285074866\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-371.75583521525067\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-387.41177241007483\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-102.98116922378541\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:55.50636291503906\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:58.16520415246487\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:60.63480536142984\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:60.639028226335846\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:8.41085513432821\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:63.89779408772787\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:61.654516408840806\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:58.80838016668955\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:57.64708968500296\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:61.56380179027716\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:58.14225591719151\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:62.86358078320822\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:67.15105269104242\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:64.74104098975658\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:69.51729727288087\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:67.88013517856598\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.53163529684146\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:64.90415193140507\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.32006092990439\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:63.49106781184673\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.33448420464993\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.42310785253842\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.73510719835758\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.37629807988803\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.80038000643253\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.3059243063132\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:58.18157353748879\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:52.34021117289861\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:51.768020559102304\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.21956580380598\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:58.56175740559896\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:59.30227915445963\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:52.52492018043995\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:61.559906005859375\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:60.93491872151693\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-699.4497553507487\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:61.70591317117214\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:66.38510862986247\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:54.84357655048371\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:63.26563470065594\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:60.84078788757324\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:60.90304831663767\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:59.948029381533466\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:58.9689002931118\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:47.8401555120945\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:57.83164128661156\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:62.53476345911621\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:57.02297103901704\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:50.284362404296786\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:56.96042140324911\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:56.152964532375336\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:59.02875925103823\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:66.22239676614603\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:58.71044047176838\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.4667460421721\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.11997664347291\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.70816775163016\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:66.6503597299258\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.85100404918194\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:67.45422877371311\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:41.92138554528355\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.86516204973062\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:30.843124116460487\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.318317127724484\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:56.88833301266034\n",
            "Layers: 2, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.99082221090794\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-513434.51171875006\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-200812.0538330078\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-146349.08732096353\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-330642.5655110677\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-692120.0862630209\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-511954.6687825521\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-4316.671743392944\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-360.5631526311239\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2819.7536659240723\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-2273.6814530690513\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1363.4232091903687\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2675.662177403768\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-36.79964820543924\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-78.82740259170534\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-45.95983624458313\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-162.91146993637088\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-47.92695919672647\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-25.09453018506369\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.56646983822186\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.24624743064245\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.68640398234129\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:50.890031158924096\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.190166685730226\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.03847807645798\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.44276116291682\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.82834608356157\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:50.54172267516455\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:54.60255074004332\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:25.683602901796498\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:19.46096797784169\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.87993719552955\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:35.80591050287087\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.41340287588536\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:57.006982080638416\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:51.65124202768008\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:24.423209205269814\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-500721.8764241536\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-138465.5012512207\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-141096.984872818\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-210246.753133138\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-474644.85727945965\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-437529.4908650716\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-5040.341006914775\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-4060.275064309438\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2226.5903401374817\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-4278.933992385864\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-3552.1650091807046\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2644.859098593394\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:58.29531732325752\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:47.026917512218155\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:35.68815097212792\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:48.156063656012215\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:58.39345847566923\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:57.61186877886455\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:59.292191738883645\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:60.02815898507834\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:58.37932695945104\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:58.54192898919185\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:62.01290716727574\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.92650474111238\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.304814664026104\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.39233916004499\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.6097720215718\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:57.42921262979508\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:44.39981174344818\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:54.323950385053955\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:47.86080485830705\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:22.44698628783226\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:57.31248894085487\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.75614980856578\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.745604177316025\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.35169567912816\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-187357.07544962564\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-226593.4049479167\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-195334.6238708496\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-44455.05447387695\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-28320.974361101788\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-111245.07676442465\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-130.63981691996256\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1313.5380601882935\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1254.2876863479614\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-937.5325266520182\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-365.33846259117126\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-414.5701390504837\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.49452108641465\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:61.43047869205475\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:66.91895805299282\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:61.44610583161314\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:60.476169511675835\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:60.96114200850328\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:61.034414395689964\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.81371288498244\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:62.872269848982484\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:61.73311248421669\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.14915863672893\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.49410441021124\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.553766089181096\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.32357103625933\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.3722216784954\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.707806820670754\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:58.434150077713035\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.26113869746526\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.73723975367224\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:48.30314288536708\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:38.12325383226077\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.880770107110344\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:28.95368583500385\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:58.0070453758041\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-41886.77791595459\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-59517.44094848633\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5342.287934621175\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-12040.364122390747\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-34431.6472752889\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-49624.27602132162\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-108.11773935953775\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-21.378291447957352\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-20.443921883900963\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-84.88430261611938\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-266.2205584843953\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-93.10717980066936\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:67.6582059264183\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:68.34427590171497\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:67.0713152627771\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:70.84345176815987\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:68.15787987783551\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:67.7729811022679\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:66.5048148545126\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.97984415168563\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.01757240792115\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.77535732338826\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:66.32407819231352\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.75098171830177\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:60.107150189578526\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:56.217633709311485\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:56.00964916249116\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:56.28581538796424\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.801843255758286\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.351244658231735\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:44.67471197247506\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:55.90777166187764\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:56.5338284149766\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.97096906602383\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.920387501517936\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.35489684343337\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-3434.4043986002603\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-4048.039962450663\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-746.5519777933757\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2314.5877202351885\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-4211.312478383382\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-3129.8757680257163\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:50.64241250356039\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:52.13959137598674\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:58.14242680867513\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:54.88264878590902\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:50.46939373016357\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:56.725006898244224\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:68.83617190023263\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:65.65976346532504\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:68.5134707391262\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:63.24511865774791\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:67.24969143668811\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:67.90019112328689\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:67.30857697625954\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:66.5296158567071\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:66.08417769894004\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:66.64238914847374\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:66.64299324775736\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:66.59194526573022\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:56.41709399720033\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:60.90150430177649\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:59.87750800947349\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:61.73855027804772\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:58.276542226473495\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:59.44592607518038\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.74351818362872\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:36.613758231202766\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.331627835830055\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.99270270764828\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:41.24401943137248\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.1815040508906\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:63.09205373128255\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:64.35550371805827\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:61.03006998697917\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-575.2599334716797\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-308.44987233479816\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:63.15663655598958\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:57.022805213928216\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:55.18678108851115\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:52.59442249933879\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:59.99758005142212\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:54.77892637252808\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:58.98826758066813\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:59.69097475210825\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:60.13626197973887\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:55.301109571009874\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:51.512644439935684\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:54.02353383600712\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:63.56990575790405\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:55.2306080237031\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:58.96453842520714\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:59.980740696191795\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:62.61415814359983\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:52.10111986845731\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:58.86820949614048\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.65085892875989\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.75908274700244\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.66802346458039\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.96415061503649\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.69580391049385\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:66.17038699487846\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.58107938369115\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.41662103931109\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.155045961340264\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.388028259078666\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.577935829758644\n",
            "Layers: 2, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.485123182336494\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-343068.9467366536\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-387282.67344156903\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-18607433.5546875\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-23743704.2578125\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-11067873.3203125\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-9168067.9296875\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-23214.386196136475\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-10436.51037534078\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-5989.404481252034\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-3945.193343162536\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-4041.066312789917\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-5937.770662307739\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:3.808660507202144\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-12.315878669420876\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-30.86716036001842\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-38.32685261964799\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:28.5813744366169\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:19.120409985383347\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:53.923768624663346\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.72213218112787\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:58.63181973186632\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:52.46839587887129\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:42.6813733826081\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:41.80752764145533\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.07295307517052\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:54.23478167504072\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:58.83314922451973\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:52.8848921135068\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:42.21638401349386\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.630820051456496\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:40.59020309398572\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:58.371066985030964\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:44.52223130812247\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:39.50289697696765\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.695994305113956\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:48.49147990345954\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-390495.4624430339\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-2943513.5415649414\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-3399891.3913981123\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-903490.1944986979\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1732461.865234375\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-7456964.842936197\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1577.5261546174686\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-448.6635887622834\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-17225.777161916096\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-3376.816520690918\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-3773.5703023274737\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3553.1837042172747\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:61.98854296157757\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:57.88628485674659\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:60.99018244693677\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:61.13916065543889\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:51.178158223629\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:60.725692932804435\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.991545140743256\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:64.17123922457297\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:65.22762837509315\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:63.18175882101059\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:57.86306753754615\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:57.88432696213325\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:50.03287470589082\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.43334403385718\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.686822560926274\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.04860695575675\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:59.41964594647289\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.1876741151015\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:39.877825820197664\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.51052597661814\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:36.031008437275894\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.061416054765374\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:52.43351389964421\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.552480943500996\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1590380.0895182292\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1527860.9894307454\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-452066.42008463544\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-203031.7645263672\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1211376.2288920085\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-257467.28538513184\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-174.38840369383493\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1864.0086046854656\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-613.2168483734131\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1100.402062535286\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-475.7562353213628\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-375.3848026196162\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.32191726790431\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:64.81146094699702\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.68520460277796\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:65.76149499664704\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:60.37625042100747\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.51703027139108\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:66.54074004540841\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.06540023908019\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.55055814236403\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:67.7013269222031\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.37043826033671\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.90204459925492\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.127470058699444\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.42765274271368\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.45832711644471\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:58.87746152778466\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.09575646370649\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:60.133940763771534\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:58.463593808313206\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:49.226031433790915\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:56.289530942837395\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:52.02086611650885\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:59.519366845488555\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:36.984301842749126\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-764410.7437260946\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-187344.65260505676\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-120023.04785410564\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-199996.68772379556\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-241046.76063219708\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-132378.30801328024\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-1250.7791930933793\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-279.3750909964244\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-25.744930704434708\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-67.10492233435312\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-781.289009253184\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-212.49237378438312\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:61.39805119484662\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:63.085159932573646\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.34765493435164\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:59.22034169236818\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:62.076146323233836\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:61.674121928711735\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:63.594190925359726\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.8420104260246\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.45420233160257\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.81394762173295\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:64.19429192241903\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:61.07561171054841\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:61.477473812798664\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:60.67678535977999\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:61.28080603977044\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:62.49431273589532\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:62.62928687036038\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:61.899115505317845\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.670544147491455\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:41.50780343140165\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:59.32077839039266\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.81413078308106\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:54.34100717306137\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:46.34976279611389\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-496026.51621500653\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-107161.66041056316\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-39720.14663696289\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-12219.145094553629\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-55559.82491811117\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-7828.058630625406\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:9.39116567373276\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-443.6707764863968\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-29.2162549495697\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-465.4196461041768\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-399.64334348837536\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:54.5397162437439\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:57.77916514625152\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:60.80967724323273\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:57.6321444970866\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:57.43576655785243\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:61.77411970992883\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:54.93207954180737\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:53.74873553713162\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:61.27615790814161\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:58.73281856377919\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:54.37819031377633\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:62.020014971494675\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:60.241477986176804\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:62.21565200636785\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.59567404290041\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:66.5022899582982\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.6660942658782\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.65713795522849\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.86160553370912\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.65389513969421\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.41124087075393\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.97124150892099\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.615073158095285\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.035416686596975\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.96196211874484\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-5901.358626683553\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-116819.86498514812\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-35464.034729003906\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-119028.4791692098\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-4515.471102396647\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-101176.2804967165\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-946.6814057032268\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-1442.667953968048\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-224.9496555328369\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:41.22550984223684\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-1016.6465322176615\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:26.017628510793045\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:43.43570586293936\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:54.21552880356709\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:52.98656081159909\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:47.639705936114\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:51.07006277268131\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:55.13180448363224\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:52.87298968061804\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:49.483626418902226\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:43.988095770279564\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:53.37829175094764\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:40.52207032839458\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:47.2203041613102\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:63.8961948081851\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.49080977588892\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.10987486069402\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:64.24533450355132\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.32931988189618\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:66.02474431196849\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:61.48781476542353\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:56.15677821139495\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.170015747348465\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:62.818715726025395\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.45838289459546\n",
            "Layers: 2, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:58.84610049426555\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-206618.18318684897\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-72317.45554606119\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-232940.27750651044\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-33023.59680175781\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-152654.3613688151\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-87197.40407307942\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-162.2893440723419\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-532.2071933746338\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1343.2625977198284\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-352.2448496023814\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-164.4973611831665\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-968.4691524505615\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:50.99942778547605\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:48.3814823627472\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:47.161706387996674\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:47.515741785367325\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:50.85174938042958\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:44.50979729493459\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.569391682744026\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.81706958015759\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.39997647205988\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:56.165018255511924\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:53.218824552992984\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.26729307572047\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:55.34873900314172\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:54.873214811086655\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:55.676845287283264\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:57.15280082076788\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:56.83765688290199\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:57.16790094971657\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.07130244374275\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:43.359313011169434\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:44.83089203635851\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:46.387268279989556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:37.543138240774475\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:35.57470420996348\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-121532.552429835\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-86489.35636202495\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-123932.00907389323\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-51435.57218551636\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-66677.25392659505\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-75613.31066449483\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-451.2693512439728\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1542.9766861597695\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-519.1745748122532\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1192.7848611275356\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-570.7564997673035\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-559.7233839829763\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:66.187144095699\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:66.71475641429424\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:68.50229191283385\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:60.931832014272615\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:62.49461809794108\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:60.43388269841671\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:54.50531517465909\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:52.126573473215096\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:52.739006231228515\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:52.008612056573234\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:58.74293364584447\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.50562152763208\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:56.25252215812604\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:57.37482346594334\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.39336777230104\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.2440799785157\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.70363632837931\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:54.091990043719605\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.74624647572637\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:57.83686789063116\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.638815954327576\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:39.2529571056366\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.34873914221923\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.84750179449718\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-54508.938878377274\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-24851.434733072918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-13767.688566843668\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-40255.41407267253\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-41256.31638844808\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-37157.937647501625\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-287.25943346818286\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-376.7128304640452\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-339.2374436060588\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-25.659790039062493\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-235.05743781725567\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-220.09701768557233\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:67.86358391245206\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:63.34265078107516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.97436262915532\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:68.6969758818547\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:67.13891361219187\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:69.2411988104383\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:58.476120928923294\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.11517708251874\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:60.18446095287799\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:57.25419215857983\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:58.26581021149953\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:60.60979043443997\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.57268486420313\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.20021528502306\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.90696515639624\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:58.40914382288853\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.96424075464408\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.40320779879888\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.397683511177696\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.482630824049316\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:27.566105773051575\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:38.30919921398163\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.70988515888651\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.67244220028321\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-9146.831442515055\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-17595.294138590496\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-49824.23645019531\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-6289.724706013997\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-13051.022885640461\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-85817.49287923177\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-16.275920867919915\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-57.093764940897614\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:55.67789395650228\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:47.70627578099569\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:38.75093142191569\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-102.15877751509348\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:61.945585453261934\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:66.90607514232397\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:62.23274709035953\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:64.38972876717646\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.11110328137875\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.04945154612263\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:67.19640431304772\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:67.45942277212937\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:67.93819793810447\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:67.32114657759666\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:66.86001248657703\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:66.70335396503408\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.38914313415686\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:55.491063594818115\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.494090567032494\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.79863300919533\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.327922215064376\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.963261460264526\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.419690534472466\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.59957816203436\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.32197322448095\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.94525095075369\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:58.26636239886284\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.534807965159416\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-737.666924794515\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-33706.848932902016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-7168.499997456868\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-17077.610677083332\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-18009.062957763672\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1328.0713272094727\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:54.652700424194336\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:48.844776948293045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:63.092835744222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:57.827160358428955\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:59.61436907450358\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-4.452658891677852\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:61.83313789467017\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:68.37956430390477\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:61.01569404204687\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:70.53645111620426\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:61.029079457124084\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.27633594969909\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:60.76081721733013\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:61.452091348667935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:62.76511392866572\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:63.46710524211328\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:59.52038075774908\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:63.09665467590093\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:56.18081822991371\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:56.23183893660703\n",
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:60.29821015894413\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:55.688751861453056\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:55.98740582664807\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:59.23903573304414\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:44.982406832277775\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:57.87539181609949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:57.479241192340844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.52128150065741\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.63324636717637\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.890024304389954\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:56.29681905110677\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:50.114809672037765\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-72.64488855997722\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:64.27138010660806\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:46.39701843261719\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:56.1182721455892\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:56.29407644271851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-258.9572485287984\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:58.402944008509316\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:54.1543964544932\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:62.34907786051432\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:61.48950258890788\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:61.03295185913642\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:64.79631386697292\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:62.48576230059067\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:68.27939038475354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:58.26602713515361\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:60.588216346999005\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:58.93526927878459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:58.17514279546837\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:58.2346468915542\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:57.63918578003844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:62.22724196811518\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:58.73877077052991\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:66.8322229385376\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.61789850145578\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.60321792960167\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.94031157592933\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:66.25119122986992\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:66.25925766925018\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.05324945847194\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.5344690233469\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.552776634693146\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.04823605219523\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:58.06097055474917\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.021932209531464\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-110408.45464070638\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-25602.398471832275\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-6824.81588681539\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-28412.548103332516\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-55276.66875203451\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-453220.072072347\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-239.70171491305035\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-866.8341283003489\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-792.1597552299498\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-611.5108201901119\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-191.48069560527802\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-771.0288878281912\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:59.59767657021682\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:58.841413110494614\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:41.34431327382724\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:20.61078106363614\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:17.786734936137993\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:47.69267226258914\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:42.660646935304\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.17846778035164\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.855286118884884\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:52.75543353209893\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:61.34544305503369\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.09812020262082\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:50.664618366087474\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.6468010507524\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:56.80400277177493\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:54.304732674111925\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:49.0252626563112\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:58.70353907346726\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:57.64235387245814\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:44.04927073667447\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:32.76458511749903\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:46.55263073121508\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:57.96723092595737\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:47.58628365894159\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-347525.27203241986\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-192655.19618988037\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-316917.0281442006\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-175293.15844217935\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-153600.53326924643\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-207858.7391535441\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-3466.4646784464517\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2243.4722995758057\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1324.76971467336\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1720.0270501772561\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1747.7841742833455\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3248.0033767223363\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:64.52024017771085\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:66.50304132451615\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:69.92312035212915\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:62.276405592759446\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:62.495154030621045\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:67.604014351964\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.62916221097112\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:65.91016846398512\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:65.3287744584183\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.9456157150368\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:65.1695350309213\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:66.38339805727203\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.88167732208967\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:48.03351587305467\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.93625785658757\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.86601046348611\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:43.81322446589668\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:40.7336539402604\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:48.23083606238166\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:40.095694487293564\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.43669381737709\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:44.1910607367754\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:50.12980033953984\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.3425078218182\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-60249.3955485026\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-31672.971356709797\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-120885.58639526369\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-64821.48955027262\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-115093.01259358723\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-63675.61073303223\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1231.040261586507\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-675.4408474763235\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-846.6175166765848\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1710.8401878674827\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-725.5078758796056\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-872.4580542246501\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:66.56585474809012\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:60.96881203353405\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:66.52818215390046\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:67.87096011141935\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:64.06610333671172\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:68.07160660624504\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.65755165865023\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:66.28534653883737\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:67.14969324568906\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.45465361637373\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:64.41379224260648\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.46148502578338\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:59.55311535547176\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.87201273938021\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:62.79024213552476\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:63.799464466671154\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:61.93101899077496\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:58.52992174215614\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.91810219758191\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.6932662675778\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:47.66431322942177\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:57.18100043013692\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.58155443767707\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:46.20309451594948\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-25091.079034805298\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-10326.915117899576\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-13453.903026580809\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-9646.345157623291\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-9422.485415140789\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-33224.6998723348\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-72.59678363800049\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-60.49870053927104\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-155.31094948450726\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-58.109091520309455\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-115.92703481515247\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-45.956000487009675\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:63.119806100924805\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:67.0498242477576\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.58179462949435\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:61.89929798245431\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:68.38614478707314\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.24125395715237\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.58833309511344\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.2353459186852\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.72908671200275\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:68.11020988970995\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:67.0246388266484\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:68.04469344516595\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:64.17012905081113\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:61.112943198531866\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:64.59515831122795\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.23196736723185\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:63.53387425032755\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:61.32359417776267\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.638191613058254\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.527937479938075\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:49.274950201312706\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:42.94169895350933\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:42.50222665568193\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:45.87794209520022\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2754.228180249532\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-2320.2616278330484\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2315.6192906697593\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1898.926150004069\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1054.6854623158772\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1508.8778549432752\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:62.25300148129463\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-97.99516593416533\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:57.94525479276975\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:61.04485273361207\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:62.92081256707509\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:59.54527219136556\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:47.64139498273532\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:54.936369086305305\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:61.9505480180184\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:58.90193288524945\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:59.40963603556156\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:56.60588073233763\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:60.5053523927927\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:62.128613467017814\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:58.08468068018555\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:62.11588726068536\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.1550293713808\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:56.789277891318\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.39241620649894\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:66.2162736679117\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.43998333315055\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.42590303967397\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:66.1865958943963\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:66.0902101546526\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:57.91245142618815\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.4530239365995\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:41.80083646128575\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.864935321112476\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:63.31322139749924\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.93995166073242\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-10170.535907745361\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-124.94577407836913\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:64.68339284261067\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:58.863271077473954\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-142.14029947916669\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-551.0092798868815\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:67.2260336081187\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:50.337204138437905\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:64.01452700297038\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:61.18500391642252\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-7.686891158421827\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:57.86203066507976\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:48.32429895798366\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:58.146805614233024\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:58.21504640082517\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:39.28575995067756\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:45.79151123762131\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:53.58029325803121\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:49.429398626089096\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:56.44916233917077\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:50.73745273053646\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:41.416235268116\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:48.361659087240696\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:51.00335129847129\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.87278700744112\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.32928880055746\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:66.29228295137484\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.93896409496665\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.28676832591493\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.37923339133461\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.573326334978134\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:61.186782370011\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:61.44456852227449\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:55.64102792491516\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:56.820125468075275\n",
            "Layers: 2, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:62.75886684656143\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-607440.0398763021\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-597936.7142740885\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-620468.7923177084\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-384567.32462565106\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-48238.579457600914\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-54670.86883544922\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-9025.19318898519\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-7885.640684763591\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-11116.409784952799\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-5971.890474955241\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-12138.081639607748\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-19197.713877360027\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-446.69084548950195\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-582.9774077733358\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-591.7390608787537\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-437.4625984827677\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-343.1576689084371\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-347.1463370323181\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:48.58393311500549\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:57.077523233989865\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.72331753248969\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:48.90432586272557\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:49.75298543771108\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:46.838369866212204\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:55.70415679365397\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:55.74267412225405\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:49.794514533132315\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.11556066324313\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:54.67342887073755\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:14.750587542851768\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.25001342346271\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.70274741202593\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:46.37099288403987\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:55.27075024632116\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.237391700347274\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:58.06300339599451\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2016947.0817057292\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-841606.8192036946\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-1208455.6953938801\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-765497.5026448567\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1071853.4393310547\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-2185791.3614908857\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-9261.66979153951\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1749.0421601136525\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-3825.86727142334\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-19208.711528778076\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-19187.863235473633\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-13577.697251637775\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-79.13179357846577\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-141.52683575948078\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-43.65412930647532\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-25.85888753334682\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-58.01654974619548\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-26.902581254641223\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:59.367111871639885\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:58.474200119574874\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.8749352445205\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:53.671908676624305\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:59.48964563508829\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:57.730668485164635\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:51.95773402849832\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.802067150672286\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.52940638363362\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:52.28421370188395\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:51.67088861266772\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:54.43263982733091\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:52.07783145209153\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:57.081476859748356\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.3439391994228\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.98680946975947\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:30.132098918159798\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.56790863183172\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-763894.4588979085\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-732759.1545740764\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-527435.5810546875\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-813834.0509033203\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-142405.6130218506\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-101237.83997217815\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2777.1453964710236\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-3203.507081270218\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-504.3922511736552\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-4027.1429856618247\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-3266.598703066508\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1768.34423383077\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:62.28426436583201\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:59.774417243897915\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:49.66774225234985\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:41.33242756128311\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:63.458704253037766\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:54.54743796338637\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:63.70923372606436\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:66.16804469997683\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.54948028177023\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.50868437687556\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.05874096726379\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.06787991772096\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:56.61626860499383\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:57.45813551669319\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.21158819397291\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.78892030070226\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.067815949519485\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.87729458759228\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:45.9264932324489\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:57.215964868664734\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.43317287663618\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.17855833967526\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.59287851303816\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:57.78295521934827\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-30178.016153971355\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-145827.54201253256\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-176995.99365234375\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-43017.2540473938\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-164471.56255086264\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-94566.56701246898\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-1743.974075317383\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-811.4856394131979\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-656.4233493804932\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-721.901687781016\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-651.5214689572653\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1989.7975746790569\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.39564039309819\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:66.02990665783484\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:67.60410490135351\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:66.24939826627572\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:68.45084741711617\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:68.20930575331052\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.99219288987418\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.51659583051999\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.06143938998382\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.80573127915461\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.87719497581324\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:66.32921930402517\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:56.85234437386195\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.96250535051028\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:61.59905910491943\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.17061420281728\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.61433477948109\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.72053797543048\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.92211932937304\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.181378930807114\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.458604936798416\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.66300507634878\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.086432119210556\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:56.769387647509575\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-7607.336153984071\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-11373.749097188313\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-8452.542839050293\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-6379.720204671225\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-19428.488381703697\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-2507.3816426595054\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:17.48365561167399\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-29.767990112304688\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:29.659142494201664\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-27.792607943216964\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-87.87442763646445\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-40.03518939018249\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:68.16056569417317\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:68.13552675147851\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:68.50016040106614\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:68.91923699527979\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:67.84857774774234\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:67.90976375341415\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:66.24509572982788\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:67.20224334547918\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:66.85117815000315\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:66.64553428689639\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:67.29925602674484\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:67.65777609000602\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.54643586277962\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.47927840302388\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:61.04159674917658\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.49638542657097\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.59991707156102\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.63743413736422\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.6603949368\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.40413941939673\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.83671856423219\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.19069486608108\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.726303771138184\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.26263522108397\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:62.40624745686849\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-2947.9004033406577\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:63.63349914550781\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:61.382293701171875\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:60.459284782409675\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-640.7617489496868\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:51.44684553146362\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-12.351392110188808\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:52.663273811340325\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.35950712362924\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:44.51060632864634\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:12.12454239527384\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:56.488449151317276\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:59.87157394488653\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:61.47279664874077\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:61.36088284353416\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:58.40206076701482\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:63.87727875262499\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:59.92304409543674\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:55.809345220526055\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:54.94602189709743\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:57.43805062957108\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:52.65071599433819\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:58.09325639779369\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.47340801606576\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.32180612906814\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.72120214502017\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.68954038744171\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.6410135080417\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.77621428916851\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.46399064858754\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:57.17245377600193\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.89475559691588\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:60.28876899431149\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.86334736148517\n",
            "Layers: 2, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:60.71715840448936\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-30685035.130208336\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-12237234.576822916\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-17887399.375\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-8438159.1015625\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-30780198.671874996\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-38886286.119791664\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-7862.083276112874\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-54378.25012207031\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2774.196783701579\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-27565.852292378742\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-36153.94045511882\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2990.8372259140015\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-246.41291081905362\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-84.7207772731781\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-127.68273631731671\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-271.74578607082367\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-169.72244560718534\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-188.16879351933795\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:57.70869851112366\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.06463677684465\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.450501546263695\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:59.8799095923702\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:56.98201437791188\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.77162412802379\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:43.81867531687021\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.36826206867893\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.56790575633446\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:51.28556614896904\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.022361278533936\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:57.72563974062601\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:55.95234523216883\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.476729352027185\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.537708638856806\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.76216773812969\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.00596700608731\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:56.04005441069603\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-2579321.0820007324\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-6808887.463277181\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-7645202.9801432295\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-3286561.260681153\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-10234065.229492188\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-3835402.5585937505\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-5770.311245123546\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-17050.622952779133\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-5567.7498809496565\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1767.4618411064148\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-19422.181433439255\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-8499.644783735275\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:48.57680719345808\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:38.16985045870145\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:43.23732058207194\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:51.35249300549427\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:40.863438049952194\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:52.700809414188065\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.41124514987071\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:62.577379917105034\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:65.60907679765175\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:66.46813249836366\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:66.35971407095592\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.78882597138484\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:56.34024446209271\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:58.71484488248825\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.92967540522416\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.53258222341537\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:56.25079058110713\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.96494554231563\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.80529295653105\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.3215029363831\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.386387764786676\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.35359742244085\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.045932937413454\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.28109052528938\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-2329056.299235026\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-2356706.240259806\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-5181939.689706166\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-2066344.3408203125\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3041761.326967875\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-2411563.2247924805\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-4063.2664799690247\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-3189.294672012329\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1797.9672145843506\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1537.070659796397\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2110.550464093685\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-16115.304098129272\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:58.62052843285104\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:50.3364839653174\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:65.11160687853892\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:59.15284654125571\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:55.22433735430241\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:60.39162892848253\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.97076307112972\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.60336855302255\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.99894931291541\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.62733768175046\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:64.66635911725461\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:64.9669426927964\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.340306063493095\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:62.39673840502897\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:58.47856801003217\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:58.632395242651306\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:59.855080110331386\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:63.011917372544616\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.83695928255716\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.30433206508557\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.06051560988029\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:49.98319666211803\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:53.571923772494\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.02680714180073\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-819142.8096135458\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-300209.4465128581\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1193457.2926330566\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-140916.522509257\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1667288.5961914065\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-347526.2165959676\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-275.0951699912548\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-791.8765149513881\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-486.13023678461707\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-554.8418633143107\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-368.3513365189234\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-436.27499183019\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:60.48078518360853\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:58.59165872136751\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:61.10426758105556\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:59.484293597439915\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:61.62569044157863\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:59.17155956228575\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:61.329075073202446\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:61.20714426661531\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:61.549114271377526\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:60.875208775202424\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:62.56933995212117\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:61.654762243852026\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.26330182949702\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.3715285292516\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:62.52326773479581\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.58022609353065\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:63.92703449043135\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:64.2669119561712\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:44.28849176193277\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.35218985068302\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.5781810618937\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:50.97340670724711\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:51.83120121558507\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:62.17121532807748\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-57155.81453641256\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-14695.869731903076\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-851106.0416666667\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-38329.639835357666\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-50926.318041483566\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-384501.7842102051\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-98.05650214354198\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-1.9990877310434918\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-117.14495420455933\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:35.88519593079885\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-217.08174963792163\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-128.35122148195902\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:52.35747600595156\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:57.2845940416058\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:57.559788463016346\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:48.41508326431116\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:57.71387983113527\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:51.60828118522962\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:48.105537028362356\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:51.05641791597009\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:51.300684958696365\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:55.984064949055515\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:49.673503916710615\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:52.29726393086215\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.12181402246158\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.81727864593267\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:62.63316453744967\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:63.645299356430776\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.67663409436743\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.7690353790919\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:61.21416194985309\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.39256779849529\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:57.23789380242428\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.529922756055996\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:48.608000775178276\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:60.48278160393238\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-259256.57895406088\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-4592.598899205526\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-1388440.2876281738\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-447121.6965675354\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1135859.3248240154\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-632158.7301445007\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-857.5600759188335\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-19.092415968577072\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-1634.5044082403185\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-52.45139916737875\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-1121.3223310311635\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:0.6977582971254948\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:59.38482835888863\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:45.61378156145414\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:48.751161471009254\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:45.34172271688779\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:48.04855120678743\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:50.8151501044631\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:52.69468298802773\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:48.272688488165535\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:47.36218335727851\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:49.11387288632493\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:52.78661772608757\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:45.343615865955755\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:58.66030334184566\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:62.713511362671845\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:61.63778378317753\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:58.55747864892085\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:59.6506092697382\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:58.204633904000126\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:62.233688440173864\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:64.06014129519463\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:59.650710367908076\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:61.59912592420975\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:59.66154077400764\n",
            "Layers: 2, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:60.14785513902704\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-29841.752319335938\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-49392.489725748695\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-48777.53575642903\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-229569.11254882812\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-70578.81418863931\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-129423.80472819011\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:3.451359669367471\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-163.52363308270773\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1907.2970167795816\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-421.38976732889813\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-875.7956155141194\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1190.0667079289753\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:26.602566838264462\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:34.966136415799454\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:46.09146227439245\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:31.310160160064694\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:44.361475706100464\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:25.858582456906632\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.27840899924436\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:57.68570579588413\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.27714582284291\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:57.15120774383347\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.46574637293815\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.31952006369829\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:41.324906150499984\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:43.83320222298305\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:57.352288911739976\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:58.23151879943907\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:46.42460225770871\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:57.89596082021793\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:57.687666499987245\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:44.844210371375084\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.51451142628987\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:58.26119552055995\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.999992586672306\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:55.466878389318786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-177200.87849934897\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-196360.9246222178\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-179587.62893676758\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-158288.64122390747\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-238720.66019694012\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-175525.69887797037\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-880.0451715787252\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-643.6129748821259\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-544.5752775669098\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1520.2089500427246\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1481.3193615277607\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-639.6438618501027\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:69.87882059067488\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:62.52723064273595\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:61.707932303349175\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:62.645823185642556\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:60.74139042447011\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.63915894925594\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:55.490695337454476\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:55.774320885539055\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:54.2049986620744\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:53.532933443784714\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:51.91971495747566\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:54.042169650395714\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.305479377508156\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.65565836429595\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.32708831131459\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:55.198466032743454\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:58.07508923423788\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.99531277269126\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:49.28835578262806\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:49.56931757430235\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.33371920635303\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.77840585013231\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:44.406922422349446\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:54.17111532141765\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-101940.46508789062\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-33704.76779937744\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-83638.7814203898\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-33655.111668904625\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-91284.00903065999\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-96183.14687093098\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-515.2242676417032\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-789.6093956629436\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-444.89763100941974\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1127.806715965271\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1069.651764233907\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-594.2328612009685\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:63.645020288725696\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.35101226220527\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:66.78297949333985\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:68.77612208326657\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:63.940507769584656\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.36146579931179\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.90246859161803\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.14847828571995\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:61.43817329158385\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.04551863546173\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:62.09605612481634\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:59.01064222057661\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.031955068310104\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:54.219104448954255\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.073194389541946\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.5552263756593\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.61725072065989\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.46785947680473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.35752618561188\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:56.599628503123924\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:47.91060093790293\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:57.54992566381891\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.41543992732963\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.83369490007559\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-15871.053593953451\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-29876.063842773438\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-17463.03014119466\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-19398.532911936443\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-10321.275698343912\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-14794.795735677084\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-34.949127038319915\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-301.5377839406331\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:13.317896525065109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-702.3761630058289\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:2.144401073455815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-171.73134406407672\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:63.50809879601002\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.37136804064114\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.5323446393013\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:67.83009395003319\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:63.44608638435603\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:62.111260406672955\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:66.85700722038746\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:67.7409074579676\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.70382916616897\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:67.98985956391941\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:67.68459685146809\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.78034778187673\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.84702051679293\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.181303779284164\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.39138217767079\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.7269036869208\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.778327037890755\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.89491299788157\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.325182132422924\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.91386033470431\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.5377613355716\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.39724595348041\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.09150049214562\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:58.1691404680411\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2728.0926736195884\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-119114.5819091797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-9297.349739074707\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2168.791364034017\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-975.950158437093\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-15112.533651987713\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:26.80824230114619\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:59.07273014386495\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:29.19881463050842\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-74.98175005118053\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-62.84995794296264\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:63.252538442611694\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:63.706652484834194\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:66.50002064804237\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:67.55123401681583\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:67.26679967095454\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:64.91280809044838\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.83474318186443\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:59.92868426255882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:61.79633832226197\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:56.41222532838584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:61.91106450123092\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:60.98706096721192\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:61.783973972002656\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:57.463533319532864\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.7734442303578\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:55.809082388877876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.416615871091686\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:55.61364270746708\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:55.23181289434434\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.690869465470314\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:55.945392623543746\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.96449475983778\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.47888177136579\n",
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.70517505457005\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.23789749542872\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-18831.02419892947\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:60.58310508728027\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-65816.54571533203\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:60.88297526041666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-19.9046007792155\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-285.21602630615234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:48.179562091827385\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:58.3711302280426\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:64.35881853103638\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:59.59761162598928\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:64.46103751659393\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:59.55357829729716\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:66.01624136169751\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.40318603316943\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.02913179496925\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.48887894550958\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:63.62997571627299\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:70.03019661953051\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:55.204592042913035\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:54.58142613992095\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:50.06529254217942\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:56.41354997952779\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:55.92726862678925\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:61.466227571169526\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.94684548676014\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:67.20615461468697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.64922367533048\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:66.2810888638099\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.46111009766658\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.65081298351288\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.52700234949589\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.2614829192559\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.84471559524536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.00780181090037\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:50.49399664004643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:56.5337577710549\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-134082.52494812012\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-94493.42661539714\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-214636.74089272818\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-8334.370756149292\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-91267.29479471843\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-111442.86879062651\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2085.172385573387\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-917.7083060145378\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-5168.054935534795\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1825.7330095767977\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-728.1451213359834\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-341.4948079983393\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:18.360557121535138\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:6.419150531291962\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-32.91326601058244\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:24.44192642966906\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-25.68904235959053\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-2.8252194573481937\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:58.285435891399786\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.97782972206672\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.7224276959896\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:48.42357408255339\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.824653637905925\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:59.967285494009644\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:48.47983539104461\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.66193578888973\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.73305806890129\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:50.13809701427817\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.202367560317114\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:50.36607791980108\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:50.18892631245156\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:45.997751355171204\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:40.43559888998668\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:46.42615502079328\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:56.05774072930216\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.52532975065212\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-767211.2516276041\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-760225.202217102\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-744165.7634480795\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-718484.722035726\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-665390.2837880453\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-1433037.848917643\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-9733.643302122751\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-15829.644175370535\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-8196.427687009174\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-9964.13910150528\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-9350.284318129223\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-11376.884886423746\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:52.45537253717581\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:56.85338859756788\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:39.73043445497751\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:47.724572618802384\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:52.43793821583191\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:51.30913563072681\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.909186236560345\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:64.06537766257922\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:65.02506836007038\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.56826928382118\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:65.9611112003525\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:65.0672974685828\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:59.113254137337215\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.411511950815715\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.305511193970844\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:57.98712616165479\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:61.51354658106962\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:59.43724351624648\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:56.4834283106029\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.41154084416728\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:35.025713667273514\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.462372633318104\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:45.170428181687996\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:52.58974372098844\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-394644.1181945801\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-304956.51240030926\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-298287.20391591394\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-418119.4613647461\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-249119.03660456341\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-455210.81033070886\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-4413.5950823624935\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-859.9237648646036\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-3629.000988006592\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-4768.890822728475\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1245.890338420868\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-2397.4070858955383\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:57.397937079270676\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:62.60096843043963\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:53.65597973267238\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:65.01425529519717\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:59.36357493201891\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:65.84334095319112\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.53120812401175\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:66.05961387666564\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.23120069876313\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:64.11920566422245\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:66.4747332657377\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:66.35430176431933\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:64.07948568463326\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:60.50103240956864\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:65.46824865664045\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:62.50451936386525\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:65.08841861815502\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:61.978125739842646\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.57130768150092\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:41.33950381229321\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:33.63590270280839\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.347771784911544\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:55.85309454550346\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:49.27228709682823\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-90528.91284942627\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-37358.49798838297\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-60747.42889404297\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-125624.08133188882\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-106090.24205525716\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-46541.425577799484\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-181.21581763029099\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-1306.138563156128\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-541.403774023056\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-694.5227773984274\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-818.0704096953074\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-1269.5732736587524\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:65.55502143998942\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:68.20793315768242\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.00792469208439\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:66.09364986419678\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:63.85605905825893\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.64798803130786\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.55754606674115\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.11498257517815\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.9597885881861\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:63.266609106212854\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.57974512378375\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.76780246570706\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.12415409088135\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:65.73422368615866\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:65.82465418304007\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.67731538166602\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:66.28593541060886\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.6493853777647\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.040391869843006\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:55.19840009510517\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.117896375556796\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.280623539040484\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:58.01518081997832\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:45.96825776621699\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-306371.1712392171\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-10357.428169250488\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-10022.907015482584\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-269070.01330057776\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-3552.818937301636\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-8093.806292215983\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:11.464718182881672\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:39.09715255101521\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:31.765093803405765\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-136.18092348178226\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:41.847622791926064\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:0.4655019442240449\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:61.853084787726395\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:64.92948969205221\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:59.895577281713486\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:57.87042823930582\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:61.987781027952835\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:64.49866766730945\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:56.67552962899208\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:57.29858043293159\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:54.78033961107334\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:54.807695162793\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:56.89422467102607\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:59.04025486049554\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.53377278149128\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.67146083960931\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.15437389413516\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:66.33158924678962\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.47219730913639\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.66167681788404\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:61.82469190408786\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:58.37593442449966\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.05657095710437\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:60.26652775704861\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.04721224308013\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.122418797264494\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-3643.2841491699223\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-732.0458571116129\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-4889.675073623657\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-784.1241979598999\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:62.88825352986653\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-4214.561354319255\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:65.24413426717122\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:66.17762235924602\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:64.50623512268066\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:59.666242599487305\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-4325.212990442912\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-534.0277874469757\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:54.62683379650116\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:54.960907002290085\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:60.83522108693917\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:58.34622281293073\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:60.28007194399834\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:47.37418023248513\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:52.851401190273464\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:46.32806472480298\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:47.91149454812209\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:43.75641919672489\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:54.78232989708582\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:50.03275167196989\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:61.84288661926984\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.513575086991\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.76735120328765\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:60.56550158808629\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:63.23011839141448\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:63.514403545608126\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:65.85815785452724\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:65.91406681885321\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:64.10289209956925\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:62.686621658504\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:63.18323977291585\n",
            "Layers: 2, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:64.09636801729599\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-4163676.751302083\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-823447.596842448\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-2491351.34765625\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-1044505.9098307292\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1796074.777018229\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-2107358.92578125\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-49525.25436401367\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-53493.566436767585\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-14825.287831624348\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-14997.807057698568\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-4255.381368001302\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-7449.537811279296\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-1618.2546520233152\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-1115.8913056055703\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-1302.5321118036907\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-746.5984161694845\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-1560.0830634435017\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-1466.1412715911865\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:-17.53580073515575\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:12.46954540411631\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:7.722498575846359\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:-25.446900924046844\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:-43.70956579844156\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:-12.01941827932993\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:56.08370362470547\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:52.212722077965736\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.45255997776985\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:48.27653098851442\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:51.72036923468113\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.02382997671763\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:58.389938840021685\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.454741321504116\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:57.16952464853724\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:57.04169437599679\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:57.64542981982231\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.889266600211464\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-3824336.92199707\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-1260814.6575927734\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-2768258.4708658853\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-2956183.926188151\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3157564.6978759766\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-2953439.7493489585\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-52221.43784840902\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-48201.58142089844\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-49990.44853210449\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-20017.247772216797\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-52728.83079528808\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-9203.233623504639\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-556.396857102712\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-532.1808012326559\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-218.1841766834259\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-531.4953891436259\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-589.9474930763245\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-429.40320730209345\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:54.1219848394394\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:50.36955157915751\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:50.02818703651428\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:50.416207114855446\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:53.835492730140686\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:58.33935858060917\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.408941378196076\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:58.63631377617517\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.9556935876608\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.12270648280779\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.27622729539872\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.63995636006196\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.44205220292011\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:50.759134398152426\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.39167958001296\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.231331929564476\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.13755711043875\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:54.197230661908776\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-3477843.1229654946\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-3725666.7805989585\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-3060637.483723958\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1529948.3658599854\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1595299.3237304688\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1318620.4212443035\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-3415.214287439982\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2940.080313682556\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-26041.113834381104\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-5319.702576001485\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-14656.087690989176\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-20164.42089398702\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:36.721451878547676\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:-96.89754645029704\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:-172.39277402559918\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:-43.830893039703376\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:53.281942208607994\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:-186.70533816019693\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.31098617861669\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:60.509871852894626\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:60.93690499663354\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:60.27606050173442\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:61.31987132132053\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:62.36274791260561\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.30688244104385\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.64789952337742\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:59.555166053275265\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.75539086262384\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:66.55574625978868\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:59.13820896297693\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:54.69222113490104\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.83816534280776\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:58.81093793238203\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:56.60319366802772\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:58.06306991105279\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.853507101535804\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-589852.6340738932\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1030564.5814005535\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-283275.8651987712\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-397868.22194417316\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-540250.8756510416\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-334059.4186401367\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-833.8656131426493\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-1916.7670194307964\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-6061.662464141846\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-4186.690121094386\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-7396.271177927653\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-7697.351098855337\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:61.8623297320058\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.76792737841606\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:49.02260025342306\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:50.454997320969895\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:45.60228163997332\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:38.42279985547066\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.8794132558008\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.81948169507086\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.26406918590267\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.99295545679827\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:66.32330828967194\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:66.00050778438647\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:64.37470342963934\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:62.22526066005229\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:65.31448295960824\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.63372953484456\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:65.30823271566382\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:58.63231652726731\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.477284039060265\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.06410021086534\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.66559564073881\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.974799389640495\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.84710379938285\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.44914743304252\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-71496.77866617839\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-37442.71353085835\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-38061.12600326538\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-56610.37850697835\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-76835.8311978976\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-68311.93615595499\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-184.8770427703857\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-342.38889455795294\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-437.03648090362555\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-713.3128547668457\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-617.4371433258057\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-549.146683216095\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:66.68702058494091\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:67.70744054267803\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:67.49570315082867\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:67.0718540251255\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:67.07611881196499\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:67.35678300261497\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:66.95116390784581\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:66.65084522372733\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:66.85625722631812\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:66.84320932875076\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:66.99886016082019\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:66.57728412499031\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.45699909329414\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.48636915783088\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.5865253135562\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.47319645682971\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.37492943306763\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.34244285275538\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:57.01887359221776\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:57.07758076488971\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:58.08506158490976\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.47725555797418\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.944552049040794\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:57.11601960162322\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-59129.756774902344\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:30.88524823387464\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-4048.8712882995605\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-5095.601552327474\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:42.9720687866211\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-547.078603108724\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:0.9821160634358672\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-90.83039045333862\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-75.65128803253174\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-37.148468891779586\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:17.037021120389305\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-30.389480590820316\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:63.47654074430466\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:62.971777468919754\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:67.67236693451801\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:67.46980393926303\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.85920244455338\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:63.65735987822214\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:62.22204772134622\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:64.4983904560407\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:62.305139886836216\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:61.5644919872284\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:61.78563756247362\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:66.29879867037137\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.47362924243014\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:65.9031811915338\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.81400502473116\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.5249709325532\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.71707978844643\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.76549872135122\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.37916124612092\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:58.03923261662325\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:63.89375019818544\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:64.1591381529967\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:63.547284455659494\n",
            "Layers: 2, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:57.218872594336666\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-48419456.197916664\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-22547561.041666668\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-49901632.395833336\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-61782551.041666664\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-19326720.10091146\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-65698480.15624999\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-58092.189102172844\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-46088.878173828125\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2710.178144176801\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-44013.4874979655\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-10938.769454956055\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-19022.90761311849\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-594.6096221605937\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-563.6724384625753\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-727.4614810943604\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-841.3942329088848\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-434.72697536150616\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-569.1501839955648\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:42.430192629496254\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:44.52646732330322\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.311496049165726\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:48.92855097850164\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:47.295942455530174\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:43.73685439427694\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:56.33498990908266\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:58.27373318374157\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:55.826816012461975\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:43.58874172593157\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.45587411647041\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:47.534847712765135\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.939063725372165\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:56.58361637033522\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:58.695423658937216\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.64977758439879\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.586649118612215\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.15426473878324\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-6694338.952433269\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-35537366.13484701\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-117462919.2154948\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-41724370.322265625\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-6399175.246175131\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-8291320.010223388\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-50757.34591166178\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-27807.570408185326\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-66397.7871799469\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-91083.12584559122\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-67518.95707448325\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-166313.13016255698\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:28.22259778777758\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:21.078798882663254\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-39.59231714407603\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:8.940508589148521\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-57.442311445871994\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:32.262784615159035\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.50066797807813\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.658813151220485\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.88924227034052\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:63.30413202444712\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:63.423355466996625\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:63.80868320663771\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.2320302526156\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:57.68894478678703\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.32085335999727\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:58.49353569249311\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:52.274776572982475\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:58.99872997154792\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:56.32250070882341\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:59.28729298214117\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:59.62129674851895\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.66611509770155\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:59.07080765503147\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.773147601634264\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-8694142.362594604\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-6655540.027262369\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-13995345.747884115\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-1883979.226996104\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-5879925.030619304\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6397120.2880859375\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-20830.940044720966\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-14306.263529459637\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-68329.6392095089\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-19051.14410797755\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-5784.564429918925\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-38144.150269826256\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:54.719387615720436\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:37.506999423106514\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:48.192407712340355\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:37.711549128095314\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:43.57421858857076\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:19.774215991298362\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.05515317743023\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.62562019253771\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:66.09820730984211\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.4477390119185\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.76398493101199\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:66.22057425168653\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:63.42181321233511\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:64.65877097720902\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:63.51013277967771\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:64.18369451072067\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:63.27781764790416\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:64.83591036250193\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.521837962170444\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.26430531467001\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:61.81115090847016\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.25606565487882\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.3370970475177\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:59.10566449165344\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-2743372.458902995\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-3113134.75596269\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-8224428.39111328\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-5096851.333414714\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-5009258.804321289\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3218473.0292256675\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-3545.3632871309915\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-2443.5962661107383\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-4455.409619013469\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-5334.664373795192\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-2802.3394775390625\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-822.0571819941202\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:60.04028105487427\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:55.94362329381208\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:61.40465859323741\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:57.57972054183483\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:56.90882173677285\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:59.73136467238267\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:62.79511864607532\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:63.4261830461522\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:63.52177830723424\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:61.43058904757102\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:60.521934988598034\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:62.20646972457568\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:66.63110659768184\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:63.16001425807675\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:63.39557962492108\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.35398704310258\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:64.61625113462408\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.47592498517285\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:59.165092408657074\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.374370294312634\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:56.754372442762055\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:59.18257335821788\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:58.747118661801025\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:60.22331578036149\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-851263.594754537\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-5407137.369283041\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-494391.2144788106\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-693801.8031771978\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-226098.75732421875\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-5359524.8681640625\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-394.67123071352637\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-142.8749454021454\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-284.70259467760724\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-6624.72271045049\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-1223.3148177464805\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-4396.186193029086\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:51.10204071427384\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:53.570684952040516\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:56.290292454262584\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:61.0988212004304\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:51.75121499846379\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:54.99019781127572\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:53.00622052823504\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:52.0967523008585\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:55.93055033435424\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:54.24756109714508\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:54.363013642529644\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:52.43247484167417\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:63.86830996721983\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.81841608261068\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:63.88333749026061\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:64.39037683109443\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:63.680037297308445\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.35403106734157\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:58.743017067511886\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:62.23423068101208\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:61.24744463711978\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:64.62791364019115\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:62.197763224442795\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:62.14283358305692\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-442618.4902826945\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-9926.06012026469\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-2492907.2096443176\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-4213.367287317911\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-3095240.3703276315\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-32608.894545237225\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-21.926517486572262\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-8236.89322501421\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-1169.8944814999898\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-751.2242611249288\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-420.854256550471\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-5859.236027399699\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:51.18433786556125\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:49.386279328415796\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:44.881324588010706\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:46.354908794164665\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:47.103025068839386\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:60.66277305285136\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:53.137979389478765\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:54.51412393323456\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:51.132676945999265\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:51.52619956682125\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:50.955720165123545\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:52.970406680057444\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:49.04945075511933\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:59.10572156310081\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:56.32000676045815\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:55.65610658377409\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:60.54765238737067\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:54.38463692242901\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:64.88521483416359\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:66.20660603046417\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:62.67414674783747\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:63.49749765669306\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:63.854747408380106\n",
            "Layers: 2, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:63.39056672528386\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-11991.928100585938\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-293526.7403157552\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-52898.87247721355\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-453052.91422526044\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-134059.8974609375\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-28330.710245768227\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-997.5845718383789\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-164.63897705078122\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1873.5471979777017\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-299.29446935653687\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-589.4148278236389\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2260.8294200897217\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-1.6231997807820697\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:22.886156042416893\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-7.128849029541007\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:12.075096170107525\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:22.136820554733273\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-8.863465785980228\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.95699744919935\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:53.24684873223304\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.74402378002803\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:57.27254172166189\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.042930625379086\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.13377765814463\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:57.59278206154704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.960402466356754\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:57.46449296052257\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:54.59040625331302\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:57.56511093427738\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.8048316364487\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.26861901332935\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:57.402188293635845\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:47.01778137435516\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:37.54911785324414\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:56.54177068422238\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:56.69924692561229\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-354859.72595214844\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-464626.0821533203\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-450566.6474278768\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-307928.17668914795\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-347647.7597554525\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-406026.85445149743\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-4432.770752112071\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1462.5433681408565\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1626.8177227179208\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1305.5610179901123\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1904.6222966909409\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1459.5734192927678\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:49.48149472475052\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:46.36996400852998\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:64.28073190152645\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:66.12971100956202\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:65.42695065339406\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:44.358327885468796\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:56.525360395510994\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:54.783198932806656\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:56.36375191311041\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:56.81951406101386\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:55.39858870208263\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:55.098934198419244\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:57.52758723994096\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:54.14013688762982\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.97804969549179\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.78588526447614\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.14317809914549\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.144498996436596\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.74177725737293\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:58.20858761978647\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.99989659960072\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:56.8907550474008\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:55.05592938512564\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.68398109575112\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-76283.76718521118\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-100336.60095214844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-103223.64398956299\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-223593.94317626953\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-118287.52126057944\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-182533.71233622232\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1163.401397864024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1996.9581906000774\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-281.12320651610696\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1234.308578968048\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1779.112418492635\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-868.9695958296458\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:56.167430778344475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:63.554585725069046\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:71.12863627572854\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:58.50756905972958\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:60.485098635156945\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:70.44399209320545\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:67.1845618573328\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:66.94367038706939\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.51282203445832\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.27674800343812\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.22306398799023\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:62.96857910851637\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.33637153108914\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.42358201742172\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.8811373213927\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.7602236866951\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.23918044567109\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.2795396943887\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:56.45518202334643\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.74511580914258\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.592391534398\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:51.5621992200613\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.10190412029624\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:57.328610364347696\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-12356.636384328207\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-59474.69502766927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-27721.941159566246\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-88066.15028381348\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-13774.189608891806\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-35708.673219680786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-756.1499937375386\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-355.4654820760091\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-707.4514595667521\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-966.8224334716797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-403.06642949581146\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-357.0604421695074\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.97220034400621\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:62.06720317403476\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:58.297447860240936\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:63.6624538898468\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:63.98282205065091\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.31141753991444\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:67.41004236352941\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:67.360436655581\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.35309799015522\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.77581064306044\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:66.17130565457046\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:66.25737632935245\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.593419094880424\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.85039162139098\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.071504190564156\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.85039413968722\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.19808939099312\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.04840350151062\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:57.04178905735413\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.889793115357556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:58.31858532813688\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:58.0779520360132\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.04321781297526\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.56003371874492\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-8359.410820007324\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1216.1571629842122\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2019.0184275309246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-2861.486396789551\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-1252.0988337198894\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-66381.75699869792\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:50.13087828954062\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-172.46598124504092\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:56.473305225372314\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:54.43843364715576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-1.4428472518920987\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:51.20448907216391\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:62.7335516611735\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:63.27136879165967\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:59.316178858280175\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.96647029121716\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:68.4631842126449\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.06131892402966\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:60.92981131126483\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:60.524916065235935\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:59.646037152657904\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:58.66889681667089\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:58.5451815277338\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:56.46554492103557\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:56.07407271862031\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:58.37754194935163\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:58.310337364673615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:61.5236904596289\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:57.06807591021062\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:60.460429315765694\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.29539233446121\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.87581583857536\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.66391780972481\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.85730001330376\n",
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.34904575347901\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.17528743545215\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-106.24550183614096\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-2438.704840342204\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-45020.23086865743\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-5754.969847997029\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-400.413277943929\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-766.3487752278646\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:61.277915438016265\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:59.909202257792145\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:59.2312502861023\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:60.43656428654989\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:59.06423449516296\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:61.372395952542625\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:62.31738654275736\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:63.73653317491213\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:62.958556239803634\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:67.22955845296383\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:65.98621053000291\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:64.79459375143051\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:45.10199758224189\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:56.919862814247615\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:59.63644659767549\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:57.074209504450366\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:55.001892972116664\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:47.1380881095926\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.08989063402018\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.62184887379408\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.41373330789308\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:66.41262288515766\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.98738246286908\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:67.9007836120824\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.481562674045556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.735960414012276\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.033929109573364\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.8615605632464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.517074227333076\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 2, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.53811873992285\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1136184.3878173828\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-80714.9299176534\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-735028.4513346354\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-232150.10114034018\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-555408.6981201172\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1424994.9650065105\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-621.1575321356455\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1319.1409973303478\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1225.3050138552985\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-4625.323037902514\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-933.6481837431589\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-3808.436393737793\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-235.18027321745953\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-172.29825259496766\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-101.41969602555037\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-114.87060565501453\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-132.92891511072713\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-153.3734221259753\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:64.81679337099195\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:64.24880180507898\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:61.23385823021332\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:61.856940370053046\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:62.91084265336394\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:62.21244691250225\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.65303977951408\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:48.69747662916779\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:55.581803200766444\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:55.17211684336265\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:50.88810615862409\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:51.123655239741005\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.19158716251454\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:56.959124499311045\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.19320992504557\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.75990599083404\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.294191331913076\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:49.707225250701114\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-3913428.4572347\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3814072.703450521\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-4334395.471776326\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-2623827.221616109\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-4287030.181922913\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-3930629.27154541\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-35245.94486554463\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-24332.364729245503\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-43273.92322937647\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-34235.327118237816\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-41026.46217981974\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-36804.97259775797\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-24.647301410635315\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-50.44222079217433\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-142.45301271478334\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-79.26290494700272\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-138.40716063976285\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-186.42441518604755\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.63783626506726\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:64.60189217080672\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.32466582705577\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.03493117168546\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.76544188335538\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:65.92123538255692\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:65.76761538162827\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:64.79214432338874\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:64.74583669255178\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:65.84888384211808\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:63.14658916244904\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:64.38828904181719\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:46.92572583133976\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:46.59633968025446\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:58.903352096676834\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:51.151091189434126\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.368487680951745\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:49.83142974476019\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-632309.0870157877\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-624398.1794993083\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-376386.9543457031\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-607311.0184987385\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1944914.544881185\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-150510.08960088095\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-6230.781033833821\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-12369.782157739002\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-33078.00276438395\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-13613.383061091105\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-9627.729787826538\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-24160.337216059368\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:43.417296721599996\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:39.87627844015758\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:50.62931854277849\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:18.913325667381287\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:34.6211218337218\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:37.372449338436134\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:66.23546237746875\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:66.20475739861529\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.95280809948842\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.78985984126726\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:65.47803758954008\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:66.41982581776877\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:66.40966417888801\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:64.83130658666293\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:67.09574830563119\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:65.5875294469297\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:64.62838216063878\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:64.49112029125293\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:56.1741274393474\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.620083020379155\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:54.150021709501736\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:56.870048943286136\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.841913366069406\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:50.338052231818445\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-150885.55783589682\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-240397.94204711917\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-238761.35380427045\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-84322.58104960124\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-51679.62229728698\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-128406.18803660075\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-46813.78290653229\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-18308.21891784668\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1749.1531296571097\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-2409.226906696955\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-1718.4956487019856\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-3460.629437764486\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:61.23091394702593\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:64.37147530416647\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:63.786179951081664\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.87079529340069\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.52126818398635\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:61.39586597060164\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.88630656773846\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.9226087257266\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.72873396798968\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.11950880040725\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:63.49411282067498\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.01961194972196\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.00861937801044\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:65.84965318751831\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:66.20603821550806\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.48695881074916\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:66.05960042526324\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.2890002199759\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:62.105784614880875\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:59.19029209762812\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:60.52548947433631\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:62.742185170451805\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:59.90662341316542\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:61.60956433042883\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-20217.762603759766\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-11806.392822265625\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-24005.229949951172\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-17055.663776397705\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-24397.897275288902\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-32611.37413660685\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-13962.385153770447\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-170.22035241127017\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-1656.6703712940218\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-10443.99135907491\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-81.54219786326091\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-760.3657309214274\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:66.86041731387377\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:64.87602452437082\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:62.13951135675113\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:66.34324022879203\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:65.50946419437726\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:66.11554024120171\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:60.82380473613739\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:58.42896720394493\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:63.13337446500857\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:64.03312259664138\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:54.65346674745282\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:61.58686046488583\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.64457989608248\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.54480454325676\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.36485529194276\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.83740212023258\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:64.52367855856815\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:66.32256493593256\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:65.02438151588042\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:62.70261025677124\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:58.16440805171928\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:63.69533377854775\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:59.71968785859645\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:62.24974783758322\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-5114.516671498617\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-31127.91416168213\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-8748.503303527832\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-5574.223143259685\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-5343.082860310872\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:58.48182678222656\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-739.5042745272318\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:51.75883611043295\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:66.7636267344157\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:43.288758993148804\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:52.96472469965616\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-10.262862841288257\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:65.21943961580594\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.97556528945763\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:61.81679295996825\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:61.10624298453331\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:57.235989471276596\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:66.97160634988298\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:55.263704533378274\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:56.41554241379102\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:56.66138598074515\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:52.82754133145014\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:51.28841621180376\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:54.59439516377947\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:59.42727928360303\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.04576093579333\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:59.30663076539835\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:61.819450110197074\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:60.152991783494755\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:58.952244240790606\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:65.23592125624418\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:65.08110037694375\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:65.17296402404706\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:65.96460446715355\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:66.05644748779014\n",
            "Layers: 2, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:65.27743171124409\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-5797.577896118164\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-115623.91438802083\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-4540.667673746745\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-36813.202921549484\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-64448.616536458336\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-6758.990325927735\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-483.0041456222534\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-3.473367293675733\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-615.1960786183676\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:30.31023979187012\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-425.24192492167157\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-31.500541369120285\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:55.27344857652983\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:49.70496049771707\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:47.943919698397316\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:53.30734213193258\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:46.95506989955902\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.67006256679694\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:3.5938414931297347\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.05544611811638\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.48047981659572\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.911261608203255\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.18938888609409\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:52.63105740149816\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:53.1461892525355\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.172778382897384\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:47.548456589380905\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:54.841385334730155\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:47.173908303181335\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:49.33666249116262\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:33.65830031534036\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:30.22840211788813\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:1.9773946205774995\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.06021596988042\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.74537309010823\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.88820300499598\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-26515.926106770832\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-16474.495951334633\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-40556.8583170573\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-42774.15669759114\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-10446.70689900716\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-6573.848648071289\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:55.01772562662761\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-176.58509810765585\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:48.04715176423391\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-45.73699951171874\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:46.229841907819115\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-74.99715805053711\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:58.091105992595345\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:52.69781152407329\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:52.59009718894958\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:54.23441767692566\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:54.731869598229736\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:50.3085399667422\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:52.38640025258064\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:51.736100216706596\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:55.27579473952453\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:52.237150271733604\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:54.913095831871026\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:52.879908084869385\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:-1.0955433050791497\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.396585653225586\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:50.956128239631646\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:42.131883700688675\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.61097767949104\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:50.35002703468005\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:55.402070557077735\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:43.3814196040233\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:32.92333456377189\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:47.92367875576019\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:54.179016401370376\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:48.444946010907486\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-4439.039103190104\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-6434.750874837239\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-29153.096516927082\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-11368.137105305988\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-5917.817433675131\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-9998.50565592448\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:2.276622454325361\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:46.325511535008744\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:55.08930325508118\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-22.27636516094207\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:56.15558147430419\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:53.07476838429769\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:66.77113647262256\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.25272751847903\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:58.64891757567723\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:65.89932685097058\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:68.4621549770236\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:56.256103118260704\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:55.01465417444707\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:51.98785454034805\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:53.81184220314026\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:54.2532920340697\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:55.152272383371994\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:54.597736497720085\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:35.38368453582128\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.654503829777234\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.76611938079199\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.513190150260925\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.2397382458051\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.54491193095843\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:45.00255982081095\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:56.81730215748151\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:52.91426402827104\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.55825543403625\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:50.70998653769493\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:51.34817361831665\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3261.4468892415366\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-974.481455485026\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-10077.476755777996\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2830.713399251302\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-3004.0585835774737\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1274.4873682657876\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:56.24324361483256\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:46.61282380421956\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:51.03468815485637\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:55.639458100001015\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:55.06666044394175\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:55.5132532119751\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:71.53051470716794\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:68.5886160035928\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:68.24970323592424\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:67.78367443010211\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:69.15310708185037\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:71.05872616171837\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:54.95550175507864\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.78281382719675\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:56.0691590110461\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:54.36758533120155\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:54.74548270304997\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:55.45510550340016\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:51.76214252909024\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:46.51697397232055\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.729125459988914\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.345736414194114\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:53.461980472008385\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.40413942933082\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:19.671061684687928\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:-32.2803979118665\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:37.49523932735125\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:52.85017723838487\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.75996978084246\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.79782057305177\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-113.19834391276041\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-888.8734181722006\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-132.85039265950522\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-155.65210978190103\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-91.8866793314616\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:15.355428059895837\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:53.09153874715169\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:53.167111476262406\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:53.87929697831472\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:53.75798384348551\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:53.67193152507146\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:52.68834670384726\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:71.32105906804402\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:70.49247230092685\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:68.7830944514523\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:71.1795822220544\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:68.36905250946681\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:67.4768968174855\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:59.504293973247215\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:68.47546122968197\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:62.87543885409832\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:68.44530428449313\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:68.75173218548298\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:68.9668391396602\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:53.70669533809026\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.57254058122635\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:53.544701387484864\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:53.92678067088127\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:54.21528870860735\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:53.947093933820724\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:47.50677190721036\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:-8.89518330494563\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.464537362257644\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:-12.471469144026436\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.27571074167887\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:52.699036796887725\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.36405436197917\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:53.36983998616536\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:53.36507161458333\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:53.39590708414714\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:53.38153839111328\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:53.391774495442704\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.51581096649169\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.3847161134084\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.44277620315552\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.38352998097737\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.37994853655496\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.386389116446175\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:60.586860344434776\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:74.14237961173058\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:70.95481639107068\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:71.00075808664164\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:72.2167707234621\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.7683636744817\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:68.3430512001117\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:70.42964740966757\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:70.68892459074657\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:68.65712771813075\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:67.73178088168304\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:66.81090071797371\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:54.32679263254007\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:53.91073599457741\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:54.913567900657654\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:55.27712712685266\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:61.26915562897921\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:55.532531241575875\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:33.15562811990579\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.95673301319282\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:30.68953543901444\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:35.09446601072948\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:49.29840090374152\n",
            "Layers: 3, Neurons: 4, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:57.86379354695479\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-890745.3518168131\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-11128956.868489582\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-33084865.572916664\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-6418281.010843913\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-9115896.020507812\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-480872.33886400855\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-5958.990589777628\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-975.4322361946105\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-835.9565619627634\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:33.049055536588035\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-2782.0725854237876\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-535.1448309421539\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:54.442081252733864\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:55.38631667693457\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:49.53705350557963\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:59.127847887575626\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:55.43262239545583\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:50.37116040786107\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.68755207459132\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:52.96987190842628\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:49.34602605799834\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:9.028378824392957\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:12.560312847296395\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.90256728231907\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:16.688397626082107\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:1.0582410792509767\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.590285703539855\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:49.25472637017568\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:33.75689906378587\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:49.36238765716553\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:52.65183255076409\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:33.17498681445916\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:58.25721539556981\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.486989587545395\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:47.37451163431009\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:35.734425957004234\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-9121.079508463543\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-243985.58756510416\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-79172.38972981772\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-7003.9906819661455\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-1131.758244832357\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-54075.31534830729\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-632.2396119435627\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-439.45973714192706\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-419.64701016743976\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:57.50896533330281\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-956.7953745524088\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-474.9809106190999\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:65.57725478584568\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:58.23044548432033\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:65.18348577121893\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:53.50850601991017\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:64.74071594576041\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:56.53133789698283\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:57.78049277762571\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:55.68092030783494\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:54.205793589353554\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:58.918512488404915\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:53.48210106293361\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:59.447126189867646\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.58396719892819\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:43.166313295563064\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:14.2456217110157\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:58.049367417891816\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:31.50814111034076\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.375632421423994\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.35958728939294\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:57.15408969670535\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.392386071383946\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:56.52340856691202\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:50.36048874258995\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.74877517422041\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-101815.05533854166\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-121117.58626302083\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-122968.82731119792\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-61458.516438802086\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-99820.31046549478\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-23033.796183268227\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-73.98840586344402\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-302.4750391642253\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-145.67883809407553\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-31.62802060445149\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-182.93608029683432\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:34.451564153035484\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:69.72018395860991\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:63.289979224403695\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:69.03376954297225\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:68.65022194882233\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:68.00939814498027\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:64.80689093470573\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:55.3215785821279\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:58.07404165466627\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:54.393473764260605\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:60.91216559211413\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:56.01594110329946\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:59.21414002776147\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.2007799645265\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.734806408484786\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.018864274024956\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:49.29924324310074\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.84729763368765\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:13.229779650767648\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:6.490928580363587\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:2.5529572367668174\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:56.047834567725666\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:46.34264503916105\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:55.636890499542154\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:55.222639888525\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-862.1011098225912\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-25979.001871744793\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-17513.0381266276\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-2734.8440806070967\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-9616.14939371745\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-20365.41188557943\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:22.421338160832725\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:12.369449933369959\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-58.20568402608235\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:19.042412439982094\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:52.725350856781006\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:58.09243520100911\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:66.53059874971707\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:67.76329506188631\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:68.38095525900523\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:69.60663688679536\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.98474030693372\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.79503857220213\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.23775225877762\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.86051050201058\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.38287726789713\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:68.33703272044659\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.78320473432541\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.65895341336727\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:51.83107331395149\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:7.1479088068008405\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:52.97662491599719\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.925732101003334\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:50.11576938132445\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:54.789970691005394\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:13.677054395278299\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:52.14384863773982\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:23.769590208927795\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.48832855621974\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:50.628520200649895\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.11730109155178\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-12480.660756429035\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-948.335329691569\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2419.359079996745\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1385.7577006022134\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-11.699422200520825\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-439.2751057942708\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:53.32437753677368\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:52.6730219523112\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:53.90886664390564\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:53.648335238297776\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:51.98092857996623\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:52.523016929626465\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:69.35122055311997\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:59.48620634774366\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:70.59446074068546\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:70.3295802573363\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:62.74861183638374\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:71.41166552901268\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.36922872066498\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:66.18387224773565\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:68.50917997459571\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:66.64111539721489\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.6317575275898\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:69.35385716458163\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:61.69367178032796\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:54.89150770008564\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:56.81808235744635\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:55.05041472613812\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:60.60752322276433\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:58.49132522940636\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:16.191141009330746\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:56.71506829559802\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:52.894080703457206\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:39.47440621753534\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.47204285860062\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.74694599707921\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.544680277506515\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:53.42693328857422\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:53.414154052734375\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:53.378550211588546\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:53.424008687337235\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:53.538386027018234\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.38250398635864\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.38201423486073\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.38197648525238\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.382838765780136\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.38251193364461\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.38263114293416\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:53.382154305775956\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:68.8358589510123\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:62.22397719820341\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.67413183612128\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:71.31701762477557\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.5395695567131\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:70.58802197376887\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:62.36199413736661\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:63.87827063600222\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:61.84218899657329\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:70.9428022801876\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:60.79668655991555\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:66.19083213309447\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:66.15025968601307\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.87464239199956\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:67.20278397202492\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:64.72753313680491\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:61.466196427742645\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:50.52193750937779\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.95834430058797\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.114338308572776\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:23.542253449559215\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:50.147909720738724\n",
            "Layers: 3, Neurons: 4, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:9.916238586107895\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-35341.28346761068\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-4087.7400716145835\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-42846.32954915365\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-4215.192337036133\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-75152.7058919271\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-34925.97844441732\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-600.8178313573201\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-238.83960564931232\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-271.8166176478068\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-692.4030208587646\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:44.33043042818705\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-718.1786362330118\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:47.80338297287623\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:50.125752786795296\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:56.703579872846596\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:56.98416419327259\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:48.73866468667985\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:56.65452977021535\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.70377318561077\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:54.48807994524638\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:12.865564028422039\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:57.71876762931545\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:48.038066625595086\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.2429404258728\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:55.11781016985575\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:23.07707900802295\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:29.642206231753033\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:37.94904706378778\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:36.879514058430985\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:23.64175662398338\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:49.48402802149455\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:27.08229924241702\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.97090802590052\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:57.21403822302818\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:32.422609726587936\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:57.279654691616685\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-19186.943562825523\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-12965.496215820312\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-28387.540690104168\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-18459.020487467445\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-14182.931391398111\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-6429.394785563151\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-178.97026936213175\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:42.14014689127604\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:15.344887177149458\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:50.61641504367193\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-209.2358903090159\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-94.92465734481812\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:55.160005688667304\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:60.1589955886205\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:56.71737718085448\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:52.72772957881291\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:59.11983499924342\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:55.049302702148765\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:51.978259036938354\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:54.46268330017725\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:55.63927183548609\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:43.37745939691862\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:52.07424054543177\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:52.00449491540591\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.93886796136698\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.77963665127754\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:58.082211067279175\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:34.50491895278295\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:58.10685555140178\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:42.66279980540275\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:54.90487257639567\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.8617298156023\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:20.198373993237816\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:35.738282899061836\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:31.708800842364624\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:38.07024826606115\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-18674.991353352867\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-13375.872294108072\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-3112.5338236490884\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-7416.7592366536455\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-16448.2187906901\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-6714.187113444011\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:43.50368857383729\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:54.09305890401204\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:53.115614255269364\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:44.32591994603475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-129.89350398381552\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-75.80394426981607\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:71.03213133911292\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:65.83101219187179\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:70.88921417792638\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:73.18079597006242\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:67.03722663223743\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:63.86664817730585\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:53.14293762048086\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:53.3710660537084\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:55.241319884856544\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:53.77964864174525\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:54.09171094497045\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:54.02050798137983\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:43.93287092447281\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.5053366223971\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:57.70952892800172\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.38697711129983\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.52457344532014\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.364293436209365\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.7575333788991\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:46.18955125411352\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:-33.52010190486907\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:47.50683041910331\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:48.86727035045624\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.34597046176592\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-441.0901387532552\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1883.1301371256511\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-2707.144419352214\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-6802.350107828776\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-6603.509012858073\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-573.3460362752279\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:46.97282314300537\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:57.67201244831085\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:58.9803687731425\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:49.74247773488363\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:52.43391990661621\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:55.660442511240646\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:68.11358111600082\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:70.96916598578294\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:71.12543414036433\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:66.66224285960197\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:66.25779452423255\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:71.45269343008597\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:61.40585005283356\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:55.49629472196103\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:61.14881955087185\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:55.887969682614\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:56.09910532832145\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.83546206355095\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:38.934390023350716\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:55.26125488181909\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:54.255542904138565\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.316187361876175\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:58.17102063447237\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:58.00718814134598\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:51.61562363306682\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.140759463111564\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:50.92352241277695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:57.43591571847597\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:55.49576838811239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.279957969983414\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-111.22767130533853\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-1053.5650889078775\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-53.336970011393234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:46.4911142985026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-52.28182474772136\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-791.1890665690104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:54.1979189713796\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:53.7149793903033\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:53.420349756876625\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:53.772336641947426\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:53.246551752090454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:53.318850199381515\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:69.1055164920787\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:70.94325316449006\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:68.16069891055425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:73.84034319780767\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:68.77126095195611\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:68.86121788372597\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:67.94863263765971\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:67.0357596501708\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:71.15127029518287\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:67.75692979494731\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:68.25339471300443\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:71.41943822304408\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:53.661530117193855\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.55674251914024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:54.09551550944647\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:53.6553563674291\n",
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:54.36638079583644\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:53.478015065193176\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.95080416897933\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:49.35818870862325\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.85632837812106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.380008091529206\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:50.91210640966892\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.90118396033843\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.37708791097005\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:50.26450157165527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:53.40086619059245\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:53.373781840006515\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:53.148113886515304\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:52.07838614781697\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.38218371073404\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.38195090492566\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:66.62579774856567\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:60.700780153274536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.38190237681071\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:63.32373062769572\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:73.09345481296381\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:70.68520142386356\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:70.431239331762\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:69.74122375249863\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:70.11321862538655\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:68.098755205671\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.95238073418538\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:72.45846047997475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:71.52915214498839\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:70.8626702055335\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:71.0816324998935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:67.50591109196344\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:56.92223633329074\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:54.09623454014461\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:54.57641889651617\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:53.78609791398048\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:57.48895275096098\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:54.34219295779864\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.90648837387562\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:49.927187686165176\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:33.745822136600815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:53.456509510676064\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:53.31943094730377\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 4, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:49.23132449388504\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-23913.09880574544\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-48302.26776123047\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-72974.72915649414\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-66434.57946777344\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-2343.6446253458657\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-76122.32899983723\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-880.6835027039051\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-175.2668728431066\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3.8791393240292793\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-882.1083132425944\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-252.3182193438212\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-26.951857109864562\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:54.59113801519075\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:50.378560920556396\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:49.09641668200493\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:52.35144200424353\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:54.80296259125074\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:50.64717570940653\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.904552514354386\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:39.84135591735443\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.69815009087324\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.835164311031505\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.09078408032656\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:33.73729519546031\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:28.53969996174176\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:50.766007055838905\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:57.92957360545794\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:45.92868760228157\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:15.805622190237045\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:25.48590019345284\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.72687538464864\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:49.41987857222557\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:45.88065764556328\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:57.081511579453945\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:50.82123046120009\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.301082337896034\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-14508.304748535156\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-16279.758211771647\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-8977.661921183268\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-15950.417836507162\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-35469.81150309245\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-42547.72669474284\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-135.87176223595935\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-59.52071984608969\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-130.83861629168192\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-114.79467650254568\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-223.1270178159078\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-103.0947419007619\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:68.29858422279358\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:64.68665016194184\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:62.225441001355655\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:68.681817514201\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:69.56943678359191\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:66.56583690394957\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:55.53108481069407\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:56.73045441508293\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:55.06138520936171\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:60.35377904617538\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:54.64855129520099\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:53.926102370023735\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:10.63777004679044\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:5.633844236532848\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:31.417148932814598\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.96268169085185\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:-11.30862394968668\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:58.27409820941587\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:46.79488425453504\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:21.662213951349262\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:16.672659466663998\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:23.29228053490321\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:57.21022945518295\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.67344228426616\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-14014.57504272461\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-5184.574546813965\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-9969.490327835083\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-4231.349271138509\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-6271.427501042684\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-4306.53359413147\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:29.76577033599218\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1.9313007593154907\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:53.01390926043192\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-52.76928305625916\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-13.995989958445222\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:18.17074577013652\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:65.18695138394833\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:73.67132045328617\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:68.68539628883204\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:71.36337672670683\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:70.17479918897152\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:69.36023841301599\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:64.27288845181465\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.00478497395913\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:63.4460690120856\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:60.97789482523998\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:67.1375781049331\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:63.111466603974506\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:56.00204390784105\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:50.24374783039093\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.89474749565124\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:56.148075734575585\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:57.2409105176727\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:42.68317110836506\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.52100099126498\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.10088578984141\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.78236316641172\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:48.92225513855616\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.143123783792056\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.75804768999417\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-3203.9267667134604\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1884.9119472503662\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1444.7306632995605\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1122.0252736409504\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-7053.66730372111\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-921.463459332784\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:57.81992355982462\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:50.22314806779226\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:51.54595573743184\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:57.01332191626231\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:48.96005948384603\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:53.596796710044146\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:70.48028477778037\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:63.83092641830444\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:68.5731090605259\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:68.6312524912258\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:72.2422789533933\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:67.75717827181022\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:69.4544430822134\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.03322791059811\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:68.38609150921305\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.99461865921815\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:68.41322436928749\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.58355940878391\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:56.454665909210846\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.98322752614816\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:58.758055567741394\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.106952667236335\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:57.69514268885057\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:57.68140897154807\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:-45.07535070180892\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:31.868516206741337\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.821199874083206\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:44.35399944583575\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.972746404508754\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:57.51358296722173\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-36.57255813479423\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-154.75795110066733\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-492.52757867177326\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-259.5485560099284\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-104.08449808756512\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-221.6129016876221\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:63.41232200463614\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:60.83556214968364\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:56.202679301301636\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:58.82116417090097\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-97.1683402856191\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:65.79656258225441\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:62.600077893584974\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:70.55701191226642\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:67.10762195910016\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:66.33340718845527\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:71.05895859499772\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:67.74380897482236\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:67.6497117926677\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:66.60475841412942\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:68.02196671565373\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:71.85429662466049\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:69.63744829098384\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:67.61350778241952\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:57.77433610210816\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:57.49326032896837\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.5447530016924\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:58.00495862960815\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:62.253310730059944\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:61.2160487473011\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.49348981181781\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:57.86315128207207\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:58.886616708866015\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:26.494439070423446\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:47.896878023942314\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:51.388849268356964\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:55.56659698486328\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:60.42428652445475\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:55.09340286254882\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:52.78823216756186\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:54.1668446858724\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-9564.892807006836\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:54.99346810082595\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:55.054980317751564\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:63.68526339530944\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:52.23061521848042\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:60.722977717717484\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:63.60861331224441\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:70.30258491635323\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:64.45700163642564\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:63.55853736400604\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:66.51489323625962\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:68.5332215949893\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.32134588807821\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.37412323678534\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:69.77573563655217\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:62.21186768263578\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:66.41170501708984\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:69.63915380338828\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:66.26458535591762\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:61.006695677836746\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:67.70399404068787\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:63.50915315250556\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:68.19764537115891\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.62727834284306\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:67.93851725757122\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:58.79285814861457\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:48.44482285901904\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.60791870827476\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:12.680320839087166\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:44.39301754037539\n",
            "Layers: 3, Neurons: 4, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.940888146559395\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-5370.523325602213\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-6082.87607828776\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-8969.54854329427\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-152302.8401692708\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-107077.40071614583\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-254550.83821614584\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-582.0169321695963\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1847.0675945281982\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2289.169470469157\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-361.9911750157674\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-2389.1626485188804\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:38.780427773793534\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:2.1542465686798073\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:43.189071118831635\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:44.02781128883362\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:18.561860422293343\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:48.845297594865166\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:46.28354082504909\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.59837793310483\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:57.19281584024429\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.45597260197004\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:51.85836851596832\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:54.61088175574938\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.23274682462216\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:49.70190912485123\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:46.88648685812951\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:21.276075839996334\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.45013203223546\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.28766143321991\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:54.58262058595816\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:55.97955857714017\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:46.979818170269326\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:48.41659794251124\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:58.157388418912895\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:19.382795592149094\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:53.3026015261809\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-342470.0113932291\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-45226.24409993489\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-170332.6334635417\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-108296.18733723958\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-49358.6405436198\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-77864.02791341147\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-219.761430422465\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-194.84143694241843\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-205.2960280577342\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-186.4730308453242\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-459.27086353302\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-121.70047283172609\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:58.47686243553956\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:54.137880429625504\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:49.520915150642395\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:50.34054468075435\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:55.48453922073047\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:50.09888937075932\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:50.32315929730733\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:55.961970711747796\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:54.04931468268235\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:52.46297602852186\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:54.44304317235946\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:54.43382037182649\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:-1.2528958916664168\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.096195012331\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:54.356520622968674\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:58.141376432031386\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:45.12795488039652\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.93978551030158\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:39.543258870641395\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:55.095659469564765\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.69164715210597\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.94616598884265\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.37939065694809\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.96878383557002\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-66320.98795572916\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-17524.516805013023\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-61635.624186197914\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-14457.547505696615\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-22473.965962727867\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-38696.78853352864\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:44.33670957883199\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:56.876832246780396\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:52.60833660761514\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-192.217169602712\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-219.76667245229086\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-393.1201124191285\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:62.28317528963089\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:56.12683646380901\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:69.41453564291199\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:70.26234216367205\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:67.5620307897528\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:61.320473353068024\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:55.87204483648141\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:53.77359931667646\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:55.70460925499599\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:54.03049757083257\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:55.29970521728198\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:57.037967145442956\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.36942204833031\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:52.889326413472496\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:38.184572855631515\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.32666203379631\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.618920048077904\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.643383433421455\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.129156678915024\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.5843708217144\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:22.86620636781057\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:57.38156398137411\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:49.08706364532311\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:54.342056065797806\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-9882.973734537762\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2467.8016026814776\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-389.43735758463544\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1286.3427797953286\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-11584.379831949871\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-167.89423624674478\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:50.13330380121867\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:9.349476496378584\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:56.43016695976257\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-40.1877514521281\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:47.387036879857384\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:45.90044180552165\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:73.72134637708466\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:69.51714586466551\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:72.40545137474935\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:68.54505797227223\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:71.16557265321414\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:68.08600408335526\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:56.60094390312831\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:58.30025993287563\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:59.617672438422844\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.08964383602142\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:67.65985713650782\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:68.293182477355\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.23822339375815\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:53.912351379791886\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.68565492331982\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:56.58353971938293\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:53.413006563981384\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.61780444780986\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:53.72076933582623\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:57.400168528159455\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:-3.7638817230860377\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:27.21316625674566\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:56.43107735862334\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.22633698582649\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-372.3636309305827\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-444.4295247395833\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2622.0596949259443\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-138.5830561319987\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-195.6919034322103\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-465.5019124348958\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:52.916534344355256\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:52.70609498023987\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:54.340991179148354\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:52.21407651901245\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:52.866528630256646\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:52.90872812271118\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:67.63122857897542\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:69.13384675358732\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:69.48557500960305\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:67.26865937312444\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:62.67782963812352\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:70.55897869169712\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:68.87170835708578\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:69.41463932394981\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:68.95375644167264\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:67.80796959996223\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:69.43148224925002\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:68.70203251640001\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:53.708512385686234\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:55.7107878724734\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:53.65274841586749\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:54.29532726605733\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:54.252672294775635\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:53.93968065579733\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:24.393237680196766\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:32.47817039489747\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.11875000099341\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.32257985075315\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.77263207733632\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:26.061467627684276\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.313541412353516\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:53.332599004109696\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:53.43818664550781\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:53.33973566691081\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:57.57568677266438\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:53.37473551432292\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.71024767557779\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.667709827423096\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.417162100474044\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.38270823160806\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.374021053314216\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.38185826937358\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:62.923930982748665\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:74.20316527287166\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:72.88924191147089\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:68.33545789743462\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:68.55061883727709\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:64.78433936213453\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:58.01358941942454\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:59.82660792768002\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:62.43404047563672\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:60.185050492485374\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:63.850143998861306\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:67.32765067368746\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:54.76483777165413\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:57.55340268214544\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.22938437759876\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:57.15198993682862\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:55.95895166198412\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.90776701768239\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.4091742982467\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:53.51287732521692\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.41606891155243\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.73772654930751\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:56.439185788234084\n",
            "Layers: 3, Neurons: 8, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:49.0939424932003\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-49790958.7109375\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-360711051.1458333\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-814320.0567626953\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-127232007.60416666\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-9570945.589192707\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-50597978.470052086\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1433.7242450316746\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-39171.9593111674\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-725.9394359588622\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-10379.696165720621\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-9179.568630854288\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-15986.578769683836\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:37.18979199727376\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:35.541150867938995\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:54.761352340380355\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:54.993924871087074\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:47.60410795609157\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:55.33177415529886\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:55.72716062267622\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:36.687010961274304\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:52.66898259520531\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:26.366999397675194\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:22.003676245609917\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.84703074892362\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:28.511508603890732\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:58.010387495160096\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:48.05514348049959\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:54.74626898765565\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:37.26415132482847\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:35.12045497695605\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.68542729690671\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:51.49802199875315\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.72509330014388\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:49.10675241922339\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:55.707791820168495\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:45.28688747435808\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-19117.57253011068\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-65857.9630533854\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-416040.7877604167\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-64555.049641927086\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-41153.9774576823\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-22696.24226888021\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-388.4445508321126\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-177.6245911916097\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-1150.3385861714683\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-955.2514394124349\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1457.1024576822915\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-949.8393376668295\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:66.02185626708281\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:51.10764130949974\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:66.52849741280079\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:55.04831477999688\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:65.52226611723502\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:64.20984377463658\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:61.176653107007354\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:56.19622314969699\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:57.12160741289456\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:55.21714086333911\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:55.69380278388659\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:62.32566212614377\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.11571963131427\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.41455538570881\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:56.491166216631726\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:57.129715724537775\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.767185052235924\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:18.511903832356136\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:15.594320744276047\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.43207858006159\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:53.41948239753644\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:50.731924722592034\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:57.927434469262764\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:21.49142389496167\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-124427.11995442708\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-51567.66560872396\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-311825.5208333334\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-193611.79606119794\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-125916.54459635417\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-79460.62215169272\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-713.4077707926432\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-402.155081431071\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:41.82732899983724\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-697.0884005228679\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-25.273684660593677\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-324.67654546101886\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:67.59201216200988\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:67.314940886572\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:67.2616296261549\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:66.34171505769093\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:63.48427630960941\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:58.72711479663849\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:67.29881335670748\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:64.36920555929343\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:67.81615756452084\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:63.27660796542962\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:61.39774891237417\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:66.39112518479426\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.68810865779718\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:49.393349861105285\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:36.190258848170444\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.88658466935158\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.08638074000676\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:45.488100076715156\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:50.032487108061716\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.75410398840904\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:52.68609583377838\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.125483199954026\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.58011095846693\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:50.28924634059271\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-41041.1885579427\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-379141.5201822916\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-9619.397989908855\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-49304.57967122395\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-13358.642069498697\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-163470.91878255206\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-54.67289288838704\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:56.2147855758667\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-124.51897462209067\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-181.35592142740884\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-151.34037017822263\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-19.47449048360188\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:53.115975856781006\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:66.17323233435552\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.96779276927312\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:69.9324896807472\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:67.60344792157412\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:64.61004674434662\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:66.91765425105889\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.66193004697561\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.18462432175875\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:68.33388794213533\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:63.82220090677341\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:67.51094837983449\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:56.32065194348495\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:49.46116799488664\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:47.25076568623384\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.15557806690534\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.27214599152406\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:59.739741533994675\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.62704288959504\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.027624383568764\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:51.30974370054901\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:30.55041084686915\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:31.677182391285896\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.51395863046249\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-473.35255940755206\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3648.829015096029\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2129.372914632161\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-59994.51700846354\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-553.2347361246746\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-5344.312032063803\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:50.658773382504776\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:49.15759563446045\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:54.49121395746867\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:52.259083588918045\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:54.914677143096924\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:54.70476627349854\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:61.71403684653342\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:71.6261355082194\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:63.27976846446594\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:65.73808583120505\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:53.395071625709534\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:53.40867290894191\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:70.6521035482486\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:61.903085124989346\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:71.81533147891362\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:69.97277587652206\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:69.96138016382854\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:63.87910671532154\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.53299740950267\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.3377440571785\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:56.771023472150176\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:61.055153533816345\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:62.40212536727389\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:62.110040411353104\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:55.13964128990968\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:52.46944749727845\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.98373415569464\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.056864549716316\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:40.97969088703394\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:52.74407044053078\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:54.002253214518234\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:53.636423746744796\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:52.755610148111984\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:55.0228754679362\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:53.83671124776204\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-2828.8783518473306\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.38268280029297\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.383178512255355\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.38387489318848\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.382233778635666\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.38245232899983\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.38103473186493\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:61.026745066046715\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:54.204461056118205\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:59.41223127146562\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.3810479839643\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:51.32599939902624\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:58.205631002783775\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:56.86406513055166\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:50.19270638624826\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:60.52316760023435\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:58.04856161276499\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:62.67904051889977\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:53.31670023500919\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.98033451785643\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:67.34668885668118\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.16392267930011\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:67.95151006430387\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:68.15512551615636\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:67.1657670289278\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:52.57897059122721\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.83080974717936\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.91221503478785\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.1056696716696\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:57.151645844181374\n",
            "Layers: 3, Neurons: 8, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.61250299215317\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-4309.666341145833\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-6038.555068969727\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-34768.512827555336\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-44666.97336832683\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-44781.06501261393\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-44624.254150390625\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:46.04266862074534\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-483.28033844629925\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-867.8504625956217\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-632.629779179891\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-748.7098709742229\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-107.21917192141217\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:54.0171497563521\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:45.80670555432638\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:48.09034377336502\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:46.551232139269516\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:33.28674003481865\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:41.290873388449356\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:52.559405167897545\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:11.112493524948752\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.82789648572603\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:45.87623788664739\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:56.75690052409968\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.10537189245223\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:40.13356233636538\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.42902253071466\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:57.80696821709475\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:58.22266670564811\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:54.52095925807953\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.53129332264264\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:55.19611423214277\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:57.2734775642554\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:2.1004058917363455\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:45.64475744962693\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:26.136361906925842\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:25.189359784126285\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-65590.7755533854\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-36882.50834147136\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-20612.47802734375\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-6413.588460286458\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-24949.283854166664\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-18854.63307698568\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-496.4831034342448\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-119.70226486523944\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-124.3129014968872\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-91.26674731572469\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-258.61669699350995\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-75.50991574923198\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:55.16494870185852\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:51.932289848725\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:55.58555940786998\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:56.74392342567444\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:52.218736410140984\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:59.75121239821116\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:52.757657269636795\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:51.83358709017436\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:51.47941683729489\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:53.11075702309609\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:53.306385974089295\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:53.15490419665972\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.75253413120906\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:51.63095146417618\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.797803521156304\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:57.194025740027435\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.605862572789185\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.36520676811536\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:42.10824308296045\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:35.223569447795555\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:54.78243817885718\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:48.055885235468544\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.330685645341866\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:54.71001466115315\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-18683.82130940755\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-10738.183263142904\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-17772.761027018227\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-24959.316507975258\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-40973.86535644531\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1483.3203633626304\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:29.318634668986\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-112.24866867065431\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-61.22712294260661\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-79.13932005564372\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-51.13671501477559\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-31.479661464691166\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.66383554041386\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:68.08619782328606\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:66.9942357391119\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:66.25578499088685\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:69.49149813503027\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:67.62496183315913\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:54.33048953612645\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:54.743954588969544\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:54.59640954931577\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:54.997335920731224\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:53.593138357003525\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:54.3132237593333\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.40469941496849\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.5373298128446\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:53.3819601436456\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.09264387190343\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.227014193932206\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:57.93245332315564\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:35.44671028852463\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.40364156166713\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:56.25837431599696\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:57.45607130229473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:24.033481130997338\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:14.744711418946588\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-8085.093943277995\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-932.4273427327474\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-4748.576863606771\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3004.710515340169\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-2733.7888081868487\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-8682.891337076824\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-23.973724047342927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:42.61228084564209\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:34.09910917282104\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:45.35157998402914\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:47.31840133666992\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:45.222957928975426\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:70.82955863326788\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:70.81655343373616\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:70.6427650153637\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:68.66900876630098\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:70.34397541234891\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:68.35258942718308\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:68.52917904655138\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:57.42140392462412\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:60.2608964840571\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:62.918967343866825\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:54.074756552775696\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:57.8878748913606\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:57.274388770262405\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:53.41226597627005\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:57.915846146643155\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:49.4142818202575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:56.78932644426823\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:55.46538695693016\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:42.49414739509424\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:40.26818610727787\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:58.152602141102165\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.910898357629776\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.734940191109985\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:57.515784899393715\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-560.3146235148113\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-11.041704813639331\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-453.9784749348958\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-633.11341603597\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-230.9172439575195\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-593.0889002482096\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:52.933782736460365\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:52.990738550821945\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:52.86313533782959\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:55.71289618810018\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:54.13021643956502\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:53.05342594782512\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:66.7491802945733\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:63.053565174341195\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:61.00142814218999\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:70.94461565216382\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:63.26468452811241\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:66.32455912729105\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:65.55535142620404\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:67.863279019172\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.47764285157125\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:67.37846108774343\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:68.52944992482662\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:67.23207886020343\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:54.36436454455058\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.72214277585348\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:55.592412700255714\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:54.432746743162475\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:53.49483211835226\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:54.08637300133705\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.63026834527651\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:58.27669588228066\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:38.7175352871418\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.33457999303937\n",
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:42.45121024549008\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.72618446747461\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.374525705973305\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-60.72270075480144\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:53.38834126790364\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:53.40048472086589\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:53.325017293294266\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-26775.697835286457\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:63.241732120513916\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.38096777598062\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.480388323465974\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-68.58004212379456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:67.68124024073283\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.381826877593994\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:68.92889515807231\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:70.28053939342499\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:61.03313234945138\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:64.76414437095323\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:73.68586782366037\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:64.724530428648\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:66.02238423501451\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:70.60783799737692\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.42483981698751\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:66.6114502462248\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:61.72506717344125\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:73.02072943809132\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:67.05666651328404\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:56.83255851268768\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:53.98541957139968\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:55.74038423597813\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:53.87721846501032\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:61.50376224269469\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.39293035864829\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:35.97114163140456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:31.958295007546745\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.58417788147927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.58567216992378\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 8, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.817886094252266\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-50346.68655395508\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-91150.9829711914\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-53923.299102783196\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-86695.81194559734\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-4107.69292195638\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-3269.2367680867515\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-173.86506388584775\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-255.74048966169357\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-99.55447733402252\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-179.0180198351542\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-72.5693584481875\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1012.4183015028636\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:52.435434311628335\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:51.355050764977925\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:57.63998365650574\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:41.24169826507569\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:52.79653541743755\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:54.93960173800587\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.721442523101956\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.56050053735574\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:56.200249393781036\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:20.628053049246475\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.696376680086054\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:53.22919538865487\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:52.260655226806804\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:45.855660500625774\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:28.138984466592476\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:40.76676554977894\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:50.97467270990212\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.637193719546005\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:54.81060226758321\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:58.7491865704457\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.62011138598124\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:52.10282382865748\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.01435807192077\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:54.970812499523156\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-49142.10132598877\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-99914.76114908855\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-56831.301682790116\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-57240.31833012899\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-150258.53454589844\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-80280.09668986002\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-522.0548506081104\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-326.46252731482184\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-221.99657956759134\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1266.8241890271504\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-404.4857015212377\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-169.4003534317017\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:66.91519305109978\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:65.38091275840998\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:64.39017614970605\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:67.46760457754135\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:67.56031667192777\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:64.17030801375707\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:62.157073703904956\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:57.805242563287415\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:60.47108265260855\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:65.28876815612117\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:61.618387276927635\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:61.6816972879072\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:18.743920723597206\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:46.747765907396875\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:39.27671377857526\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.24493305385113\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:43.421380979319416\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:44.24619458615779\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:9.414431105057396\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:36.3494445507725\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:37.47187418242296\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:44.11148384213448\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:36.0650508850813\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:38.8047598550717\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-45296.725006103516\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-51834.375286102295\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-34568.40474446615\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-33053.23792139689\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-45963.31930796305\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-32279.05831972758\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-159.6531303723653\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-108.90732675790788\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-108.55593840281168\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-92.76753122607866\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-118.79474719365439\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-184.98943150043488\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:70.41476368904114\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:71.9822870194912\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:68.08099251240492\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:69.46224321921666\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:69.58629071712494\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:66.4853391299645\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:63.39637110630672\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:63.98971024900675\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:65.69599635899067\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.21102357655764\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:66.36126550535361\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.35182802627484\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.38951836278041\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.0667297343413\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:58.02215757469335\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:58.15162931879361\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.81116426487765\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.067555874586105\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.26203595598539\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:51.0543093830347\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:56.537922667339444\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:54.42694630473852\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:55.69318008919557\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:55.10410582025847\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-7199.468180338542\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-6648.233413696289\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-8508.886286417643\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-5626.817626953125\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-4911.81723276774\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-13012.130533854168\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:12.123628457387293\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:10.186147689819336\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:47.93110132217407\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:31.288184324900314\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:48.78734723975261\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:36.375109354654946\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:67.82816062370935\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:69.47743475437164\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:62.85457881788412\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:68.85917169352372\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:66.1925995349884\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.61659009816746\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.62087826430798\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:68.29908082882564\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.03546024610598\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.9316714691619\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:68.28780001650254\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:69.29353465636572\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:64.30384195099275\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:60.67146946986517\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:44.06096413731575\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:57.0636900762717\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:59.671387771765396\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:57.61924720058838\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.961834018429116\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:47.31640053292116\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:36.52702281872432\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.913106559465334\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.01839806511998\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:52.486055642366416\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-989.4827143351238\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-305.59176762898767\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-744.2389202117919\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-269.4598372777303\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-357.2881889343262\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-743.1556542714437\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:60.9864846865336\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:55.63180173436801\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-111.60045266151428\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:55.14494707187016\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:63.23589324951172\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:63.3395254611969\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:72.44833522476256\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:69.34452692667644\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:61.80900494257608\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:66.24985578159492\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:67.14978396892548\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.02009769280752\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:72.82367793222268\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:64.8478215932846\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:62.738725331922375\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:69.4949431469043\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:65.6474619358778\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:72.99074624975522\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.63419587910175\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:64.87914338707924\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.13632278641064\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:63.56458727270364\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.73563779393832\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.47595997651419\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.43093657741944\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:55.17167679965495\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:35.16626603901386\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:48.9116903146108\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:58.06331388652325\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.545166022454694\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-145.19614537556964\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-50.266741116841644\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:56.829579671223954\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:58.28553517659505\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-14.088989098866778\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:58.627160390218094\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:57.34430511792501\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:57.99327691396077\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:56.17139180501303\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:52.356195052464805\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:60.677184561888375\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:57.44548628727595\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:70.4594898596406\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:66.96674339473248\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:58.99934008717537\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:61.38522309561571\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:58.127243096629776\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:65.91615170240402\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:64.4736255457004\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.99853887533148\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:70.66923593481383\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:68.6157101765275\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:63.363522651294865\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:66.03267854079604\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:66.66387606722613\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:66.05592466890812\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:66.93162187933922\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:66.10401574522257\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.22787779569626\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.35746013124783\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.22955601414045\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:52.04623332247138\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:52.298708384235695\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:59.621303478876754\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:59.234518073499196\n",
            "Layers: 3, Neurons: 8, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:57.75413401424885\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-30709.752400716145\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-574159.7330729167\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-203217.9280598958\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-164808.7565104167\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-424990.3157552083\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-335113.7125651041\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-347.2649478912354\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-325.2482350667318\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3244.167652130127\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1101.3895908991494\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-7904.734865824382\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-276.5951983133952\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-169.49408491452536\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-112.19016512235007\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-68.05769761403401\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-137.62030204137167\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-134.6974237759908\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-101.3319166501363\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.23651827375094\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.98484627902508\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.21798876424631\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:54.30068574845791\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:53.8968380788962\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.24067311485608\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:50.28532830377419\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:49.9026146531105\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:58.13346514478326\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.466328650712974\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:26.828901072343193\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:46.45457652707895\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:45.39289622257153\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:52.42302400370439\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:31.10792865355809\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:55.56238474945228\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:34.747199366490044\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:23.36690907677015\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-97627.3478190104\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-83256.15030924478\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-182488.54573567706\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-186582.76774088544\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-185268.0257161458\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-164576.88395182294\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-197.3952960968018\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1852.7691841125488\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:37.76191631952922\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-604.9691836039226\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-188.84076436360675\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1345.3751786549885\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:46.18162959814072\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:47.645841489235565\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:47.806449234485626\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:48.86738489071528\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:50.14671752850215\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:53.34177364905675\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:56.19108890493712\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:55.32178893685341\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:54.17264729738236\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:52.923481365044914\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:55.56666905681292\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:55.88888178269069\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:56.916041908164814\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.73672782878081\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.808588367576405\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:53.114677270253495\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:57.580616008490324\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.67699283361435\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:36.60742864012718\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:55.75542469819387\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:52.1254510184129\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:38.57120049496492\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:44.198198641339935\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.037284319599465\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-323611.8815104166\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-191103.3040364583\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-246536.26302083334\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-73025.90535481772\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-229796.40299479166\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-256661.14095052084\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-142.09874232610065\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-595.3134441375732\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-268.3942977587382\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-993.0681769053141\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-890.4270537694294\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-449.71955498059594\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:56.954852640628815\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:59.14864127834638\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:59.83024617036183\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:58.08279871940613\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:59.09064620733261\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:67.47445580859979\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:54.93728272616863\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:57.98404196898142\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:55.8296619852384\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:55.73762431740761\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:59.07708371678988\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:61.301843492935106\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.288102090358734\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:52.92628278334936\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:52.10615624984105\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.36786891023317\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.907422040899604\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.07596399386724\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.020504916707665\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.87748152017593\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:56.72035078207651\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:44.46454524993897\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.57033821195364\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.24186613162358\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-95481.30696614584\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-83955.68644205728\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-70829.84212239584\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-15507.730611165365\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1000.3912607828776\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-38015.605672200516\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:43.28651626904806\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-170.93413829803467\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-58.537341753641755\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-257.2994740804036\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-103.2949940363566\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-59.7459328174591\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:53.591682414213814\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.82548176248868\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:71.73488438129425\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:66.13918197651705\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:67.18551427125931\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.77405263980229\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:62.4932078147928\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:68.21356101582448\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:65.92069665590923\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:67.95083779841661\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:68.14506232738495\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:66.22372447202602\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:54.021598845720284\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.06789548695088\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.14986546834311\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.941884587208435\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.746974259614944\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.53609845042229\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:57.948001387218625\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.49318866928419\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.33103428284327\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.61960976322492\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:58.13122278700272\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.701492279768\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-505.49952189127606\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-37919.35628255208\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-54860.127766927086\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-4524.502690633139\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-132.79088338216147\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1941.0598119099934\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:52.21498807271321\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:50.21083116531372\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:49.42331790924073\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:51.72086397806803\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:53.555832703908294\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:49.337569077809654\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:71.25288824240367\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:66.61893752713999\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:68.76632473741968\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:68.84297837813695\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:69.12789707382521\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:65.09250019987425\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:69.28918536752462\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:68.87153221915166\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:67.74446996549766\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:68.68853021413088\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:68.12564371774594\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:68.32668370256822\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:54.72999845941862\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.88286451498667\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:54.219399044911064\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:55.29467125733694\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:54.01405374209086\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:54.6527340511481\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.80304442842801\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.133749912182495\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.44799100359281\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.98532582322757\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:58.15344045559565\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.779800191521645\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-72.56415685017903\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:53.23111216227214\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-498.21020762125653\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:53.546078999837235\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-166.83785120646158\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-980.4037729899088\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.37956110636392\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.352530797322586\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.09390068054199\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:50.654381116231285\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.37177753448486\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.381563027699784\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:62.537842790285744\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:63.0364740989171\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:69.5229410380125\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:68.2527955683569\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:61.667290863891445\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:67.62451892097792\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:58.48269011825323\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:66.76312552765012\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:64.88876258333525\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:62.860072404146194\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:62.625681708256394\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:61.68597464760144\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:62.31918095300595\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:66.39107905949156\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.32902884607515\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:65.459817952166\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:66.27627556522687\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:60.88933872679869\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.72965102394423\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.04650995135307\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.778871794541686\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.1148412724336\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:53.61931875348092\n",
            "Layers: 3, Neurons: 16, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:53.47212354342143\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-413334197.7083333\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-37445275.514322914\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-40078608.893229164\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-932603858.75\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-792933143.75\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-586500309.375\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-56450.81606547038\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-3077.0015239715576\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-212938.1728108724\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-77420.44514973958\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-14868.582592010498\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-75000.0705464681\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-71.3578333457311\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:14.955522219340011\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-20.232423742612205\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:34.795476595560714\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-20.713706215222683\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-44.36587572097779\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.44701418280602\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.878191058834396\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:41.1644596606493\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:56.94077777365843\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:55.28244021038214\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.136608670155205\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:57.11952192087968\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:28.242830261588093\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.37673963482181\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.88441301882268\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.23375337322554\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.815141228338085\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:57.744355803976454\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:56.896715834736824\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:54.46049690246581\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:43.501873686909676\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:18.639982491731644\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:52.32906937599182\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-102366.42252604167\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-175664.05843098956\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-253675.04069010416\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-145087.3942057292\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-117936.11246744792\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-2231660.5708821616\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-337.6797596613566\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1697.7160771687825\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-3297.7877298990884\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-5552.429835001627\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-2975.5726496378584\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-549.5430787404377\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:53.43811213970184\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:55.7449362675349\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:50.91888805230458\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:48.510029911994934\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:61.85129349430403\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:64.01378661394119\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:63.32048041125138\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:62.16709808756909\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:62.95737930883965\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:62.4631264557441\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.88029864927132\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:63.299114406108856\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:50.33129325757424\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.60093968113264\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.15021108587584\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:57.50298604369164\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:45.33723800132672\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.8249439795812\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:56.495332581301525\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:46.2790385633707\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:45.510241985321045\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:56.19410689920187\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:36.50773684183757\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:36.747145503759384\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-119792.56184895833\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-209436.70247395834\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-604410.4654947917\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-210838.85091145834\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-433586.2141927083\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-163862.3209635417\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-4677.979888916016\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1647.2082773844402\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-1047.2214380900064\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1815.8664067586262\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-2737.7051035563154\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-279.46297327677405\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:52.00124700864156\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:52.21686661243439\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:52.008624374866486\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:68.1501592695713\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:63.816539756953716\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:66.72977983951569\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:67.11607366800308\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.6274111320575\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:64.1766214184463\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.06635252634685\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:69.12356125811736\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:68.61829989900193\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.300763373573616\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:56.18031774957974\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:60.6764738758405\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:55.74942294508218\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.05802436669667\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:58.33494539683064\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:37.7306921283404\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:57.51892150690159\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:52.31571425994237\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:44.89396280298631\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.63377564027905\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:44.15474209934474\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-245773.54329427084\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-328170.6461588541\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-110870.06022135417\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1366090.2994791665\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-893915.8528645834\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1478774.1861979165\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-135.78097025553384\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-3.603299458821607\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-449.40001169840497\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:27.614561716715492\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-398.23606808980304\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-64.53394095102946\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:53.774717946847275\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:52.83431112766266\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:53.1315599878629\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:53.838641444842025\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:54.13097441196442\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:57.11139460404714\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:64.7548008710146\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.82466435929139\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.0462318311135\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:64.2297097792228\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:67.1287882514298\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:67.3731926518182\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.8611567268769\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:55.65265066921711\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:56.814342737197876\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:59.14297023167212\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:60.94102741529544\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:62.56830838819345\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.59168738483762\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:58.03474134455124\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:55.9598602509747\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.85193505883217\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:56.21031393607458\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:44.899478616813816\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-9359.34346516927\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-5828.038279215494\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-212.79818216959634\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-178937.99235026044\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-21477.82999674479\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-25707.761637369793\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:32.11838404337565\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:56.00167910257976\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:48.13441435496012\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:57.537857691446945\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-99.09216562906902\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:52.87346839904785\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:53.36169997851054\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:53.34196090698242\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:53.42152267694473\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:62.17791865269343\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:53.378063937028244\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:51.88904461450875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:52.68291649719079\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:62.92674080158274\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:53.419090559085205\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:66.40127981081605\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:58.62252650161584\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:61.29770887394746\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.3250805536906\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.9445433691144\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:66.22121817121904\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.78347003708282\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.84236432487766\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:64.2032106841604\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.540213959912464\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.340155323346465\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:57.339500468224294\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.90065368513266\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.83676322673759\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:57.77064530799787\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-12907.032267252604\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:54.009437561035156\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:51.89857482910156\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:51.744206746419266\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:51.23319625854492\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:53.092988332112625\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.37897439797719\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.380584716796875\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-576.5725564956665\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.3799409866333\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.386179606119796\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.38273048400879\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:57.40061036621531\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:53.38217318058014\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.45004208261768\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:53.38216821352641\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:61.9908099869887\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:53.38216026624043\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:51.422415326038994\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:51.81998370836178\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:61.300891190767295\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:49.85890794545412\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:47.21365263064702\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:62.80412531147401\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:63.16374231129884\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:64.89557582885027\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:64.46081915249427\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:63.72659441549331\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.07546774763614\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:67.28778176009655\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.317487423618644\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:59.25458048780759\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.85427510738372\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.81260014822085\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:60.119990073144436\n",
            "Layers: 3, Neurons: 16, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:58.41134538253148\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-7716.649983723958\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-193351.6717529297\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-152580.6833902995\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-86008.33740234375\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-31263.325551350914\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-6806.162668863933\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-1287.6281086603801\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-462.877828280131\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1736.6792678833008\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-486.4041384061178\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-642.9563013712565\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1477.9762077331543\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:46.325219472249344\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:43.73348911603292\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:47.34994411468506\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:47.916528284549706\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:50.326548963785164\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:47.50626842180888\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:45.03861685593923\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:46.221954400340714\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.16949869195619\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.4311206638813\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:34.44894050558408\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:55.1657023280859\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.539753099282585\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.369788882633046\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:54.82401577134928\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:55.887538827955716\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:56.49755872786045\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:29.961268752813343\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:44.55324240028858\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:57.2990606725216\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:53.371078620354325\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:50.1831033701698\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:45.84607448428869\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:41.73674372335275\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-92188.0655924479\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-21364.38252766927\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-80183.64461263022\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-72051.7049153646\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-17198.929850260414\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-114059.10237630208\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-195.8796711762746\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-276.4567518234253\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-564.0591557820638\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-389.5861546198527\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1221.787486076355\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-766.6845019658407\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:51.84397175908089\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:55.82433670759202\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:60.98453357815743\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:53.70458498597145\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:58.66764257972439\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:55.84326778848966\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:51.04475269714992\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:54.038227001825966\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:51.26102566719055\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:51.58785184224446\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:51.06290052334468\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:50.795924713214234\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:54.61413192252318\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.033434897661216\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.60058757662774\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:55.6661774466435\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.42382144431272\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:53.58993952473005\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:54.43162098526955\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.30776913215716\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:57.88657663700481\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.35962341725826\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:55.20596240957578\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.376150881250695\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-39528.29488118489\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-26800.89823404948\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-96460.95987955728\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-50010.66792805989\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-55065.78165690104\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-65305.92751820882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-239.2703151702881\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-328.569966952006\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-259.01687781016034\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-360.47195076942444\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-535.7508675257365\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-381.2677224477132\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:66.2609979386131\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:66.47708075741927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.28299956023693\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:66.81898569067319\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:62.937555983662605\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:66.71352793773015\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:53.73685975869497\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:54.3444215754668\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:54.56683069467545\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:53.50260535875957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:53.68835215767225\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:54.460782731572785\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:58.15111888262132\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:55.672513221700996\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.422260810931526\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.75175202886264\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.897868931293495\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.71445903306207\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.655597527821854\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.74584490060806\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:43.58638063073158\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.69197656710942\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:58.066214323043816\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:57.3626842101415\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-8906.08122507731\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-7081.173960367839\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-5741.002400716146\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-11843.072764078777\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-17747.98685709635\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-6707.412211100261\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-76.60195271174113\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:57.4257214864095\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:0.036469101905822754\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:56.00059111913045\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:47.82480796178182\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:44.5606009165446\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.4406454761823\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:71.1277203510205\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:65.15947051346302\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:69.14454452693462\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:70.26374330123267\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:65.20693669716518\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:69.26616518447797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:59.5944594591856\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:67.87279071907201\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.81389541427293\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:53.92789115508398\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:54.86351589361826\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:54.88565002878507\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.2093534519275\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.199574251969665\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.18940162658692\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.331996008753784\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.297194838523865\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.76371788978577\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:53.38475093245506\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.99772675335407\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:23.9147387444973\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:48.01576979458332\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:54.27201107144356\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-125.78606287638348\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-397.02664057413733\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-631.1097462972004\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:51.0152022043864\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-175.70292154947916\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-7.958348592122388\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:54.489375750223786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:57.00316985448202\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:56.989972591400154\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-364.2040987809499\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:48.08054049809773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-278.36249987284344\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:66.17587506771088\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:70.9662559380134\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:66.65607390304406\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:67.7679118514061\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:67.58020296692848\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:68.69651557256778\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:64.63603441913924\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:67.4980445454518\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:65.94001101329923\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:68.07086235533157\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:67.88133465995392\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:68.77979582796495\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:53.35735316077867\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.59204401572546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:53.38445713122686\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:53.979757030804954\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:53.45566660165787\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:53.387878984212875\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:50.08130649725596\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.98901853958766\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.4130780523022\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:55.33653033276399\n",
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.18044271568457\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.851690893371895\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.31929524739583\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:53.317515055338546\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-518.9966837565105\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-1632.550875345866\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:53.46946716308594\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:53.27536265055339\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.38167508443197\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.38106314341226\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.22979728380839\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.40467135111491\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.38695049285889\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:55.57619134585063\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:70.08800182491541\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:68.97208616137505\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:67.10378502806027\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:66.99377211431663\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:69.94515530765057\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:61.79667167365551\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:60.63458301126957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:64.16147613277037\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:64.03531734521191\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.45489940792322\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:64.86310196419556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:64.44665503998597\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:54.10372272133828\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:61.19087023039659\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:54.39570173621178\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:66.90322041511536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.90486792723338\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:54.48845957716306\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:47.011039555072784\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:53.65309859315555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:57.764462679624565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.878945184250675\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:56.54875595122576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 16, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.80991439521312\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-37855.3488667806\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-142861.19135538736\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-325203.7709554037\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-67600.28027852376\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-14396.485303243\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-42092.8382619222\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-130.6169734398524\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1024.5134552319846\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-421.64438863595325\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-141.0886736710866\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-542.4169524510702\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-847.8846170504887\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:52.600627814730004\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:55.502188081542656\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:18.476393620173138\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:54.76489502936601\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:33.13792022566001\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:6.041416103641195\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:54.626949056983\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.26529688636461\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.333115433653205\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:58.21548943718275\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:58.08685547361772\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.328986057390765\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:42.192037838200726\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:54.88960983852545\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:56.17945938992004\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.05638023465872\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:31.178462033470467\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:35.97085464745759\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.643066282073654\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:50.63118831564984\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:33.83848038812478\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:40.81454977393151\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:54.695853491624206\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:38.730710111558444\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-393621.2403996785\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-332176.56163533527\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-216809.67173258463\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-225868.3603922526\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-596091.1373901367\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-491318.9908599854\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-2604.4064009189606\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2014.1091779867807\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2619.3524074554443\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-1708.850859006246\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-6067.881239255269\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2743.4412105878196\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:60.71501662333807\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:65.55400491381684\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:59.70402030895154\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:63.521575840810925\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:62.870622811218105\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.86342619980375\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:65.12366500993569\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:64.83451864371696\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:65.80528204639752\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:63.09279505163431\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:64.2058442781369\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:66.35582237193982\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:56.715701023737594\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:38.60412679612637\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.1008156935374\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.089645214378834\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.694024225076035\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:56.625902093946934\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:56.43374852836131\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:45.828852169215686\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:54.80505160366496\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:54.09921150033672\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:49.30442191660405\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:56.12995864202579\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-22036.281865437824\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-152377.5907007853\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-175014.90563710532\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-71131.57777786255\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-139510.53446451822\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-51462.57099151611\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-805.8503178755442\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-1123.285629749298\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-592.8852077325186\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1522.072868347168\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-565.2710373699665\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-1546.1981892585754\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.06281787902117\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:68.1013261526823\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:71.47221575180689\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:67.80315726995468\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:69.18657068784037\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:71.10230608532827\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:66.50124911218882\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.21223501612742\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:66.61221994707982\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.78400620569785\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:67.66839638352394\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:66.0004174336791\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.08308596909046\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:58.306005957225956\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:57.44991511106491\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:59.811205677688115\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:60.04778053611517\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:61.85280103236437\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:39.67586743334929\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:56.92848653843006\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:45.20728594313065\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.7708376844724\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:46.421589689950146\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.24987275650104\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-43570.91009775797\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-44736.925366719566\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-15446.109313964842\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-11007.887891133627\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-58786.093800862625\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-28152.66724904378\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-116.47105932235719\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-34.54984029134114\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-72.9795225461324\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-57.71060044566789\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-280.723876953125\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-268.6977736155192\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:60.31400678058465\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:68.32964236537616\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:67.60019541562845\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:68.29710061351459\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:66.82756428917249\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:71.93746271232764\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:65.81650911519925\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:71.42205957323313\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:67.82646207759777\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:67.90730018168688\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:67.05140905765195\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.54164124652743\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.01989893615246\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:64.87588581318657\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:66.20820075273514\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:64.91321238378684\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:66.67422538002332\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:64.17655902604263\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:54.14272593955198\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:38.87616043289503\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:57.98549518610041\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.926817844311394\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.71749841670194\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:35.37409457067648\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-4539.653097788493\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-4598.381570180257\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-2262.0457712809243\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-904.4735654195149\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-2575.073833465576\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1606.776242653529\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:53.6205639441808\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:55.96065903703371\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-415.41655893127125\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:41.03837092717488\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:50.922255267699555\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:53.17525386810302\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:57.81784959137439\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:68.03426866730054\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:65.86122186233601\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:69.07737821340561\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:69.43468227982521\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:60.673564175764724\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:60.70602421260749\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:65.41675107553601\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:62.39021409302949\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:63.96678825219473\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:63.88675965368748\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:57.43667686978976\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:65.88362293938796\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:66.18184965103865\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.17121461530526\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:65.3524019693335\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.61045845970511\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.9032429032959\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.984813690185554\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:39.80599081764618\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.35504211733739\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:58.71629864598313\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:55.630465944608055\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:55.93252946933111\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-396.98965708414715\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-419.3080647786458\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-64.70901648203531\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-303.27246348063153\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1697.4662971496582\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:61.638781229654946\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:59.06789143880209\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:62.35951602458953\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:60.83578983942668\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:14.762536684672034\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:61.14288568496704\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:61.87035004297891\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:59.484611228108406\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:68.34738224744797\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:57.30377197265625\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:55.11232341329257\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:64.08254367609818\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:60.10070482889811\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:53.12379773706197\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:57.13546561698119\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:59.9674308548371\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:45.31322707732518\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:56.43353705604871\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:64.1800323377053\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:65.2055030874908\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:66.42279346163073\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.7354824244976\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:62.53867427508036\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:65.11281562348206\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:65.51709761222205\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:59.2612381093204\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:63.178742602467544\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:61.68694553275903\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:57.63066635777553\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:61.882693879306316\n",
            "Layers: 3, Neurons: 16, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:59.31364546219508\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1017795.9309895834\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-837812.5651041666\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1303959.8307291665\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-51900.459798177086\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-438348.9095052083\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-46957.920735677086\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-9629.796803792318\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-9681.04345957438\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-5557.649790445964\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-564.2467562357584\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-8763.272336324057\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-27417.682342529297\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-492.27725108464557\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-390.00853697458905\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-378.0897299448649\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-516.765820980072\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-385.3329118092855\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-272.1242729822795\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:44.460151071349785\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.608439818024635\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:51.044781009356186\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:44.79594151178996\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:46.448817352453865\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:40.68808009227117\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:42.88237815101942\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:53.101272632678345\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:46.99064812312523\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:50.99972801283001\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.03109338879586\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:40.446346501509346\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:55.49768291413783\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.91217360893886\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:43.60439298053582\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.022916267315544\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:57.54683529337248\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:56.23196323712667\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-338219.4661458334\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-1102827.5716145835\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-599035.1725260417\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-879266.4713541666\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-507975.0651041667\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-623787.4837239583\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-978.1146589914957\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-2546.4202467600503\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-320.01725276311237\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2458.503818511963\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-17612.37335205078\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-3981.3462003072104\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:38.2252703110377\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:40.72898169358571\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:44.01967187722524\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:30.571179389953617\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:17.04706569512685\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:40.64128359158834\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:52.98033098379771\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:54.532557229201004\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:50.99807669719061\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:52.1858116487662\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:58.10282014310359\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:51.56613916158677\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:52.377725442250565\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.928283105293914\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:53.73775998751322\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:51.97725454966226\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:53.41008802254994\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.692763408025115\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:37.997041096289955\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.17852945625782\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.21338799595833\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:17.583574652671818\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:57.976308266321816\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:53.562774707873665\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1107226.6927083335\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-442979.1829427083\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-976645.0846354166\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-9422.396596272785\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-1158451.7903645835\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-1241600.0651041665\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-465.6521479288737\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-11736.006673177082\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2331.656913757324\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-937.4086062113444\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1304.1343069076538\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-2336.8966484069824\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:48.63030115763346\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:49.707704236110054\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:49.94723737239838\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:54.76249237855275\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:49.14329131444295\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:56.45044133067131\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:58.108707343538605\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:54.47607338428497\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:55.814956525961556\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:55.1812806725502\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:55.76375129322211\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:55.317756682634354\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:53.41144626339276\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.41465209921201\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:55.01330062747002\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.87018213669459\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:53.28185816605886\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.85798828303814\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:53.197750598192215\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:53.10626695553462\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.93557394544284\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:53.04168631633123\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.9815019518137\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.34851627548536\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-424354.6223958333\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-322056.5999348959\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-381772.5179036459\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-326615.8040364584\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-188173.72639973956\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-243417.27701822916\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-1076.3753128051758\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-354.5090532302856\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:55.70721228917439\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-285.82471211751306\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-574.5951016743977\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-30.92485427856446\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:60.49373626708985\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:59.33039054274559\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:53.8807021578153\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:53.269532024860375\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:54.556770324707024\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:58.78906552990277\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:66.78594636109968\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:67.50653109202783\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:67.93322907450299\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:67.35152348876\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:67.10114033271869\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:68.65761217971642\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:54.701107343037926\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:56.33596162001292\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.337842375040054\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.83797531326612\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.084081153074905\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.883829464515046\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:47.73916420837243\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:54.825840555131435\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.88766100009283\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.226459989945084\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:53.6379337310791\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:44.69354286789894\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-10042.775472005207\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-36418.24137369792\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-31369.773356119793\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-6511.764017740886\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-22856.271870930992\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-5586.428960164389\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:34.77074782053629\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:45.77621618906657\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:57.91226387023926\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-44.48432127634685\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-204.5168956120809\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-13.038752079010019\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:62.71338780721029\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:53.306232541799545\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:53.287635346253715\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:64.285882016023\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:61.80943702658017\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:54.93275304635365\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:69.29333675652742\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:69.68465770905216\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:69.76061542207997\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:68.9756466448307\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:69.18068050717314\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:69.83225235715508\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.241974661747605\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.61733623345694\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:61.64808049798012\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:55.740054249763496\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:57.29318795104821\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:65.34580960869789\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.57823093732198\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.9341239631176\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:54.906056871016816\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.23741521934669\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:53.43626578648886\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.43107258280118\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.80973815917969\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:52.575810750325516\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:52.784665425618485\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:53.19232940673828\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-4557.708994547525\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:53.099632263183594\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.3658218383789\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.381474812825516\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-263.04825146993005\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.381408452987664\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-38.96756966908772\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-169.79605356852213\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:64.53790456056595\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:53.38146711389224\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:68.32600792249043\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:66.40759475529194\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:64.10571972529094\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:61.14980407059193\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:60.223857232679926\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:59.43572957689563\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:66.30587877705693\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:58.405667543411255\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.22277149061362\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:63.371520445992545\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:66.64015093197425\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:66.59686849762996\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:66.42756235475342\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:66.1108429543674\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:66.67406397561233\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:66.424565538764\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:57.79337617258231\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:53.62385302782059\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:55.871064091722175\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.49364662170411\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:53.84013762076696\n",
            "Layers: 3, Neurons: 32, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.094688544670746\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-1188413765.0\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-4952750281.666667\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-1085581890.0\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-3014115376.6666665\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-7181476161.666666\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-6986092375.0\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-673798.2430013021\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-68532.70431518555\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-369773.4702555339\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-42458.70600382487\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-505770.9908040365\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-682030.6038411459\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-866.0661323865254\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-435.7365520795186\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-420.56418657302856\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-589.1518195470173\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-333.05863459904987\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-277.46412714322406\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:56.53818611055612\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.615461183091\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:55.75592050949732\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:52.34069548547268\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:57.35283666600783\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.15048502261439\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:43.25362301121155\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:44.051019474864006\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:53.661816387126834\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:56.18549911926189\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:57.37170765952517\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:41.336646998922035\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:45.28273830190302\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:45.38762296239535\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.3651210310248\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:53.196829967200756\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:49.39064669112364\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:57.316025600302964\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-171506.6080729167\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-198695.7112630208\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-563926.1555989583\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-586453.9388020833\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-212401.72526041666\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-2957.61038462321\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-756.9582303365072\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-4313.673655192057\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2410.484568277995\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-3845.104090372721\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-7579.576365152995\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-5326.503499348959\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:46.18801156679789\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:42.262470722198486\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:44.586158792177834\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:41.4859930674235\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:43.72733533382416\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:29.684851020574566\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:69.43907912820578\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:63.44977452109257\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:66.83992769569159\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.86834609260161\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:65.39222809175651\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:64.87408088520169\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.210598453879356\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:55.50111850102743\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:58.01729639371236\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.00255011270443\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:55.12313437958558\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:54.42307638625303\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.04305857419968\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:55.057377185051635\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:57.80105385308465\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:56.16814914469918\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.933180686707296\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:57.7613098671039\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-1921110.0911458333\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1088814.0299479165\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-746288.4928385417\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-2091954.5572916667\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-2034080.4036458333\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-2396977.083333333\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-989.2440478006998\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2570.418230692546\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-7945.741780598958\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-823.8136927286783\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-3969.1340128580728\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-3256.678263346354\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:56.968202789624534\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:57.03996196389198\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:64.66357618570328\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:54.65787400801976\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:58.854586432377495\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:56.283657252788544\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:66.12784039229155\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.93744981909792\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:67.32341514279445\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:68.16616363823414\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:69.44028089443843\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:68.68832960880052\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:57.852341135342925\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:52.95430148641269\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:61.889352686703205\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:58.038735911250114\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:56.8697576969862\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:56.63571479419866\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:55.44961212823789\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.8280991440018\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:57.08615854382515\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.88138083616892\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:58.16228666653236\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.0282987728715\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-553780.4036458333\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-10103.573099772137\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-14598337.226562498\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1868690.8854166667\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1305732.1940104165\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-623319.7591145833\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-878.4524281819662\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-685.008939107259\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-181.07403119405112\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-4709.883931477864\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-419.0824826558431\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-257.5014511744181\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:52.11466302474339\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:62.181745072205864\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:63.357503563165665\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:52.47935752073924\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:63.36710924903552\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:53.212519983450576\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:60.92563788716991\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:65.30299376696348\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:66.10116872626047\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:68.7345159985125\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:63.54869097471237\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:65.09174971530835\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:60.91298811137676\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:62.79104057699442\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:66.63758289068937\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:63.51909710094332\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:66.40368270377319\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:63.680808010200664\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.4035946726799\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.35624043953915\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:46.45188541462024\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:54.219746248175696\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:58.4100597910583\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:55.661533772945404\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-90394.4783528646\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-226459.09830729166\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-672190.9342447917\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-174438.4928385417\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-665897.7864583333\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-110717.80192057292\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-5.685345331827807\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-93.49741141001384\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:42.91708469390869\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-204.37482198079428\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:1.4091650644938114\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:43.9337432384491\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:53.253326316674546\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:53.257450461387634\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:53.515565395355225\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:53.28268210093181\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:53.37616105874379\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:53.52254857619603\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:59.921645571788154\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:55.09874359083673\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:63.20876192922393\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:61.60687182098628\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:58.14986096695065\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:62.44798840334018\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.97282309302439\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.00290495033066\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:66.62708369394143\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:67.40405075252056\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.95653366297483\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:67.66317652538419\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:59.002385437488556\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:55.13845083614191\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.59790015220643\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:56.75108865524332\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:59.44303914904594\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:56.69092372059822\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-372.64124552408856\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:56.659813721974686\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:57.681822776794434\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:52.8537114461263\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-31.929906209309888\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:21.138890584309898\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-51.436605453491204\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.396431605021164\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.389475742975876\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.40164502461751\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.38401794433594\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.38974446058273\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:53.38210165500641\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:55.78641360004744\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:53.38207930326462\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:53.382090727488205\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:53.38221887747447\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:53.38221391042073\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:60.62158927942316\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:58.88393118977546\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:59.31073513502876\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:60.65765503793955\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:63.88347076872984\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:57.520418912172325\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:58.98077696406593\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:58.832315877079964\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:63.52057439119865\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:59.23594797650973\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:54.68519107749065\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:58.654707117627055\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:59.14856166889271\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:62.942971512675285\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:59.70147473116716\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:60.82144049927592\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:59.12619840353728\n",
            "Layers: 3, Neurons: 32, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:60.318191585441426\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-70811.09883626302\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-128135.99263509116\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-111046.15539550783\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-70192.5717163086\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-149849.9550374349\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-111147.7480061849\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-786.9233989715576\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-803.7235991160076\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1932.344929377238\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-771.1475086212157\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-765.0982681910197\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-1219.7019211451213\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:36.26670777797699\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:44.82735594113668\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:44.41315233707428\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:19.608643651008606\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:45.08269101381301\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:30.71098109086354\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:51.954590529203415\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:56.995505057275295\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.473059276739754\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:44.14089145759742\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:56.67238414287568\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:54.72506210207939\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:54.83880596856277\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:47.53501153240601\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:57.33571028957765\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:57.70460067937771\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:54.989534094929695\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.73042862055202\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:58.24758873631557\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:48.59868788470825\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:44.756085400780044\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:56.461505057911076\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:55.44934262832007\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:55.73255330324173\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-216599.66634114584\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-235841.81315104166\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-227188.76139322916\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-311325.2360026041\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-162268.7337239583\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-324913.06513468426\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-1349.940020243327\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-982.4912818272909\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-601.9107373555502\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2918.1517219543457\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1213.8857905069988\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-1512.7335802714028\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:57.7078154993554\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:56.789292407532535\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:57.04277624686559\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:56.14018303652604\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:56.31690646211307\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:56.63976150254408\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:53.420042991638184\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:53.09997349977493\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:51.31983583172162\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:53.55118274688721\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:54.28304448723793\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:53.256105532248824\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:57.08390474319458\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:56.40818335115909\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:55.235196674863495\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:52.267248344918094\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:56.17811600367229\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:55.007757817705475\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.96478773777684\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:54.216366571684674\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.35569049355884\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.592098434766136\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:58.107876628637314\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:49.53664777179559\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-89137.15616861978\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-143006.00179036456\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-13480.572001139322\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-66470.63262939453\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-132816.9026692708\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-143309.76969401044\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-1114.5836242039998\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-509.6197613080343\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-384.4241682688395\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-1472.0366636912026\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1304.9504820505779\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:51.136207580566406\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:64.83896382153034\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:70.40446287641923\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:69.24155960480371\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:67.51017549385627\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:69.40586686134338\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:67.6791166762511\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:52.852438390254974\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:53.0369226137797\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:53.16536724567413\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:53.869213511546455\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:53.84851713975271\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:53.362944672505066\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:55.25925862292449\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.315510749816895\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:57.03832757969698\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:53.16491454839707\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.421598464250565\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:54.70939517021179\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:51.182536793251835\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:58.17873075604438\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.422399658709764\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:50.49084393928449\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:55.14167457818985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:50.190832950174816\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-9273.166580200195\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-35188.63932291667\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-29637.13887532552\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-5021.553166707357\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1690.7117207845051\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-16588.07169596354\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-51.53710206349691\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-3.2821496327718025\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-84.12794152895609\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-154.91838614145914\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:21.852600971857704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-326.6781047979991\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:69.48418033619721\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:67.1618527919054\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:63.33879753947258\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.87343888978164\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:62.87354568640391\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:66.85219335059325\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:55.496758818626404\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:57.69909511009852\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:58.44667986035347\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:68.08962561190128\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:56.750355536739036\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:69.16046414524317\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:53.331982990105956\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:54.039911429087326\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:53.416020621856056\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.787511140108116\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:54.983795235554375\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.613553742567696\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:50.17095595598221\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:56.653386702140175\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:54.667751491069794\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:58.005225180337824\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:38.97765311102073\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:56.24986144403616\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-6322.7773030598955\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-93.84473164876302\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-641.2404378255208\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1338.0420049031577\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-329.81516520182294\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-950.1287460327148\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-268.2375939687093\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:57.25412686665853\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-186.13932609558103\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:54.437287648518875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:50.44445951779684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:52.1273422241211\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:64.19157319081326\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:69.49349517623584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:64.99055730799834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:66.03987986842792\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:67.88990541050832\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:66.4279609421889\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:63.834427716210485\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:64.11446038633585\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:62.34250611315171\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:62.70428338398536\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:63.6246941362818\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:65.41911161504686\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:53.44652463992436\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.4610100587209\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:53.45499301950136\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:53.41253216067949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:53.439591974020004\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:53.45230042934418\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:56.98563319941361\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:54.02288208405177\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:55.183422639966004\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:54.654996953904636\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:57.35457835098108\n",
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:54.96840854485829\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.22151184082031\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:54.15538787841797\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:54.476636250813804\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:31.16785685221354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:53.397878011067704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:53.67523829142253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.342811862627656\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:63.70006402333577\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.406297365824386\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.381403287251786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:62.303633689880364\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:54.18545643488566\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:64.50100767115752\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:67.09651060402393\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:67.22244650125504\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:66.58506645510593\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:70.44630269209544\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:68.53675010303657\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:65.60096266058584\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:66.55634876340628\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:65.89099149840574\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.98185785114765\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:64.35063010702531\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:64.35768248513341\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:55.77439121901989\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:57.297080457210534\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:62.36902502675852\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:63.18563958009085\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:61.36056716243425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:56.71234553058942\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:55.54023971160254\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:55.625057592988014\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:54.61078872283301\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:56.275231912732124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:54.39154167970022\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 32, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:55.83829969167709\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-327527.670694987\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-70031.87255859375\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-29093.386891682945\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-115742.92460123697\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-22184.928889274597\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-702334.2504882812\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2559.0226407845817\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1918.4094587961833\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-313.1946576635043\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1329.4652231534321\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-1260.031867424647\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:3.2092565298080467\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:4.619744320710495\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:19.073743348320328\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:31.844621524214745\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-56.02361411477128\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-109.47287218024333\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-26.620296960075706\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:60.773899052292116\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:57.71084822714329\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.70302454878886\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:58.10558527708054\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:60.35313593534132\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:56.053588315844536\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:56.89873803096512\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:54.70038767283161\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:44.1988226895531\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:57.28361640280733\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.04557257393996\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.306956661865115\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:59.17959623038769\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:43.64641190816959\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.554913464933634\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:39.140923668940864\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:31.986050220827266\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:48.18398760942121\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-404605.29575983685\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-1570807.5928751628\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-962534.3273544312\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-724895.6346766154\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-981216.7945353191\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-1750078.8162231445\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-22353.411274751026\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-10723.406963348389\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-17438.536028862\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-12012.189968427021\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-6340.171330769857\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-14649.896685282389\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:47.597755597283445\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:30.718678583701454\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:1.0461800048748637\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:22.448527875045933\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:30.867005909482636\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:61.29498358815908\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:66.05308523401618\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:66.5828659509619\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:63.64571223035455\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:62.80266488902271\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:63.42787251342088\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:65.13709088166554\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:53.051920905709274\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:59.96598762770493\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.246136309889465\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:59.19424639393887\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:59.91774445399643\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:60.7576169570287\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:53.692312171915546\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:52.78045584137241\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:42.106977912286915\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:37.50259599337975\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:56.541734132915735\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:50.130628341188036\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-233186.93367004395\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-154222.79744466147\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-582792.3413213094\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-362135.5182393392\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-500891.3811747233\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-681764.4663492839\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-2430.563199122747\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-7316.218095620474\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-6889.834202130636\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-6918.715091198684\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-3674.0503835678096\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-3227.1279207865396\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:52.989700784285866\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:57.15315175553163\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:53.50268793602784\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:63.90085563063621\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:57.456837147474296\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:51.12792294472456\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:67.5153495495518\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:65.74629593562955\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:66.4894590775172\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:66.40292164559165\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:64.68038430437446\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.9133331477642\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:66.33151364823182\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:65.53926967084408\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:63.20694708886245\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:67.01609030986826\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:65.8201958052814\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:65.42619059483211\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:56.546674414227404\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:57.14644546310107\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.59245898822944\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:45.869831629097455\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.99761621902386\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.53475999832154\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-91298.16664377849\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-163365.76395670572\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-144252.9844156901\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-144328.43485514322\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-154980.43915112814\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-56795.93578974406\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-414.70620870590216\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-487.70375887552893\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-1548.7169718742373\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-1122.5627462069192\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-349.4429941972097\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-4290.82470258077\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:64.86012021700542\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:65.8822285135587\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:67.64661903182665\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:65.73466155678034\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:64.09510279695193\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:63.06718168159327\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:67.86837117280811\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:63.90012903759876\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:62.66234504679839\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:63.04879151284695\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:66.03755195314686\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:63.816780274113015\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.73184181625645\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:65.33637476464112\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:65.8892038712899\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.63039201622207\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:64.94738597422838\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:66.19453348219395\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:58.529826479886346\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:57.05841061969599\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:58.26130665217837\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:57.44386425241827\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:57.990218847990036\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:58.86287003134687\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-7246.531906127931\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-9299.17750676473\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-23158.858737945557\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-12843.25028737386\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-8495.33526102702\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-7584.282385508219\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-1406.1123768488565\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-67.94403076171875\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-2477.599987188975\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-38.91971826553344\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-252.98863887786865\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-189.80750759442645\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:69.1799985865752\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:68.50659863402446\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:69.2810187737147\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:68.92414326469103\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:63.563531090815864\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:67.19773093859355\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:61.34320673222343\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:60.70389197518429\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:60.54618674640855\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:58.89555207143226\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:63.121567306419216\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:62.35218459740282\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:66.28397077942888\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:66.71551534285148\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.81003687034051\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:66.35365433990955\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.3892153998216\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:66.93347656478484\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:62.11086674282949\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:60.92238112042347\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:63.702873413761466\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.58521796514591\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:57.36104217668374\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:60.00099956989289\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-1304.1863187154133\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:59.06153361002604\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-232.8064473470052\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-2279.410972595215\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:61.51820500691731\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:62.29479471842447\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:31.520784695943192\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:18.480981190999344\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:58.57263535261155\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-935.318542321523\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-763.2096060117085\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:56.23109847307205\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:60.82829224566619\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:63.9007236994803\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:62.02259916191299\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:57.41934518019358\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:58.53269760807356\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:64.92807226255536\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:55.166369751095765\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:62.23698883317411\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:56.824034278591476\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:58.0989574889342\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:54.777527327338845\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:60.36241235832374\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:60.27147111793359\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:63.66010449205836\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:61.4679649223884\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:64.00843773037195\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:61.654041868944965\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:59.623194436232254\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:64.36124001940091\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:65.85431118476359\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:65.41514149246117\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:64.79981008296211\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:64.71918643762669\n",
            "Layers: 3, Neurons: 32, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:64.75689093271892\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-930158.4309895834\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-1561620.3450520835\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-3857774.7395833335\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-4214617.057291666\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-1677825.2604166667\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-1910387.7604166667\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-7388.396962483724\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-18350.472513834633\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-2198.0452855428057\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-8640.538533528645\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-6139.713795979818\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-22291.08327229818\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-1249.365267753601\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-1161.8766498565674\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-1412.9615179697673\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-911.0178963343303\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-1295.8770322799683\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-1447.1148379643757\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:-23.787703712781273\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:5.272386868794754\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:-16.051627596219387\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:-18.810265660285943\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:-34.13975874582926\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:-58.0469403664271\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:36.21771392722925\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:35.668257450064026\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:52.76014511783917\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:53.805790593226746\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:55.62190622091293\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.22488114237785\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:53.96162127455075\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:55.053427194555596\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:57.639625420173004\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:56.621499595542744\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:57.1286246056358\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:55.318752986689404\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-3548478.3854166665\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-348353.3365885416\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-3558286.0677083335\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-3307518.6197916665\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-3346239.9739583335\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-2761397.200520833\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-62954.90519205729\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-67672.76407877603\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-33667.93314615886\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2520.3936894734697\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-5023.128382364908\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-432.9164346059163\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-4.993677139282227\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:22.14970012505849\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-24.8797599474589\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:50.43390934665998\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:50.38954809308051\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:4.551588296890263\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:51.78117742141089\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:54.34768016139666\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:50.51293671131134\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:51.91355307896932\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:52.88484175999959\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:50.75966576735178\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:55.563955803712204\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:52.3452278971672\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:51.17343867818514\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.77311449746291\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.42644417285919\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:52.44110658764839\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:54.97938185930252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:53.454399059216186\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:55.637647385398544\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:53.73506943384807\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:53.61068174242973\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:55.06926201283932\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-2290205.403645833\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-3655252.4739583335\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-4506542.057291666\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-2132096.809895833\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3731352.4739583335\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-106102.04264322917\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-49962.13785807292\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-16196.439615885416\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-47087.66682942708\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-34648.3662923177\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-3454.3999989827475\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-26139.134724934895\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:53.11894662678242\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:55.36199301481247\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:41.15941606462001\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:56.74661161998908\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:47.069593469301864\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:33.30333714683851\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:55.99037798742453\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:56.08172213037809\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:54.84521289666493\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:56.361573711037636\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:56.588602339228004\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:55.7675622900327\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:54.01165301601092\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:53.28707456588745\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:54.89690209428469\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:54.00241747498512\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:54.609623799721405\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:52.70686000585556\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.772949139277145\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:52.78152013818422\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:53.01321268081664\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:55.36300462981065\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:54.121775378783546\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:53.45435207088789\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-482642.3177083333\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1132338.4440104165\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-35324.76704915364\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-1404912.5325520835\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1248968.7174479165\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-1997508.5286458333\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-7138.15434773763\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-11750.854237874348\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-9286.169179280598\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-3509.6700032552085\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-395.8132902781169\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-18250.554402669273\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:52.23284075657526\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:50.849158664544426\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:53.34559693932533\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:50.86510285735131\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:50.00753735502561\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:51.68942580620448\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:66.4971262589097\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.76022471984227\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:63.43876791497072\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:66.15345029781263\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:67.08964237943292\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:61.730947966376945\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:54.47235137224198\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:55.50971359014512\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:55.59827456871669\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:54.07946988940239\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:55.73602755864462\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:56.56229518353939\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:55.59678758184114\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:52.80868093172709\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:53.17211637894312\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:53.62133180101713\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:52.92576342821121\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:53.61297056078911\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-90593.4855143229\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-476552.0833333333\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-155855.13102213544\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-165877.83610026044\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-65913.21004231772\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-92555.82478841147\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-791.6381518046061\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-277.2484461466471\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-670.2028592427571\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-451.6407330830892\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-1090.9061113993325\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-380.48679033915204\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:53.20684855182966\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:53.578938941160835\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:53.41334943970044\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:53.13910499215127\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:53.38264043132463\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:53.650205135345466\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:69.72536553318302\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:70.05411688859265\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:69.69083429003756\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:69.75624354245763\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:69.54808687791228\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:69.56486745427053\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:58.44281040132046\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.78082390595227\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.59523865580559\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.12599154561757\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:60.92730750640234\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:62.988243702178195\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:53.49994267026583\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:53.554637034734085\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:53.64907155434291\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:53.80891626079878\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:54.491999223828316\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:53.977920760711044\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-2209.6356709798174\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:50.98317464192708\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-24543.6757405599\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-397.1617062886556\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-8532.06507364909\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-28864.441935221355\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-133.2624832789103\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-230.53577740987143\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:41.48435195287069\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.41692765553792\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-76.94862683614095\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-103.74747117360434\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:53.357377499341965\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:53.38212748368581\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:53.381547778844826\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:53.38232522209485\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:53.38201656937599\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:53.38284129897753\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:62.93186955774823\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:65.80662397046883\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:62.77444402997692\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.49242318297426\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:65.16308340554436\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:60.651600986408695\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:66.67496810667217\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:66.62483879054587\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:66.59525379538536\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:66.37115021546683\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:66.34315956383944\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:66.85405884558956\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:54.06834284464519\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.45011253158252\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:56.08602310220401\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:54.3762743473053\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:55.81709903975327\n",
            "Layers: 3, Neurons: 64, Activation: Sigmoid, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.871146877606705\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-29993001835.000004\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-20131664778.333332\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-39968542008.33333\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-3641645493.333333\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-28542907595.0\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-5365205588.333333\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-2273622.521158854\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1372035.7275390625\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-1916327.8946940103\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1854099.2626953125\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-598833.3675130209\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2244726.0286458335\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-4252.753985722859\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-3022.0082982381186\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-1066.6004467010498\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-1059.0123112996419\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-4329.319734573364\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-3260.2309926350913\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:49.35977349678675\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:48.670724580685295\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:53.032177984714515\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:52.20109298825264\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:51.30563144882521\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:47.53220578034719\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:58.31205237656831\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.13970663398504\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:45.25124315172434\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:57.61503822480638\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:52.87219196557999\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:53.196425617982946\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:55.11201535662016\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:55.9878148076435\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:56.26679766302307\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:57.839626449470714\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:56.187411819895104\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:55.37566485504309\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-862831.3151041666\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-5199565.494791666\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-40885622.6171875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-684458.9680989583\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-11635635.60546875\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-1119636.6861979165\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-14614.824422200521\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-17550.235493977867\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2064.195378621419\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2879.920260111491\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-11905.095163981121\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-8667.007954915363\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-5.071338017781568\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:0.18839041392008093\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-5.172427495320631\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:0.22390286127725867\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-194.7274323304494\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-11.77180608113606\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:67.540983009773\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:67.46605072170496\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.95277730127175\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:67.37583325554928\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:67.81642460574706\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:66.837644080321\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:58.8418822735548\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:53.843488842248924\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.275336061914764\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:56.085959772268936\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:54.254383097092315\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.61055986086527\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:50.929160322993994\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.43477212637663\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:57.63508605848378\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:56.03942083194852\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:58.50916095698872\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:57.25492243965466\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-3536974.0885416665\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-2479362.760416667\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-240090931.5641276\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-4663431.901041666\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-3010050.846354167\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-4484693.229166666\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-10526.747385660809\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-12960.538228352865\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-25690.279134114582\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-9040.577952067059\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-5602.555592854818\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-9277.321116129559\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:54.915190537770584\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:29.148144125938412\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:-17.029043485720962\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:-20.822543005148564\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:13.733403881390894\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:46.864781777064\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:66.87780657162268\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.1128380826364\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:68.67460211738944\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.49615262697141\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:64.84419370690982\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:66.79132788131635\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:63.18252995299795\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:64.80103846639395\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:67.69147868268192\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:63.58282340690493\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:64.35781389474869\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:62.41025103876988\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:57.00685419142246\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:56.39845384595294\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:55.97872234880924\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:57.182957902550704\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.61607753485441\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:56.922671385109425\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-1060297.3307291665\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-1192249.1861979165\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-1280116.9596354165\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-3109395.442708333\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-1166127.6041666665\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-3647762.3697916665\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-7876.33539835612\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-2618.9978917439776\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-3882.2767893473306\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-2282.033220926921\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-7519.712575276692\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-8864.657338460285\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:53.6091610789299\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:56.662614320715264\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:53.762663404146835\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:49.28784812490146\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:55.23670961459477\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:51.13885899384816\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:61.48239462325971\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:66.10710657201707\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:62.202785201370716\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:62.035821489989765\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.18766508748134\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:63.69186953951915\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:66.89883586019278\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:65.78145215287805\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:67.8486569908758\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.17894511731963\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:64.73439635088046\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:66.41204171503583\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:57.90124252438545\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:57.60480215152104\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:57.40785965075095\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:55.40449505050977\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:56.633653889099755\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:57.46130123734474\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-2463723.763020833\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-3625176.0416666665\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-733852.5553385417\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-447661.1002604167\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-3989615.7552083335\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-1045782484.4791667\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-177.80524094899496\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-133.04532368977866\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-168.26690832773843\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:56.137462953726455\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:56.2075138092041\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-204.31729952494302\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:53.41440508762996\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:52.66672889391582\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:53.60371520121892\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:53.24856092532475\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:53.17241599162419\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:53.35388680299123\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:63.50385464106997\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:61.37668146441379\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:58.13332788335781\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:62.26329105595747\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:61.03324866465603\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:67.658734669288\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:64.90440811341007\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:66.2059665719668\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:64.06927388782302\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:62.81599770610531\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:62.80821969422201\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:61.47385428970058\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:59.93089102208614\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:57.03061357140541\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:57.18928607801597\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.43277303874492\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:60.32601383825143\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:59.852937137087196\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-7170954.427083333\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-64194.474283854164\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:-720248.7630208333\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-330572.1028645834\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-1105328.9713541665\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-395932.3323567709\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:53.351636727650956\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:53.397536277770996\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:53.41515938440959\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:53.36110591888428\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.3625602722168\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:53.38409741719563\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:56.82610799868901\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:53.38218162457149\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:53.38226159413655\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:53.382228314876556\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:53.38216324647267\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:53.38212649027507\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:62.839500887009\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:61.88284574076533\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:62.62239244145651\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.28075483317177\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:64.79439281548063\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:60.701408833265305\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:59.39799142380555\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:62.22084925199549\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:61.50303499152263\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:60.27733301588645\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:61.17608521754543\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:60.561575038979456\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:63.30032824228206\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:65.69927745498717\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:66.48789785491924\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:65.53253903364143\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:61.92776092638572\n",
            "Layers: 3, Neurons: 64, Activation: ReLU, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:64.37021759649117\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-333909.3054199219\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-13409.715169270834\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-106654.54284667969\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-252961.47989908853\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-147025.50984700522\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-67359.0727742513\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-3942.9995155334473\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-1142.5012079874675\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-923.0642445882161\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-1156.3049952189126\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-5719.685980478923\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2793.8764667510986\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:43.06689341862996\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-41.17632885773976\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:18.856054743131\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:-24.307948946952827\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-5.72120090325674\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-0.34432013829548413\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:50.68534137060246\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:55.73454193770886\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:54.378902092576034\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:53.631656914949424\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:56.56215886274973\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:57.25304941336313\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:56.29254353543123\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:56.442857362950846\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:51.57502892116705\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:57.8415691293776\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:56.8768585473299\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:56.132043500741325\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:56.34119380265474\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:44.813265701134995\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:52.424474551031985\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:56.69610848029454\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:57.18784401814143\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:57.80619089802106\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-165824.32235717773\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-252351.8448893229\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-363613.7561035156\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-326873.5432942709\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-286563.85009765625\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-240447.20052083334\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-3476.5896860758467\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-1959.4905408223472\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-2269.6363735198975\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-2939.9620056152344\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-1668.6332893371582\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-2647.56898244222\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:45.54475322365761\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:56.39031220227479\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:51.96686146159967\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:57.579954266548164\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:42.32380976279576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:41.27154608567556\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:54.54787368575732\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:52.92377422253291\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:53.17473928133647\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:53.357941309611\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:54.226489464441926\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:53.397073447704315\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:56.15794298549493\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:57.16882986327012\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:57.02857070912917\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:54.593014071385056\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:56.63248623410861\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:57.65762380013864\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:57.86461455126604\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:51.89071673899889\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:50.82638202855985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:45.39642132818699\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:55.83976804589233\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:57.711503754059464\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-184355.3385416667\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-112659.28527832031\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-138275.57520548502\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-232794.88932291666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-111114.83459472656\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-139793.5872395833\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-200.70038636525473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-2631.953090031942\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-2206.653550465902\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-2331.7478307088218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-1687.1110725402832\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-632.66570409139\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:66.05576078097026\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:66.48674189423521\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:67.94975221157074\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:57.85146663586298\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:65.88076514502366\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:55.225943128267915\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:53.37641179561615\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:53.81628702084223\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:53.591958433389664\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:53.317640870809555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:52.97177985310555\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:53.729071617126465\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:52.88073023160298\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:52.8548930088679\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:52.71156683564187\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:52.916665176550545\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:55.750181078910835\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:53.32317188382149\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:52.09275186061859\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:54.98721595853567\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:56.77510558317105\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:58.04662448043625\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:56.50883177916208\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:52.81529119859138\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-50486.19160970052\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-2537.341435750325\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-15126.547241210938\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-56377.54069010417\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-46329.73531087239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-41257.99458821614\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-253.36425145467123\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-633.6106808980306\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-60.88447411855063\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-227.36887454986575\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-316.4097595214844\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-889.7985076904297\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:66.57723471522331\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:66.9968702395757\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:64.7720072666804\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:66.29444308578968\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:65.72994371255238\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:63.77963677048684\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:59.2684486011664\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:69.24333784729242\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:58.28802553315957\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:60.54526043434938\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:58.99595898886522\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:64.02913235127926\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:52.869277050097786\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:53.457064876953766\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:52.87025501330693\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:53.140634049971894\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:53.561824361483254\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:53.06011910239856\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:56.93354732046525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:57.03043000151713\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:57.30893124515812\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:56.53753648201625\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:49.96689639985561\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:56.31838861852885\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-6547.7528889973955\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-40429.070027669266\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-4301.468022664389\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-1689.2138163248699\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-5980.563227335611\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-817.2763188680013\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:53.34269126256307\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:53.92812957366308\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:50.3206237157186\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:40.58566530545552\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-272.3163382212321\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-3.8547865549723337\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:65.2092916270097\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:61.148184736569725\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:64.89403061568737\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:67.80086502432823\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:66.72619881729285\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:67.96876416852076\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:61.86495540353158\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:63.392730296278984\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:62.2557281392316\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:61.75121077336371\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:62.12750945861141\n",
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:63.52040314426024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:53.42283154527346\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:53.40415378411612\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:53.47308476765951\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:53.47597569227218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:53.40408151348433\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:53.39845021565755\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:54.916023115317024\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:58.29281110316516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:56.164148822426796\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:57.57816664874553\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:56.88385089238485\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:57.680590798457466\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:-269206.9169108073\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:-898.0705579121908\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:52.90383021036784\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-641.9573465983074\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-217.73465474446616\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-4531.166585286459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:-828.9444955190023\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:58.65117492775123\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:51.9898815949758\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-447.30806668599445\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:53.4158714612325\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-3084.1236050923667\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:69.05832727750143\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:66.43254898488522\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:65.01265933116277\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:63.752602438131966\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:68.53570401668549\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:67.5214228282372\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:63.30320557889839\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:63.1314120752116\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:69.50510287036498\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:65.09823622802892\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:58.805327775577695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:59.85606843295197\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:59.874355743328735\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:68.14712042609851\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:65.62652931859097\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:57.321337511142104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:67.99351821343105\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:57.51318916678429\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:53.864769438902535\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:54.98807117342949\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:53.390824000040695\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:53.38754857579867\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:55.04517806073031\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layers: 3, Neurons: 64, Activation: Softmax, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:54.72465418279171\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 16, Accuracy:-817173.2173665365\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 32, Accuracy:-44250.112406412765\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 64, Accuracy:-41165.20884195963\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 128, Accuracy:-228051.35579427084\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 256, Accuracy:-236983.1655883789\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 10, Batch Size: 512, Accuracy:-51631.11947377523\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 16, Accuracy:-9439.00203704834\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 32, Accuracy:-228.8074709971746\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 64, Accuracy:-3632.0402294397354\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 128, Accuracy:-21817.552353541058\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 256, Accuracy:-2265.3868528207145\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 1, Batch Size: 512, Accuracy:-2877.05321153005\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 16, Accuracy:-33.14458360274632\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 32, Accuracy:-267.3788534849882\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 64, Accuracy:-549.0893463790417\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 128, Accuracy:5.058510998884835\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 256, Accuracy:-152.06768323977786\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.1, Batch Size: 512, Accuracy:-462.1073097487291\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 16, Accuracy:60.72213011483352\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 32, Accuracy:60.84726789345344\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 64, Accuracy:63.41074469809731\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 128, Accuracy:61.10456311609595\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 256, Accuracy:59.37863057789703\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.01, Batch Size: 512, Accuracy:63.75504383817315\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 16, Accuracy:57.12726509819428\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 32, Accuracy:51.77043095231056\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 64, Accuracy:58.68386254956325\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 128, Accuracy:57.88045921052496\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 256, Accuracy:50.60710847377777\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.001, Batch Size: 512, Accuracy:55.72147065773606\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 16, Accuracy:51.326813343912356\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 32, Accuracy:54.01310486719012\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 64, Accuracy:50.92844291279713\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 128, Accuracy:41.381075233221054\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 256, Accuracy:53.96380460510651\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 1, LR: 0.0001, Batch Size: 512, Accuracy:45.205922623475395\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 16, Accuracy:-3058730.5989837646\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 32, Accuracy:-3238571.001739502\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 64, Accuracy:-5053144.939371745\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 128, Accuracy:-6151231.194864909\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 256, Accuracy:-4680160.147094727\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 10, Batch Size: 512, Accuracy:-4501934.5553080235\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 16, Accuracy:-48513.55806350708\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 32, Accuracy:-50170.30536015829\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 64, Accuracy:-43697.75909662247\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 128, Accuracy:-69081.02374712627\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 256, Accuracy:-120069.23024495442\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 1, Batch Size: 512, Accuracy:-34254.92637952168\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 16, Accuracy:-3.032004733880367\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 32, Accuracy:-731.6882377366225\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 64, Accuracy:-251.51901925603548\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 128, Accuracy:-133.71729560196403\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 256, Accuracy:-97.46642085413137\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.1, Batch Size: 512, Accuracy:-207.76005824406943\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Accuracy:64.77697312521438\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Accuracy:67.04523173471291\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Accuracy:64.76841319041948\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 128, Accuracy:64.99171706537406\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 256, Accuracy:66.39255917941531\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.01, Batch Size: 512, Accuracy:63.12795315869153\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Accuracy:64.18722114215294\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Accuracy:65.28847971310219\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Accuracy:64.40889574587345\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 128, Accuracy:65.11718566219011\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 256, Accuracy:65.54940802355607\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.001, Batch Size: 512, Accuracy:66.71688631176949\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Accuracy:51.305145102863506\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Accuracy:56.23749355785549\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Accuracy:56.27576934484144\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 128, Accuracy:55.102958176285036\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 256, Accuracy:54.63697748879592\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 10, LR: 0.0001, Batch Size: 512, Accuracy:49.90248174096147\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 16, Accuracy:-894672.437693278\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 32, Accuracy:-1659691.1020914714\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 64, Accuracy:-1257292.4259440105\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 128, Accuracy:-660897.1270243328\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 256, Accuracy:-2223879.9476114907\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 10, Batch Size: 512, Accuracy:-374797.0946756999\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 16, Accuracy:-17788.55047384898\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 32, Accuracy:-12685.036061604818\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 64, Accuracy:-22277.230610847473\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 128, Accuracy:-11578.842481772104\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 256, Accuracy:-17743.940267562866\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 1, Batch Size: 512, Accuracy:-18885.44764359792\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 16, Accuracy:-76.5081131706635\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 32, Accuracy:-11.02909098068874\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 64, Accuracy:9.115685330082968\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 128, Accuracy:-73.96114215875664\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 256, Accuracy:26.421697946886226\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.1, Batch Size: 512, Accuracy:-8.696947048107774\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Accuracy:65.89228610508144\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Accuracy:67.77193169419964\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Accuracy:67.66946319490671\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 128, Accuracy:65.36882043195267\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 256, Accuracy:66.43061452855666\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.01, Batch Size: 512, Accuracy:65.9190324259301\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Accuracy:65.522847486039\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Accuracy:65.51862896730502\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Accuracy:65.35907558475931\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 128, Accuracy:66.02164944012961\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 256, Accuracy:64.9878578260541\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.001, Batch Size: 512, Accuracy:65.6967177366217\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Accuracy:58.58716336389382\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Accuracy:55.45467844853798\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Accuracy:59.18963392265141\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 128, Accuracy:60.23091968769829\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 256, Accuracy:57.08584863692522\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 25, LR: 0.0001, Batch Size: 512, Accuracy:58.30242320895195\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 16, Accuracy:-489243.1899007161\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 32, Accuracy:-136928.9288965861\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 64, Accuracy:-739137.1089808146\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 128, Accuracy:-136763.33739598593\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 256, Accuracy:-275303.1144269307\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 10, Batch Size: 512, Accuracy:-787189.2891438802\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 16, Accuracy:-2668.9895836512246\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 32, Accuracy:-3469.3540851275125\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 64, Accuracy:-3875.226697921753\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 128, Accuracy:-5908.441735903422\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 256, Accuracy:-3043.393378059069\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 1, Batch Size: 512, Accuracy:-2759.4195540746055\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 16, Accuracy:57.05772171417872\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 32, Accuracy:48.00490528345108\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 64, Accuracy:51.379195422244564\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 128, Accuracy:49.0418764948845\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 256, Accuracy:54.50112397472064\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.1, Batch Size: 512, Accuracy:60.62329133351644\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Accuracy:67.19877843745053\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Accuracy:64.01885758464535\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Accuracy:64.63318071638544\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 128, Accuracy:65.67574286833405\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 256, Accuracy:65.07707963387172\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.01, Batch Size: 512, Accuracy:66.3935362175107\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Accuracy:65.89888900518417\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Accuracy:65.47268442809582\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Accuracy:65.43600462377071\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 128, Accuracy:65.12987455353141\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 256, Accuracy:65.92759086440007\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.001, Batch Size: 512, Accuracy:65.6752489383022\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Accuracy:61.31902122249207\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Accuracy:59.972445610910654\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Accuracy:60.16905918717384\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 128, Accuracy:59.40792065113782\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 256, Accuracy:59.78281598848601\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 50, LR: 0.0001, Batch Size: 512, Accuracy:60.52901014375189\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 16, Accuracy:-36742.15492248535\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 32, Accuracy:-42451.82498931885\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 64, Accuracy:-34916.38854980469\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 128, Accuracy:-109343.096148173\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 256, Accuracy:-56268.80735397339\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 10, Batch Size: 512, Accuracy:-22425.828545888264\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 16, Accuracy:-2317.5207312901816\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 32, Accuracy:-1065.1434004306793\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 64, Accuracy:-1071.4253544807434\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 128, Accuracy:-664.5933492978414\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 256, Accuracy:-320.276673634847\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 1, Batch Size: 512, Accuracy:-299.94144717852276\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 16, Accuracy:59.60124069824815\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 32, Accuracy:62.86240148047606\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 64, Accuracy:68.21117259562016\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 128, Accuracy:55.309413969516754\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 256, Accuracy:56.38040301700433\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.1, Batch Size: 512, Accuracy:63.750808040300996\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 16, Accuracy:58.724251942088216\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 32, Accuracy:62.27361692736546\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 64, Accuracy:61.42128951847553\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 128, Accuracy:62.58561974391341\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 256, Accuracy:59.84841719890635\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.01, Batch Size: 512, Accuracy:62.20468385145068\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 16, Accuracy:66.48963706257443\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 32, Accuracy:65.76265022158623\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 64, Accuracy:65.27126954868436\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 128, Accuracy:66.21059415861964\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 256, Accuracy:65.39943437402447\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.001, Batch Size: 512, Accuracy:66.73693762471278\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 16, Accuracy:65.28365531315406\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 32, Accuracy:64.91582895318668\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 64, Accuracy:64.98706142107646\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 128, Accuracy:64.21529522786538\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 256, Accuracy:65.0023242396613\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 100, LR: 0.0001, Batch Size: 512, Accuracy:64.82675272971392\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 16, Accuracy:53.64576975504558\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 32, Accuracy:52.45608488718669\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 64, Accuracy:50.52397092183432\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 128, Accuracy:-418.76584927241004\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 256, Accuracy:-4365.0296751658125\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 10, Batch Size: 512, Accuracy:-4198.17403793335\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 16, Accuracy:42.72527734438578\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 32, Accuracy:-909.9927658836046\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 64, Accuracy:-496.0610326131185\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 128, Accuracy:-134.7364823023478\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 256, Accuracy:-4693.421279589335\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 1, Batch Size: 512, Accuracy:-3712.9326597849526\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 16, Accuracy:59.98541382451852\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 32, Accuracy:65.23408353328705\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 64, Accuracy:55.84161177277564\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 128, Accuracy:47.05560373763243\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 256, Accuracy:60.78311949968338\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.1, Batch Size: 512, Accuracy:51.862911209464066\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 16, Accuracy:54.962953330638506\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 32, Accuracy:55.14267400062332\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 64, Accuracy:56.01008879486471\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 128, Accuracy:55.89187365025282\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 256, Accuracy:60.96401907115554\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.01, Batch Size: 512, Accuracy:57.698181457817554\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 16, Accuracy:54.264356540516026\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 32, Accuracy:61.85977530355255\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 64, Accuracy:61.66044054940964\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 128, Accuracy:59.22148783380787\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 256, Accuracy:59.458586846788734\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.001, Batch Size: 512, Accuracy:60.09650846322378\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 16, Accuracy:65.13638542965055\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 32, Accuracy:65.64158147200942\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 64, Accuracy:65.94408655228715\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 128, Accuracy:65.32881042609613\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 256, Accuracy:65.91303829258929\n",
            "Layers: 3, Neurons: 64, Activation: Tanh, Epochs: 250, LR: 0.0001, Batch Size: 512, Accuracy:65.18521992489696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the results to a DataFrame and save them to CSV."
      ],
      "metadata": {
        "id": "74WObPB8myq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv(\"mlp_regression_hidden layer 123.csv\", index=False)\n",
        "print(\"All results have been saved to 'mlp_regression_hidden layer 123.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpGm_LSElwER",
        "outputId": "0c4eebd0-e769-4326-cb9c-a73cb325ba58"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All results have been saved to 'mlp_regression_hidden layer 123.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select relevant hyperparameters and mean MAE"
      ],
      "metadata": {
        "id": "ekbzs2ZTm3gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = ['layers', 'neurons', 'activation', 'epochs', 'lr', 'batch_size']\n",
        "mean_mae_by_hyperparameter = results_df.groupby(hyperparameters)['mae'].mean().reset_index()\n",
        "\n",
        "# Plot mean MAE against each hyperparameter\n",
        "for param in hyperparameters:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
        "    plt.title(f'Mean MAE vs. {param.capitalize()}', fontsize=14)\n",
        "    plt.xlabel(param.capitalize(), fontsize=12)\n",
        "    plt.ylabel('Mean MAE', fontsize=12)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UqYoIqXbm7YA",
        "outputId": "f5fd8416-f173-4a7f-959d-66649b76ca5e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "The `ci` parameter is deprecated. Use `errorbar=None` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n",
            "<ipython-input-20-0832088b5b92>:7: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(data=mean_mae_by_hyperparameter, x=param, y='mae', ci=None, palette=\"pastel\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}